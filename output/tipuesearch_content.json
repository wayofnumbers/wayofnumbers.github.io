{"pages":[{"title":"About Me","text":"I am a Machine Learning practitioner, Product Manager, UI / UX Designer, Web Developer and I also write my own website, web app and manage my own server. I love to read and share my thoughts on technology, data science and design. Technology is fun, but it's like an acorn, you'll have to crack the shell to taste the good. Currently writing a lot on Medium.com .","tags":"Miscellaneous","url":"about-me"},{"title":"","text":"Anyone watched Blade Running 2049 must remember â€˜Joi', the pretty and sophisticated holographic projection of an artificial human. She speaks to you, helps you with house affairs, tells jokes to you, keeps you accompanied, and some moreâ€¦ just like a real human. She even has her own memory with you and developed character over time. Except, â€˜she' is not human. She is just a super complicated â€˜modeling' of a real human that can speak, act and react like one. Yet still, quite some people secretly wish that they could also have their own â€˜Joi'. Well, she might not be as far away as you think. Enter NEON , Samsung's new artificial human. Joi from Gfycat Encounter I was at CES 2020 show last week and walking the floor. There were many new gadgets, new technologies revealed like past years. There were also tons of displays. Small, big, huge, foldable, half-transparent, you name it. Among them, one display grabbed my attention. A life-like human stands within a display looking at me with a warm smile and also talks about something with rich gestures. What is this for? A new remote video service maybe? Intrigued, I came closer and checked. Turns out, none of these very realistic figures are human. They are called NEONs, artificial humans created in a Samsung-backed company called STAR Labs. NEON , our first artificial human is here. NEON is a computationally created virtual being that looks and behaves like a real human, with the ability to show emotions and intelligence. â€” STAR Labs From NEON . LIFE The look, expression, gesture are so natural I can't really tell whether it is pre-recorded video or CGI . Look closer, it is obviously CGI , just very very â€˜real'. Real in the sense of â€˜human-like' rather than â€˜high-resolution'. I dug in deeper and found out that these are AI -generated CGI footage based on the pre-recorded real human video, a â€˜recreation' from human actor videos. Very much like what James Cameron first did it in the movie Avatar . Photo from lyon.onvasortir.com But NEON didn't stop there, it pushes things even further. These NEONs can go out-of-script and develop its own â€˜personality'. It can originally generate new expressions, gestures, and reactions out of its own unique â€˜personality'. These â€˜personalities' can also be trained and adapted to outside stimuli. Now, this is deeper than just mimic the facial expression! How did Samsung achieve this and what does this mean? There aren't too many details revealed at the show. My inner Data Scientists instantly got turned on, let's try to figure out (guess) how this is achieved and what impact it could have on our society and industry, shall we? Anatomy So how did they do this? Let's first look at what it can do. To achieve what they claimed, NEON need to do several things: Notes: The below parts are just my â€˜educated prediction', thus bearing no truth on how NEON actually works or created. More details of NEON has yet to be released by Samsung. Physical modeling: Real-human video to CGI , cross the uncanny valley Given some video datasets of one actor, the model needs to learn how to transfer a video into CGI footage, the more similar the better. This technology has been well developed with the rise of Avatar and performance capture. Actors get filmed with some color dots grid on their faces to record their facial expressions and transfer those facial expressions grid movements into CGI character expressions. It's a rather mature technology. What NEON did is just a bit different. It might not have the grid as a reference but using deep learning, it's not too hard for the deep neural networks to find the features they need for the task and it can maybe do better than a simpler model like the facial grid. Data Input: video footages Data Output: facial/body grid movements time series data. Expression modeling: Expression/Gesture projection to CGI So from the video footage, we now have a grid movements time series data set, if we can label these data set with different expressions, we should be able to train some kind of autoencoder that can encode the CGI time-series to expression encoding, then re-generate the same CGI time-series data. Then we can look at the encoding and figure out what is smile, cry, surprise, angry, etc. This is also a solved problem. You can find one examples below: Data Input: CGI Time-series data set Data Output: Expression encoding/embedding layers Personality modeling: Emotion to expression So now we can pretty much control the expression of our CGI avatar via expression encoding, the next step would be to map emotion to expression. The expression is the externalizing of emotion, but the mapping isn't always straightforward. You would think people will laugh when they are happy, but humanity is way more complicated than that. Some outgoing people will laugh out loud while an introvert will probably just smirk subtly. What controls the mapping from emotion to expression is personality. Now how do we model personality? This requires a lot of domain knowledge(this is also what Samsung claims the part they are still working on and I think the most challenging. Cause humanity, you knowâ€¦). Data Input: Emotion Labeling (multiple labels since one expression could have multiple emotions behinds it) Data Output: Expression encoding/embeddings representing the emotion for given avatar What Samsung Say About NEON is comprised of From the presentation we know that NEON is actually comprised of three parts: Behavioral Neural Network ( Expression Model? ) Evolutionary Generative Intelligence ( Personality Model? ) Computational reality ( Physical Model? ) Are my above assumptions true? We'll know more in the near future, but please leave some responses if you have different ideas! Theorycrafting So how do these parts fit together and form a NEON ? It could work as a pipeline: First using the video footage of one human actor to train a neural network that can generate CGI grid time-series data. This will give the ability to control the CGI avatar to be as human as possible. The neural network will inevitably learn how human gestures and human facial expressions patterns, this lays the ground for further abstraction. With the CGI grid movement time-series data, we can train an autoencoder that can do some kind of dimensional reduction, create some middle layer encoder then regenerate the CGI . Once the regenerated CGI is similar enough to the original time-series data, we'll get an even more abstract layer (expression encoder) of the video, expressions, and gestures. Once we have the encoder or embedding, we can play around and see which combination of weights could generate certain expressions, e.g. smile, angry, surprised, etc. We can then use these weights ( might need to do some PCA to make it more manageable) to control the expression of our avatar, make it smile, cry, etc. To this point, the avatar's expression could be largely controlled manually, but it's not there yet. What's needed is to have the avatar itself originally â€˜generate' expressions on its own, react to outside stimuli. This is where the personality model comes into play. Using the domain knowledge of phycology, emotional science, many different personality features can be developed their relationship to expression and outside stimuli can be modeled. If we use certain celebrity (say Bruce Lee) as an example, by labeling his behavior (expression) and outside stimulus (sentiment of words, gestures, etc.), we can develop a â€˜personality' model that reflects what the celebrity will react to the different sentiment with different expressions. Then we use this personality model to control the NEON 's reaction expression according to outside sentiment ( output from a sentiment classifier neural network maybe). In the NEON official videos, there is a real-time visualization of NEON 's â€˜emotion activation' status, indicating how NEON react to outside stimulus. Pretty cool. NEON 's emotional map in real-time, the light bulb is where her current state is and the words are different emotional states. Beyond that, NEON can learn domain knowledge and provide more value. Samsung claims that they have another cloud AI platform called Spectra for that and 3rd party developers will be able to develop those â€˜skills' for NEON . Thinking Siri with a pretty face, charming voice, and can teach you Kung Fu. ðŸ˜œ I have to say, even though the demo they showed on CES 2020 is far from perfect, NEON is groundbreaking. The team is thinking quite big and laid down a good foundation and framework. The computational hunger application at this moment may mean NEON can't live on the edge, but with the fast development of 5G and better cloud platform, I believe the future potential for NEON is huge. Vision Which NEON do you want? Yoga tutor? Magician? Business assistant? Personal Photographer? This is the part of the article where I'm allowed to go wild. Let's see what a NEON can do: Perfect NPC in gaming. In RPG games, NPCs are usually pretty dumb. Their facial expression and reaction are so fake. NEON can change that and give gamers a very real experience. Recreate your passed away loved ones or friends. If you've read this article about a boy tried to create a chatbot speak exactly like his dad and kept him accompany after the old man passed away, you know what I'm talking about. NEON can go even further on this, not only the chatbot generate texts like his father, it can look like, sounds like, act as his father and even with similar â€˜personality'. (maybe a bit creepy but who am I to judgeâ€¦) All kinds of service assistants. Like Yoga tutor, financial planner, or just keep you company with a good personality. Guidance/Helper for disabled people. Celebrity â€˜copy' for fans to adore Autism therapist The list can go on and on, but you get the idea. With it being an open platform, it could very well be the next big thing in tech. Conclusion Usually, CES is about engineering innovations rather than science breakthrough, but I think NEON is somewhat sit in the middle. The team is still very young and I'm so excited to see what they can do in the near future and learn about their approaches. It is really a hidden gem that I felt compelled to introduce to my readers. What do you think an artificial human can do? Cannot do? Or should never do? For more details on what's shown on the stage of CES , you can check out this detailed video:","tags":"Machine Learning","url":"neon-life-your-real-virtual-assistant-for-real-this-time-6de4a52e66c4"},{"title":"Let's Build a Fashion- MNIST CNN , PyTorch Style","text":"When it comes to frameworks in technology, one interesting thing is that from the very beginning, there always seems to be a variety of choices. But over time, the competitions will evolve into having only two strong contenders left. Cases in point being â€˜ PC vs Mac', â€˜iOS vs Android', â€˜React.js vs Vue.js', etc. And now, we have â€˜PyTorch vs TensorFlow' in machine learning. TensorFlow , backed by Google, is undoubtedly the front-runner here. Released in 2015 as an open-source machine learning framework, it quickly gained a lot of attention and acceptance, especially in industries where production readiness and deployment is key. PyTorch is introduced much later by Facebook in 2017 but quickly gaining a lot of love from practitioners and researchers because of its dynamic computational graph and â€˜ pythonic ' style. Image from The Gradient Recent research by The Gradient shows that PyTorch is doing great with researchers and TensorFlow is dominating the industry world: In 2019, the war for ML frameworks has two remaining main contenders: PyTorch and TensorFlow. My analysis suggests that researchers are abandoning TensorFlow and flocking to PyTorch in droves. Meanwhile in industry, Tensorflow is currently the platform of choice, but that may not be true for long. â€” The Gradient The recent release of PyTorch 1.3 introduced PyTorch Mobile, quantization and other goodies that are all in the right direction to close the gap. If you are somewhat familiar with neural network basics but want to try PyTorch as a different style, then please read on. I'll try to explain how to build a Convolutional Neural Network classifier from scratch for the Fashion- MNIST dataset using PyTorch. The code here can be used on Google Colab and Tensor Board if you don't have a powerful local environment. Without further ado, let's get started. You can find the Google Colab Notebook and GitHub link below: ðŸ“™ **Google Colab Notebook ** ðŸ‘½ **GitHub ** Import First, let's import the necessary modules. # import standard PyTorch modules import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from torch.utils.tensorboard import SummaryWriter # TensorBoard support # import torchvision module to handle image manipulation import torchvision import torchvision.transforms as transforms # calculate train time, writing train data to files etc. import time import pandas as pd import json from IPython.display import clear_output torch . set_printoptions ( linewidth = 120 ) torch . set_grad_enabled ( True ) # On by default, leave it here for clarity PyTorch modules are quite straight forward. torch torch is the main module that holds all the things you need for Tensor computation. You can build a fully functional neural network using Tensor computation alone, but this is not what this article is about. We'll make use of the more powerful and convenient torch.nn, torch.optim and torchvision classes to quickly build our CNN . For those of you interested in knowing how to do this from â€˜ scratch scratch ', visit this fantastic PyTorch official tutoria l by Jeremy Howard . torch.nn and torch.nn.functional Photo by Alphacolor on Unsplash The torch.nnmodule provides many classes and functions to build neural networks. You can think of it as the fundamental building blocks of neural networks: models, all kinds of layers, activation functions, parameter classes, etc. It allows us to build the model like putting some LEGO set together. torch.optim torch.optim offers all the optimizers like SGD , ADAM , etc., so you don't have to write it from scratch. torchvision torchvision contains a lot of popular datasets, model architectures, and common image transformations for computer vision. We get our Fashion MNIST dataset from it and also use its transforms. SummaryWriter (Tensor Board) SummaryWriter enables PyTorch to generate the report for Tensor Board. We'll use Tensor Board to look at our training data, compare results and gain intuition. Tensor Board used to be TensorFlow's biggest advantage over PyTorch, but it is now officially supported by PyTorch from v1.2. We also imported some other utility modules like time, json, pandas, etc. Dataset torchvision already has the Fashion MNIST dataset. If you're not familiar with Fashion MNIST dataset: Fashion- MNIST is a dataset of Zalando â€˜s article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion- MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits. â€” From Github Fashion MNIST Dataset â€” From GitHub # Use standard FashionMNIST dataset train_set = torchvision.datasets.FashionMNIST( root = './data/FashionMNIST', train = True, download = True, transform = transforms.Compose([ transforms.ToTensor() ]) ) This doesn't need much explanation. We specified the root directory to store the dataset, snatch the training data, allow it to be downloaded if not present at the local machine, and then apply the transforms.ToTensor to turn images into Tensor so we can directly use it with our network. The dataset is stored in the dataset class named train_set. Network Building the actual neural network in PyTorch is fun and easy. I assume you have some basic concept of how a Convolutional Neural Network works. If you don't, you can refer to this video from deeplizard: The Fashion MNIST is only 28x28 px in size, so we actually don't need a very complicated network. We can just build a simple CNN like this: We have two convolution layers, each with 5x5 kernels. After each convolution layer, we have a max-pooling layer with a stride of 2. This allows us to extract the necessary features from the images. Then we flatten the tensors and put them into a dense layer, pass through a Multi-Layer Perceptron ( MLP ) to carry out the task of classification of our 10 categories. Now that we are clear about the structure of the network, let's see how we can use PyTorch to build it: # Build the neural network , expand on top of nn . Module class Network ( nn . Module ) : def __init__ ( self ) : super (). __init__ () # define layers self . conv1 = nn . Conv2d ( in_channels = 1 , out_channels = 6 , kernel_size = 5 ) self . conv2 = nn . Conv2d ( in_channels = 6 , out_channels = 12 , kernel_size = 5 ) self . fc1 = nn . Linear ( in_features = 12 * 4 * 4 , out_features = 120 ) self . fc2 = nn . Linear ( in_features = 120 , out_features = 60 ) self . out = nn . Linear ( in_features = 60 , out_features = 10 ) # define forward function def forward ( self , t ) : # conv 1 t = self . conv1 ( t ) t = F . relu ( t ) t = F . max_pool2d ( t , kernel_size = 2 , stride = 2 ) # conv 2 t = self . conv2 ( t ) t = F . relu ( t ) t = F . max_pool2d ( t , kernel_size = 2 , stride = 2 ) # fc1 t = t . reshape ( - 1 , 12 * 4 * 4 ) t = self . fc1 ( t ) t = F . relu ( t ) # fc2 t = self . fc2 ( t ) t = F . relu ( t ) # output t = self . out ( t ) # don 't need softmax here since we' ll use cross - entropy as activation . return t First of all, all network classes in PyTorch expand on the base class: nn.Module. It packs all the basics: weights, biases, forward method and also some utility attributes and methods like .parameters() and .zero_grad()which we will be using too. The structure of our network is defined in the init dunder function. def __init__(self): super().__init__() # define layers self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5) self.fc1 = nn.Linear(in_features=12*4*4, out_features=120) self.fc2 = nn.Linear(in_features=120, out_features=60) self.out = nn.Linear(in_features=60, out_features=10) nn.Conv2d and nn.Linear are two standard PyTorch layers defined within the torch.nn module. These are quite self-explanatory. One thing to note is that we only defined the actual layers here. The activation and max-pooling operations are included in the forward function that is explained below. # define forward function def forward(self, t): # conv 1 t = self.conv1(t) t = F.relu(t) t = F.max_pool2d(t, kernel_size=2, stride=2) # conv 2 t = self.conv2(t) t = F.relu(t) t = F.max_pool2d(t, kernel_size=2, stride=2) # fc1 t = t.reshape(-1, 12*4*4) t = self.fc1(t) t = F.relu(t) # fc2 t = self.fc2(t) t = F.relu(t) # output t = self.out(t) # don't need softmax here since we'll use cross-entropy as activation. return t Once the layer is defined, we can then use the layer itself to compute the forward results of each layer, coupled with the activation function(ReLu) and Max Pooling operations, we can easily write the forward function of our network as above. Notice that on fc1(Fully Connect layer 1), we used PyTorch's tensor operation t.reshape to flatten the tensor so it can be passed to the dense layer afterward. Also, we didn't add the softmax activation function at the output layer since PyTorch's CrossEntropy function will take care of that for us. Hyperparameters Normally, we can just handpick one set of hyperparameters and do some experiments with them. In this example, we want to do a bit more by introducing some structuring. We'll build a system to generate different hyperparameter combinations and use them to carry out training â€˜runs'. Each â€˜run' uses one set of hyperparameter combinations. Export the training data/results of each run to Tensor Board so we can directly compare and see which hyperparameters set performs the best. We store all our hyperparameters in an **OrderedDict **: # put all hyper params into a OrderedDict, easily expandable params = OrderedDict( lr = [.01, .001], batch_size = [100, 1000], shuffle = [True, False] ) epochs = 3 lr: Learning Rate. We want to try 0.01 and 0.001 for our models. batch_size: Batch Size to speed up the training process. We'll use 100 and 1000. shuffle: Shuffle toggle, whether we shuffle the batch before training. Once the parameters are down. We use two helper classes: RunBuilder and RunManager to manage our hyperparameters and training process. RunBuilder The main purpose of the class RunBuilder is to offer a static method get_runs. It takes the OrderedDict (with all hyperparameters stored in it) as a parameter and generates a named tuple Run, each element of runrepresent one possible combination of the hyperparameters. This named tuple is later consumed by the training loop. The code is easy to understand. # import modules to build RunBuilder and RunManager helper classes from collections import OrderedDict from collections import namedtuple from itertools import product # Read in the hyper-parameters and return a Run namedtuple containing all the # combinations of hyper-parameters class RunBuilder (): @staticmethod def get_runs ( params ): Run = namedtuple ( 'Run' , params . keys ()) runs = [] for v in product ( * params . values ()): runs . append ( Run ( * v )) return runs RunManager There are four main purposes of the RunManager class. Calculate and record the duration of each epoch and run. Calculate the training loss and accuracy of each epoch and run. Record the training data (e.g. loss, accuracy, weights, gradients, computational graph, etc.) for each epoch and run, then export them into Tensor Board for further analysis. Save all training results in csv and json for future reference or API extraction. As you can see, it helps us take care of the logistics which is also important for our success in training the model. Let's look at the code. It's a bit long so bear with me: # Helper class , help track loss , accuracy , epoch time , run time , # hyper - parameters etc . Also record to TensorBoard and write into csv , json class RunManager () : def __init__ ( self ) : # tracking every epoch count , loss , accuracy , time self . epoch_count = 0 self . epoch_loss = 0 self . epoch_num_correct = 0 self . epoch_start_time = None # tracking every run count , run data , hyper - params used , time self . run_params = None self . run_count = 0 self . run_data = [] self . run_start_time = None # record model , loader and TensorBoard self . network = None self . loader = None self . tb = None # record the count , hyper - param , model , loader of each run # record sample images and network graph to TensorBoard def begin_run ( self , run , network , loader ) : self . run_start_time = time . time () self . run_params = run self . run_count += 1 self . network = network self . loader = loader self . tb = SummaryWriter ( comment = f '-{run}' ) images , labels = next ( iter ( self . loader )) grid = torchvision . utils . make_grid ( images ) self . tb . add_image ( 'images' , grid ) self . tb . add_graph ( self . network , images ) # when run ends , close TensorBoard , zero epoch count def end_run ( self ) : self . tb . close () self . epoch_count = 0 # zero epoch count , loss , accuracy , def begin_epoch ( self ) : self . epoch_start_time = time . time () self . epoch_count += 1 self . epoch_loss = 0 self . epoch_num_correct = 0 # def end_epoch ( self ) : # calculate epoch duration and run duration ( accumulate ) epoch_duration = time . time () - self . epoch_start_time run_duration = time . time () - self . run_start_time # record epoch loss and accuracy loss = self . epoch_loss / len ( self . loader . dataset ) accuracy = self . epoch_num_correct / len ( self . loader . dataset ) # Record epoch loss and accuracy to TensorBoard self . tb . add_scalar ( 'Loss' , loss , self . epoch_count ) self . tb . add_scalar ( 'Accuracy' , accuracy , self . epoch_count ) # Record params to TensorBoard for name , param in self . network . named_parameters () : self . tb . add_histogram ( name , param , self . epoch_count ) self . tb . add_histogram ( f '{name}.grad' , param . grad , self . epoch_count ) # Write into 'results' ( OrderedDict ) for all run related data results = OrderedDict () results [ \"run\" ] = self . run_count results [ \"epoch\" ] = self . epoch_count results [ \"loss\" ] = loss results [ \"accuracy\" ] = accuracy results [ \"epoch duration\" ] = epoch_duration results [ \"run duration\" ] = run_duration # Record hyper - params into 'results' for k , v in self . run_params . _asdict (). items () : results [ k ] = v self . run_data . append ( results ) df = pd . DataFrame . from_dict ( self . run_data , orient = 'columns' ) # display epoch information and show progress clear_output ( wait = True ) display ( df ) # accumulate loss of batch into entire epoch loss def track_loss ( self , loss ) : # multiply batch size so variety of batch sizes can be compared self . epoch_loss += loss . item () * self . loader . batch_size # accumulate number of corrects of batch into entire epoch num_correct def track_num_correct ( self , preds , labels ) : self . epoch_num_correct += self . _get_num_correct ( preds , labels ) @torch . no_grad () def _get_num_correct ( self , preds , labels ) : return preds . argmax ( dim = 1 ). eq ( labels ). sum (). item () # save end results of all runs into csv , json for further analysis def save ( self , fileName ) : pd . DataFrame . from_dict ( self . run_data , orient = 'columns' , ). to_csv ( f '{fileName}.csv' ) with open ( f '{fileName}.json' , 'w' , encoding = 'utf-8' ) as f : json.dump ( self . run_data , f , ensure_ascii = False , indent = 4 ) init : Initialize necessary attributes like count, loss, number of correct predictions, start time, etc. begin_run : Record run start time so when a run is finished, the duration of the run can be calculated. Create a SummaryWriter object to store everything we want to export into Tensor Board during the run. Write the network graph and sample images into the SummaryWriter object. end_run : When run is finished, close the SummaryWriter object and reset the epoch count to 0 (getting ready for next run). begin_epoch : Record epoch start time so epoch duration can be calculated when epoch ends. Reset epoch_loss and epoch_num_correct. end_epoch : This function is where most things happen. When an epoch ends, we'll calculate the epoch duration and the run duration(up to this epoch, not the final run duration unless for the last epoch of the run). We'll calculate the total loss and accuracy for this epoch, then export the loss, accuracy, weights/biases, gradients we recorded into Tensor Board. For ease of tracking within the Jupyter Notebook, we also created an OrderedDict object results and put all our run data(loss, accuracy, run count, epoch count, run duration, epoch duration, all hyperparameters) into it. Then we'll use Pandas to read it in and display it in a neat table format. track_loss, track_num_correct, _get_num_correct : These are utility functions to accumulate the loss, number of correct predictions of each batch so the epoch loss and accuracy can be calculated later. save : Save all run data (a list of results OrderedDict objects for all runs) into csv and json format for further analysis or API access. There is a lot to take in for this RunManager class. Congrats on coming to this far! The hardest part is already behind you. From now on everything will start to come together and make sense. Training Finally, we are ready to do some training! With the help of our RunBuilder and RunManager classes, the training process is a breeze: m = RunManager() # get all runs from params using RunBuilder class for run in RunBuilder.get_runs(params): # if params changes, following line of code should reflect the changes too network = Network() loader = torch.utils.data.DataLoader(train_set, batch_size = run.batch_size) optimizer = optim.Adam(network.parameters(), lr=run.lr) m.begin_run(run, network, loader) for epoch in range(epochs): m.begin_epoch() for batch in loader: images = batch[0] labels = batch[1] preds = network(images) loss = F.cross_entropy(preds, labels) optimizer.zero_grad() loss.backward() optimizer.step() m.track_loss(loss) m.track_num_correct(preds, labels) m.end_epoch() m.end_run() # when all runs are done, save results to files m.save('results') First, we use RunBuilder to create an iterator of hyperparameters, then loop through each hyperparameter combination to carry out our training: for run in RunBuilder.get_runs(params): Then, we create our network object from the Network class defined above. network = Network() . This network objects hold all our weights/biases we need to train. We also need to create a DataLoader object. It is a PyTorch class that holds our training/validation/test dataset, and it will iterate through the dataset and gives us training data in batches equal to the batch_size specied. loader = torch.utils.data.DataLoader(train_set, batch_size = run.batch_size) After that, we'll create an optimizer using torch.optim class. The optim class gets network parameters and learning rate as input and will help us step through the training process and updates the gradients, etc. We'll use Adam as our optimization algorithm here. optimizer = optim.Adam(network.parameters(), lr=run.lr) OK . Now we have our network created, data loader prepared and optimizer chosen. Let's get the training rolling! We will loop through all the epochs we want (3 here) to train, so we wrap everything in an â€˜epoch' loop. We also use the begin_run method of our RunManager class to start tracking run training data. m.begin_run(run, network, loader) for epoch in range(epochs): For each epoch, we'll loop through each batch of images to carry out the training. m.begin_epoch() for batch in loader: images = batch[0] labels = batch[1] preds = network(images) loss = F.cross_entropy(preds, labels) optimizer.zero_grad() loss.backward() optimizer.step() m.track_loss(loss) m.track_num_correct(preds, labels) The above code is where real training happens. We read in the images and labels from the batch, use network class to do the forward propagation (remember the forward method above?) and get the predictions. With predictions, we can calculate the loss of this batch using cross_entropy function. Once the loss is calculated, we reset the gradients (otherwise PyTorch will accumulate the gradients which is not what we want) with .zero_grad(), do one back propagation use loss.backward()method to calculate all the gradients of the weights/biases. Then, we use the optimizer defined above to update the weights/biases. Now that the network is updated for the current batch, we'll calculate the loss and number of correct predictions and accumulate/track them using track_loss and track_num_correct methods of our RunManager class. Once all is finished, we'll save the results in files usingm.save(â€˜results'). The output of the runs in the notebook looks like this: Tensor Board Image from Tensorboard.org Tensor Board is a TensorFlow visualization tool now also supported by PyTorch. We've already taken the efforts to export everything into the â€˜./runs' folder where Tensor Board will be looking into for records to consume. What we need to do now is just to launch the Tensor Board and check. Since I'm running this model on Google Colab, we'll use a service called ngrok to proxy and access our Tensor Board running on Colab virtual machine. Install ngrok first: !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip !unzip ngrok-stable-linux-amd64.zip Then, specify the folder we want to run Tensor Board from and launch the Tensor Board web interface (./runs is the default): LOG_DIR = './runs' get_ipython().system_raw( 'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &' .format(LOG_DIR) ) Launch ngrok proxy: get_ipython().system_raw('./ngrok http 6006 &') Generate an URL so we can access our Tensor Board from within the Jupyter Notebook: ! curl - s http : // localhost : 4040 / api / tunnels | python3 - c \\ \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\" As we can see below, TensorBoard is a very convenient visualization tool for us to get insights into our training and can help greatly with the hyperparameter tuning process. We can easily spot which hyperparameter comp performs the best and then using it to do our real training. Conclusion As you can see, PyTorch as a machine learning framework is flexible, powerful and expressive. You just write Python code. Since the main focus of this article is to showcase how to use PyTorch to build a Convolutional Neural Network and training it in a structured way, I didn't finish the whole training epochs and the accuracy is not optimum. You can try it yourself and see how well the model performs. This article is heavily inspired by deeplizard's PyTorch video series on YouTube . Even most of the code snippets are directly copied from it. I'd like to thank them for the great content and if you feel the need to delve down deeper, feel free to go check it out and subscribe to their channel.","tags":"Machine Learning","url":"build-a-fashion-mnist-cnn-pytorch-style-efb297e22582"},{"title":"How to Build Your Own PyTorch Neural Network Layer from Scratch","text":"This is actually an assignment from Jeremy Howard 's fast.ai course , lesson 5. I've showcased how easy it is to build a Convolutional Neural Networks from scratch using PyTorch. Today, let's try to delve down even deeper and see if we could write our own nn.Linear module. Why waste your time writing your own PyTorch module while it's already been written by the devs over at Facebook? Well, for one, you'll gain a deeper understanding of how all the pieces are put together. By comparing your code with the PyTorch code, you will gain knowledge of why and how these libraries are developed. Also, once you're done, you'll have more confidence in implementing and using all these libraries, knowing how things work. There will be no myth to you. And last but not least, you'll be able to modify/tweak these modules should the situation require. And this is the difference between a noob and a pro. OK , enough of the motivation, let's get to it. Simple MNIST one layer NN as the backdrop First of all, we need some â€˜backdrop' codes to test whether and how well our module performs. Let's build a very simple one-layer neural network to solve the good-old MNIST dataset. The code (running in Jupyter Notebook) snippet below: # We'll use fast.ai to showcase how to build your own 'nn.Linear' module % matplotlib inline from fastai.basics import * import sys # create and download/prepare our MNIST dataset path = Config () . data_path () / 'mnist' path . mkdir ( parents = True ) ! wget http : // deeplearning . net / data / mnist / mnist . pkl . gz - P { path } # Get the images downloaded into data set with gzip . open ( path / 'mnist.pkl.gz' , 'rb' ) as f : (( x_train , y_train ), ( x_valid , y_valid ), _ ) = pickle . load ( f , encoding = 'latin-1' ) # Have a look at the images and shape plt . imshow ( x_train [ 0 ] . reshape (( 28 , 28 )), cmap = \"gray\" ) x_train . shape # convert numpy into PyTorch tensor x_train , y_train , x_valid , y_valid = map ( torch . tensor , ( x_train , y_train , x_valid , y_valid )) n , c = x_train . shape x_train . shape , y_train . min (), y_train . max () # prepare dataset and create fast.ai DataBunch for training bs = 64 train_ds = TensorDataset ( x_train , y_train ) valid_ds = TensorDataset ( x_valid , y_valid ) data = DataBunch . create ( train_ds , valid_ds , bs = bs ) # create a simple MNIST logistic model with only one Linear layer class Mnist_Logistic ( nn . Module ): def __init__ ( self ): super () . __init__ () self . lin = nn . Linear ( 784 , 10 , bias = True ) def forward ( self , xb ): return self . lin ( xb ) model = Mnist_Logistic () lr = 2e-2 loss_func = nn . CrossEntropyLoss () # define update function with weight decay def update ( x , y , lr ): wd = 1e-5 y_hat = model ( x ) # weight decay w2 = 0. for p in model . parameters (): w2 += ( p ** 2 ) . sum () # add to regular loss loss = loss_func ( y_hat , y ) + w2 * wd loss . requres_grad = True loss . backward () with torch . no_grad (): for p in model . parameters (): p . sub_ ( lr * p . grad ) p . grad . zero_ () return loss . item () # iterate through one epoch and plot losses losses = [ update ( x , y , lr ) for x , y in data . train_dl ] plt . plot ( losses ); These codes are quite self-explanatory. We used the fast.ai library for this project. Download the MNIST pickle file and unzip it, transfer it into a PyTorch tensor, then stuff it into a fast.ai DataBunch object for further training. Then we created a simple neural network with only one Linear layer. We also write our own update function instead of using the torch.optim optimizers since we could be writing our own optimizers from scratch as the next step of our PyTorch learning journey. Finally, we iterate through the dataset and plot the losses to see whether and how well it works. First Iteration: Just make it work All PyTorch modules/layers are extended from thetorch.nn.Module. class myLinear ( nn . Module ) : Within the class, we'll need an init dunder function to initialize our linear layer and a forward function to do the forward calculation. Let's look at the init function first. We'll use the PyTorch official document as a guideline to build our module. From the document, an nn.Linear module has the following attributes: So we'll get these three attributes in: def __init__(self, **in_features, out_features, bias=True**): super().__init__() ** self.in_features = in_features self.out_features = out_features self.bias = bias** The class also needs to hold weight and bias parameters so it can be trained. We also initialize those. ** self.weight** = torch.nn.Parameter(torch.randn(out_features, in_features)) ** self.bias** = torch.nn.Parameter(torch.randn(out_features)) Here we used torch.nn.Parameter to set our weight and bias, otherwise, it won't train. Also, note that we used torch.rand n instead of what's described in the document to initialize the parameters. This is not the best way of doing weights initialization, but our purpose is to get it to work first, we'll tweak it in our next iteration. OK , now that the init part is done, let's move on to forward function. This is actually the easy part: def forward(self, input): _, y = input.shape if y != self.in_features: sys.exit(f'Wrong Input Features. Please use tensor with {self.in_features} Input Features') **output = input @ self.weight.t() + self.bias return output** We first get the shape of the input, figure out how many columns are in the input, then check whether the input size match. Then we do the matrix multiplication (Note we did a transpose here to align the weights) and return the results. We can test whether it works by giving it some data: my = myLinear(20,10) a = torch.randn(5,20) my(a) We have a 5x20 input, it goes through our layer and gets a 5x10 output. You should get results like this: OK , now go back to our neural network codes and find the Mnist_Logistic class, change self.lin = nn.Linear(784,10, bias=True) to self.lin = myLinear(784, 10, bias=True). Run the code, you should see something like this plot: As you can see it doesn't converge quite well (around 2.5 loss with one epoch). That's probably because of our poor initialization. Also, we didn't take care of the bias part. Let's fix that in the next iteration. The final code for iteration 1 looks like this: class myLinear ( nn . Module ) : def __init__ ( self , in_features , out_features , bias = True ) : super (). __init__ () self . in_features = in_features self . out_features = out_features self . bias = bias self . weight = torch . nn . Parameter ( torch . randn ( out_features , in_features )) self . bias = torch . nn . Parameter ( torch . randn ( out_features )) def forward ( self , input ) : x , y = input . shape if y != self.in_features : sys.exit ( f 'Wrong Input Features. Please use tensor with {self.in_features} Input Features' ) output = input @ self . weight . t () + self . bias return output Second iteration: Proper weight initialization and bias handling We've handled init and forward, but remember we also have a bias attribute that if False, will not learn additive bias. We have not implemented that yet. Also, we used torch.nn.randn to initialize the weight and bias, which is not optimum. Let's fix this. The updated init function looks like this: def __init__(self, in_features, out_features, bias=True): super().__init__() self.in_features = in_features self.out_features = out_features self.bias = bias **self.weight = torch.nn.Parameter(torch.Tensor(out_features, in_features)) if bias: self.bias = torch.nn.Parameter(torch.Tensor(out_features)) else: self.register_parameter('bias', None)** ** self.reset_parameters()** First of all, when we create the weight and bias parameters, we didn't initialize them as the last iteration. We just allocate a regular Tensor object to it. The actual initialization is done in another function reset_parameters( will explain later ). For bias, we added a condition that if True, do what we did the last iteration, but if False, will use register_parameter(â€˜bias', None) to give it None value. Now for reset_parameter function, it looks like this: def reset_parameters(self): **torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))** if self.bias is not None: **fan_in, _ torch.nn.init._calculate_fan_in_and_fan_out(self.weight) bound = 1 / math.sqrt(fan_in) torch.nn.init.uniform_(self.bias, -bound, bound)** The above code is taken directly from PyTorch source code. What PyTorch did with weight initialization is called kaiming_uniform_. It's from a paper Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification â€” He, K. et al. (2015) . What it actually does is by initializing weight with a normal distribution with mean 0 and variance bound , it avoids the issue of vanishing/exploding gradients issue( though we only have one layer here, when writing the Linear class, we should still keep MLN in mind ). Notice that for self.weight, we actually give the a a value of math.sqrt(5) instead of the math.sqrt(fan_in) , this is explained in this GitHub issue of PyTorch repo for whom might be interested. Also, we can add some extra_repr string to the model: def extra_repr(self): return 'in_features={}, out_features={}, bias={}'.format( self.in_features, self.out_features, self.bias is not None ) The final model looks like this: class myLinear ( nn . Module ) : def __init__ ( self , in_features , out_features , bias = True ) : super (). __init__ () self . in_features = in_features self . out_features = out_features self . bias = bias self . weight = torch . nn . Parameter ( torch . Tensor ( out_features , in_features )) if bias : self.bias = torch . nn . Parameter ( torch . Tensor ( out_features )) else : self . register_parameter ( 'bias' , None ) self . reset_parameters () def reset_parameters ( self ) : torch . nn . init . kaiming_uniform_ ( self . weight , a = math . sqrt ( 5 )) if self . bias is not None : fan_in , _ = torch . nn . init . _calculate_fan_in_and_fan_out ( self . weight ) bound = 1 / math . sqrt ( fan_in ) torch . nn . init . uniform_ ( self . bias , - bound , bound ) def forward ( self , input ) : x , y = input . shape if y != self.in_features : print ( f 'Wrong Input Features. Please use tensor with {self.in_features} Input Features' ) return 0 output = input . matmul ( weight . t ()) if bias is not None : output += bias ret = output return ret def extra_repr ( self ) : return 'in_features={}, out_features={}, bias={}' . format ( self . in_features , self . out_features , self . bias is not None ) Rerun the code, you should be able to see this plot: We can see it converges much faster to a 0.5 loss in one epoch. Conclusion I hope this helps you clear the cloud on these PyTorchnn.modules a bit. It might seem boring and redundant, but sometimes the fastest( and shortest) way is the â€˜boring' way. Once you get to the very bottom of this, the feeling of knowing that there's nothing â€˜more' is priceless. You'll come to the realization that: Underneath PyTorch, there's no trick, no myth, no catch, just rock-solid Python code. Also by writing your own code, then compare it with official source code, you'll be able to see where the difference is and learn from the best in the industry. How cool is that?","tags":"Machine Learning","url":"how-to-build-your-own-pytorch-neural-network-layer-from-scratch-842144d623f6"},{"title":"Another Self-Driving Car Accident, Another AI Development Lesson","text":"Photo from https://blogs.nvidia.com T his accident actually happened about one and a half years ago, it happened on an Uber's self-driving car, and it took one women's life. This is a serious reminder to the AI community that the work being done carry a lot of weights, sometimes other people's life. A Flash Back of What Happened This terrible accident happened on March 19, 2018, late in the night. An Uber self-driving car, running in autonomous mode with a safety driver behind its wheel, hit and killed a woman in Tempe, Arizona. You can find the detailed investigation results here . From the dash-cam and internal driver-seat camera footages, the accident happened on a poorly lit road with a speed limit of 40 mph. The safety driver was watching her cellphone ï¼ˆpossibly watching Hulu) right before the car hit the woman. According to the telemetry obtained by Uber after the crash, the algorithm classified the women as â€˜ unknown object ', then â€˜ vehicle ' and then â€˜ bicycle ' during the process and the indecisiveness led to very late action(order the car to stop 1.3 seconds before the crash) which eventually led to the tragedy. Neither the Lidar or Radar sensor triggered nor the paid safety driver picked up the pedestrian. Either one of the above measures, if worked, could have saved the woman's life. This accident has passed for some time and Uber has already resumed testing their self-driving cars on the road. Yet it might be valuable to contemplate a bit more from a Data Science point of view on what went wrong and what flaws were in Uber's self-driving system that caused this tragedy. Possible Flaws of the Self-Driving System Before diving deep into the potential flaws of a self-driving system, it's worth noting that self-driving car is actually the most-advanced application of AI that's is the closest to AGI (Artificial General Intelligence) . Driving is a very complex and potentially quite dangerous act to begin with. The environment a self-driving car has to deal with could be very complicated that require all kinds of situation awareness: other cars, pedestrians, bikes, traffic signals, signs, weather, road situations, etc. It's true that great progress has been made on artificial intelligence these years, but is it good enough for this task? No matter the answer, all possible issues should be thoroughly addressed and tested, no stone unturned. This leads to the first and most important aspect of the system, the team developing the self-driving car. Applied Artificial Intelligence Development Teams Sometimes Are Under-staffed with Engineers Photo from https://365datascience.com You don't necessarily need to have a master's degree or Ph.D. to do data science work, but the statistics show that the majority of the data scientists in the industry at least have a master's degree. A big part of them even has a Ph.D. This is very well justified since Artificial Intelligence and Data Science are not trivial areas. It requires many years of training in math, computer science and a wide variety of technologies. This has been the consensus of the industry. A consensus so strong, sometimes people forgot other parts of the equally important roles to make a real-life AI project such as self-driving cars successful. Most importantly, engineering . If what required is to prove the performance of an algorithm for some single-purpose task ( like Radiology Image Recognition), you don't need much engineering power. A solid Data Scientist will probably do the job well enough. If developing and deploying a machine learning application on the web to analyze comments sentiment is the task, then you might want to hire more solid developers and DevOps engineers to make sure the application is well structured, carefully coded and easily maintainable. So what if you want to build a self-driving car system that needs to sustain many hours without any incident in the real world? You might want to hire car designers, regulatory specialists, car safety experts, physicists, and some top-notch data scientists to create a diversified team so the task can be properly tackled. For this Uber self-driving car incident, one reason the self-driving car failed to respond quickly is that neither of the Lidar and Radar systems picked up the woman crossing the street. Uber changed from using 7 Lidar sensors to use only one on top of the car, which creates some â€˜blind spot' around the car. What is the reason for that? Are there any other engineering debts that need to be covered for safety reasons? Are there any design flaws in the placement of the sensors? Are there any interference issues in the environment? Does the communication channel between sensors and the central computer work smoothly? This is not to say these are the exact cases, it's just these are the question need to be asked and addressed, and the best type of talents to address these issues are engineers , not data scientists. Small Data Now small data IS a data science issue to address. What is means is to build an efficient model, a large amount of data for each situation would be required to train the model. But sometimes imbalanced data issue is hard and costly to solve. Take the self-driving car as an example. When it comes to safety, what matters most is when things do go wrong. The more data for different accident types are collected, the better it will be to train a model that are robust enough to handle itself in all conditions. But unlike airplanes with the black boxes, car accident data is much harder to gather. Firstly it's hard to â€˜generate' or â€˜create' an accident. Secondly, not all cars are equipped with sensors to gather those data while the accident happens(some more â€˜smart' cars like Tesla probably can, but the majority of the cars are not there yet). As data scientists, it's a consensus that the bottleneck for a high-performance model usually is not the algorithm, but the data. Without enough relevant data about car accidents, it will be very hard for the data scientists to develop a model that can handle those accident types very well. To make a self-driving car system that can drive a car on the street, turn, accelerate/decelerate properly is not the hardest task. The hardest task is creating a model that handles all the accidents well, without enough data. Handle Edge Cases This is actually a more extreme case of the small data issue, but worth single it out. One rule of thumb for safety is to consider all the edge cases that things could go wrong and be prepared for it. This is less of a problem for humans since a human has common sense and a broader situational awareness than any algorithms, so humans are more prepared to handle the edge cases, but algorithms are usually not sophisticated enough, thus need more work. Photo from https://www.chron.com Let's imagine some of those edge cases. Flood on the road: Humans will back off, or choose some flatter grassland to cross the flood, but if cars are only trained on driving on road, it cannot handle this correctly. Very slippery road: Humans will change their driving patterns and handle turns very gently to avoid slipping. Or stop and put the anti-snow chain, AI will be hard to achieve the same level of flexibility. Road with graffiti on it: Human can easily know what's going on and will not make mistake but AI if not trained by road with graffiti on, it might mistake the graffiti with real road guidelines. The list goes on and on. If you can think of other edge cases you encounter from your past driving experience, please leave a response below. The bottom line is, driving in real-world need way more sophisticated system to handle all weird cases and humans are very good at that (thus taking that as guaranteed). While AI needs to train on every case. No shortcut. The ability to come up with those edge cases and design the self-driving system around it will gain robustness and safety scores and possibly gain an edge over the competition. Where to Improve So should self-driving car accidents stop the development of the technology? Of course not! The technology has huge potential in saving a lot of lives. The AI might be biased or not sophisticated enough, but it has one treat that humans don't. They never become emotional, or reckless, or sleepy. Done right, it should out-perform humans on safety in most situations, but obviously it is not there yet. So which parts of the process can be improved? ( I'm not a self-driving car expert myself and just wanted to explore possibilities in this article so take the following with a grain of salts. If you have better ideas, please feel free to leave a response below! ) Testing Process Again, before delving deep into technology, people-related issues need to be tackled first. One thing that was especially surprising about the incident is the car actually HAS a safety driver. The whole thing could have been avoided if the safety driver did her job and not looked at her cellphone and kept her eyes on the road. It's not that hard to do but her failure to do so indirectly costs a life. This has nothing to do with technology but has everything to do with how the self-driving test process can be improved. It's a good start to put a paid safety driver behind the wheel to add another layer of safety for the test, yet humans make mistake. Since the car already has an internal camera monitoring the driver, why not develop an algorithm to monitors her/his behavior and give alerts/scores when her/his eye wonders off the road? Hardware Photo from https://labs.sogeti.com The Lidar/Radar fails to trigger in this accident. What was the reason? Will add more than one sensors work better? Adding more types of sensors? Optimize the position of the sensors? The sensors need to work on all weather conditions. Hot, code, snow, extreme sunburn, windy, etc. If not, have a backup plan. Prepare for the extreme. Software Is the central driving system has a prioritized control system, means some special events triggered on the sensor or image recognition system will cause the car to immediately stop to avoid severe accidents, surpass all other driving control system. ( e.g. hard code assured clear distance ahead ) The prioritized system needs to be carefully designed and adjusted for maximum safety. Algorithm One thing that is very essential for all machine learning models is the validation set . A good validation set defines how well the model generalizes and thus heavily determines the success/failure of a project in real life. This also applies to the self-driving car. What would be a good validation set here? Well, driving a car is not as simple as our classifier problem thus not very clearly defined. This is exactly where the problem is. Should all the self-driving car companies and regulatory bodies team up together and develop a good â€˜test routine' that captures all the extreme situations, edge cases, test scenarios, automatic test software, etc., to effectively serve as the â€˜validation set' for self-driving cars? I think a collateral consensus and efforts here from all players is essential and less explored. Final Thoughts Photo by Ciprian Morar on Unsplash No matter how much progress has been made on self-driving cars, sometimes it felts like just scratching the surface and the size of the iceberg lurks beneath the water remains unknown. Also, the self-driving car accident usually gets high media attention. According to Wired, nearly 40,000 people died in road incidents last year in the US alone, but very few (if any) made headlines the way the Uber incident did. Unfair? No really. This is actually a good thing. Strict and close scrutiny is a good thing to push the limits of how safe the self-driving car can be. Because it's human lives that are on the line. Update: The final result of the investigation is out on Nov 20, 2019. You can refer to this article by The Verge .","tags":"Machine Learning","url":"another-self-driving-car-accident-another-ai-development-lesson-b2ce3dbb4444"},{"title":"How to Gain State-Of-The-Art Result on Tabular Data with Deep Learning and Embedding Layers","text":"Embeddings can be use other than word representations Motivation Tree-based models like Random Forest and XGBoost have become very popular in solving tabular(structured) data problems and gained a lot of tractions in Kaggle competitions lately. It has its very deserving reasons. However, in this article, I want to introduce a different approach from fast.ai's Tabular module leveraging: Deep Learning and Embedding Layers. This is a bit against industry consensus that Deep Learning is more for unstructured data like image, audio or NLP , and usually not suitable for handling tabular data. Yet, the introduction of embedding layers for the categorical data changed this perspective and we'll try to use fast.ai 's tabular module on the Blue Book Bulldozers Competition on Kaggle and see how far this approach can go. You can find the Kaggle Notebook ðŸ“”: here . Loading Data First, let's import the necessary modules. The core one here is fastai.tabular : from fastai import * from fastai.tabular import * Then we'll read the data into a Pandas DataFrame. You can find the specific code in the Kaggle Notebook link on top of this article but for here, I'll only show necessary code snippets to keep things as concise as possible. We will read in the CSV file into train_df and this will be the DataFrame we'll be mainly working on. We will also read in test_df which is the test set. Let's take a brief look at the data we're dealing with: len(train_df), len(test_df) (401125, 12457) Sorting the Training Set This is to create a good validation set. It cannot be emphasized enough how important a good validation set is in making a successful model. Since we are predicting sales price data in the future, we need to make a validation set that all of its data is collected in the â€˜future' of the training set. So we need to sort the training set first, then split the â€˜future' part as the validation set. train_df = train_df.sort_values(by='saledate', ascending=False) train_df = train_df.reset_index(drop=True) Data Pre-Processing The competition's evaluation methods use RMSLE (root mean squared log error). So if we take the log of our prediction, we can just use the good old RMSE as our loss function. It's just easier this way. train_df.SalePrice = np.log(train_df.SalePrice) For Feature Engineering , since we will be using deep learning to tackle the problem and it is very good at feature extraction, we'll only do it on the saledate. This is the advantage of using a Deep Learning approach, it requires way less feature engineering and less dependent on domain knowledge. We'll use the fast.ai's add_datepart function to for adding some more features related to the sale date. # The only feature engineering we do is add some meta-data from the sale date column, using 'add_datepart' function in fast.ai add_datepart(train_df, \"saledate\", drop=False) add_datepart(test_df, \"saledate\", drop=False) What add_datepart does is it takes the saledate column and added a bunch of other columns like day of week, day of month, whether it is the start or end of a month, quarter and year, etc. These added features will offer more insights into the date and are relevant to user purchasing behaviors. For example, at the end of the year, the company will usually run promotions and prices will usually decrease. Let's check whether all these date related features got added into our DataFrame: # check and see whether all date related meta data is added. def display_all(df): with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): display(df) display_all(train_df.tail(10).T) They did get added. Good. Now we need to do some data pre-processing since this DataFrame has quite some missing data and we also want to categorify and normalize the columns. With the fast.ai library, this is rather simple. We just specify the pre-processing methods we want into a Python list, like so: # Defining pre-processing we want for our fast.ai DataBunch procs=[FillMissing, Categorify, Normalize] This variable procs will later be used to create the fast.ai DataBunch for training. Building the Model Let's look at the data types of each column to decide which ones are categorical and which ones are continuous: train_df.dtypes g = train_df.columns.to_series().groupby(train_df.dtypes).groups g Here are the results: Then we'll put all categorical columns into a list cat_vars and all continuous columns into a list cont_vars. These two variables will also be used to construct fast.ai DataBunch. # prepare categorical and continous data columns for building Tabular DataBunch. cat_vars = ['SalesID', 'YearMade', 'MachineID', 'ModelID', 'datasource', 'auctioneerID', 'UsageBand', 'fiModelDesc', 'fiBaseModel', 'fiSecondaryDesc', 'fiModelSeries', 'fiModelDescriptor', 'ProductSize', 'fiProductClassDesc', 'state', 'ProductGroup', 'ProductGroupDesc', 'Drive_System', 'Enclosure', 'Forks', 'Pad_Type', 'Ride_Control', 'Stick', 'Transmission', 'Turbocharged', 'Blade_Extension', 'Blade_Width', 'Enclosure_Type', 'Engine_Horsepower', 'Hydraulics', 'Pushblock', 'Ripper', 'Scarifier', 'Tip_Control', 'Tire_Size', 'Coupler', 'Coupler_System', 'Grouser_Tracks', 'Hydraulics_Flow', 'Track_Type', 'Undercarriage_Pad_Width', 'Stick_Length', 'Thumb', 'Pattern_Changer', 'Grouser_Type', 'Backhoe_Mounting', 'Blade_Type', 'Travel_Controls', 'Differential_Type', 'Steering_Controls', 'saleYear', 'saleMonth', 'saleWeek', 'saleDay', 'saleDayofweek', 'saleDayofyear', 'saleIs_month_end', 'saleIs_month_start', 'saleIs_quarter_end', 'saleIs_quarter_start', 'saleIs_year_end', 'saleIs_year_start' ] cont_vars = ['MachineHoursCurrentMeter', 'saleElapsed'] We'll create another DataFrame df to feed into the DataBunch. We also specify the dependent variable as dep_var . # rearrange training set before feed into the databunch dep_var = 'SalePrice' df = train_df[cat_vars + cont_vars + [dep_var,'saledate']].copy() Now is the time to create our validation set. We do this by cutting out a block of the most recent entries from the training set. How big the block should be? Well, the same size as the test set. Let's see the code: # Look at the time period of test set, make sure it's more recent test_df['saledate'].min(), test_df['saledate'].max() # Calculate where we should cut the validation set. We pick the most recent 'n' records in training set where n is the number of entries in test set. cut = train_df['saledate'][(train_df['saledate'] == train_df['saledate'][len(test_df)])].index.max() cut 12621 # specify the valid_idx variable as the cut out range. valid_idx = range(cut) We first look at the time period of the test set and make sure it is more recent than all our training set. Then we calculate how many records we need to cut out. Finally, let's construct our DataBunch for training using fast.ai's datablock API : # Use fast.ai datablock api to put our training data into the DataBunch, getting ready for training data = (TabularList.from_df(df, path=path, cat_names=cat_vars, cont_names=cont_vars, procs=procs) .split_by_idx(valid_idx) .label_from_df(cols=dep_var, label_cls=FloatList) .databunch()) Building the Model We will fire up a fast.ai tabular.learner from the DataBunch we just created. We want to limit the price range for our prediction to be within the history sale price range, so we need to calculate the y_range. Note that we multiplied the maximum of SalePrice by 1.2 so when we apply sigmoid, the upper limit will also be covered. This is a small trick to squeeze a bit more performance out of the model. max_y = np.max(train_df['SalePrice'])*1.2 y_range = torch.tensor([0, max_y], device=defaults.device) y_range tensor([ 0.0000, 14.2363], device='cuda:0') Now we can create our learner: # Create our tabular learner. The dense layer is 1000 and 500 two layer NN. We used dropout, hai learn = tabular_learner(data, layers=[1000,500], ps=[0.001,0.01], emb_drop=0.04, y_range=y_range, metrics=rmse) The single most important thing about fast.ai tabular_learner is the use of embedding layers for categorical data. This is the â€˜ secret sauce ' that enables Deep Learning to be competitive in handling tabular data. With one embedding layer for each categorical variable, we introduced good interaction for the categorical variables and leverage Deep Learning's biggest strength: Automatic Feature Extraction. We also used Drop Out for both the dense layers and embedding layers for better regularization. The metrics of the learner is RMSE since we've already taken the log of SalePrice. Let's look at the model. TabularModel( (embeds): ModuleList( (0): Embedding(388505, 600) (1): Embedding(72, 18) (2): Embedding(331868, 600) (3): Embedding(5155, 192) ... (60): Embedding(3, 3) (61): Embedding(2, 2) (62): Embedding(3, 3) ) (emb_drop): Dropout(p=0.04, inplace=False) (bn_cont): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (layers): Sequential( (0): Linear(in_features=2102, out_features=1000, bias=True) (1): ReLU(inplace=True) (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (3): Dropout(p=0.001, inplace=False) (4): Linear(in_features=1000, out_features=500, bias=True) (5): ReLU(inplace=True) (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (7): Dropout(p=0.01, inplace=False) (8): Linear(in_features=500, out_features=1, bias=True) ) ) As can be seen from the above, we have embedding layers for categorical columns, then followed by a drop out layer. We have a batch norm layer for the continuous columns, then we concatenate all of them (categorical embeddings + continuous variables) together and throw them into two fully connected layers with 1000 and 500 nodes, with Relu, BatchNorm, and Dropout in between. Quite standard stuff. Now that we have the model, let's use fast.ai's learning rate finder to find a good learning rate: learn.lr_find() learn.recorder.plot() We'll pick the learning rate at the end of the biggest learning rate curve slope: le-02 Let's do some training using fast.ai's One-Cycle Training approach. Note that we added some weight decay (0.2) for regularization. learn.fit_one_cycle(2, 1e-2, wd=0.2) We can train some more cycles with smaller learning rate: learn.fit_one_cycle(5, 3e-4, wd=0.2) We've reached a score of 0.223 on our validation set. Since the competition is not accepting submissions, we can only look at the leaderboard to get a rough idea of how well this model performs: The top place is 0.229 . Compare to this model's 0.223 . We don't know how well it works on the test set but overall I think the result we got isn't bad at all. A Couple of More Words on Embedding Layers What makes everything click here is the embedding layers. Embedding is just a fancy word of saying mapping something to a vector. Like the word embedding that is getting more popular in NLP , it means using a vector (the size is arbitrary though, depending on tasks) to represent words, and those vectors are weights and can be trained via back-prop. Similarly, for our case, we used embeddings on our categorical variables. Each column gets an embedding matrix that can be trained. And each unique column value gets a specific vector mapped to it. The beautiful thing about this is: with embedding, we can now develop â€˜semantics' to the variable , â€˜semantics' in the form of weights that matters to our sale price and can be extracted and trained via our deep neural network. The model will have the â€˜ depth ' it needs to fit a big data set well. But don't take my words for it, or just look at the results of my humble little project. In a more glory case, there was this paper by the folks who came 3rd in a Kaggle competition for something called Rossman (prediction future sales). Among the top teams in the leaderboard, everyone else used some kind of heavy feature engineering, but by using embedding layers, they managed to score 3rd place with way less feature engineering. What's more interesting is, with embedding layers, you can actually visualize the variable projection in the embedding matrix space. Take the Rossman project as an example. They took a two-dimensional projection of the embedding matrix for the German states. And if you circle some states on the embedding space and same states on the actual map. You'll find out that they are scarily similar. The embedding layer actually discovered geography.","tags":"Machine Learning","url":"how-to-gain-state-of-the-art-result-on-tabular-data-with-deep-learning-and-embedding-layers-d1eb6b83c52c"},{"title":"No Human Can Beat AlphaGo, and It's a Good Thing","text":"Photo from Netflix South Korean Go master Lee Se-Dol recently announced his retirement from professional Go competition. The reason? He felt that no matter how hard he tries, he will never beat AI Go players like AlphaGo. It is a rather sad decision and development of his historical defeat in competition with Google DeepMind's AlphaGo. It gives the whole thing a more dramatic tone than it should be. However, the defeat of human Go players to AI is neither the end of the world for the Go game nor for the human players. Quite the opposite, I believe this could mean a brand new chapter for the Go game, and an opportunity for us to go back to the original purpose Go game is invented for. AlphaGo vs. Lee Se-Dol Photo from androidheadlines.com For those not familiar with what happened, according to Wikipedia : AlphaGo versus Lee Sedol , also known as the Google DeepMind Challenge Match , was a five-game Go match between 18-time world champion Lee Sedol and AlphaGo , a computer Go program developed by Google DeepMind , played in Seoul , South Korea between the 9th and 15th of March 2016. AlphaGo won all but the fourth game; [1] all games were won by resignation. [2] The match has been compared with the historic chess match between Deep Blue and Garry Kasparov in 1997. â€” Wikipedia Barring the seemingly dramatic defeat, Lee Se-Dol actually is the only human player actually defeated AlphaGo, even it was only one match. But this defeat deeply hurt the human Go master's confidence, in an interview with Yonhap News Agency in Seoul, he said: \"With the debut of AI in Go games, I've realized that I'm not at the top even if I become the number one through frantic efforts,\" said Lee. \"Even if I become the number one, there is an entity that cannot be defeated,\" To commemorate his retirement, he plans to get into a competition with another AI go player HanDol developed by South Korea's NHN Entertainment Corp that has already defeated 5 of South Korean's top Go players. So what to make of all these? Does this mean Go human players are worthless anymore because AI can already do a much better job? Is Go game not worth playing since a human can never beat a machine? Does this suggest the beginning of the end for human intelligence and the rise for AI to rule them all? The answer is a resounding NO , but to ask why, we need to go back to the original of the Go game. The Origin Of Go Game Go is a very ancient game. It's said that Emperor Yao(å°§) of ancient China invented the Go game to teach his naughty son. His son DanZhu(ä¸¹æœ±) was very combative, yet refused to read any book his parents throw his way. How do you talk sense into this kind of kid? Well, entice him to play games of course! It turns out, DanZhu enjoyed the Go game very much. The competitive nature of the game plays into his combative personality, yet to win consistently, he needs to be more patient, smart and strategic. So he gradually learned all these and his parents were much happier. It's a rather old and simplified story, but it tells one thing: Go is not created to see who is the best, it is created for educational purposes. I've learned to play Go when I was 12 years old and I still remembered our teacher telling us: \"To win the game of Go, you need to be good at calculating the current move, but also thinking long term. You need to accumulate small advantages yet never forget about the big picture. You need to be brave enough to fight the good fight when needed, yet never too reckless if you know you can't win. When you are behind, you need to have the patience to wait for the best opportunity to strike. When you are ahead, it's even harder to not get complacent and make mistakes. Doing all these, and you can start to compete in Go game\" The game has so much depth and such a high â€˜skill cap' that no one can claim he has mastered it. It's said that's the game played by people in heaven. Myths aside, Go as a game can definitely shape a person's character, sharpen his mind and strengthen his will. All of these are way more valuable than winning itself. Go is a Way to Communicate There is an old saying in Chinese that goes \"a person's Go game style echos his personality(æ£‹å¦‚å…¶äºº)\" . It's easy to hide one's true nature under well-organized words, but it's much harder to hide when you're in a fiercely played game. Go game used to be part of the interview process when ancient Chinese emperors hire his officers. It's also a way to communicate. Since it's very popular in ancient China, anyone knows how to read knows how to play Go. Engaging in a healthy competitive Go game is the fastest way to know another person. From your opponent's playstyle, you'll quickly know what kind of person he is. Is he conservative and not taking any risks? Is he used to follow some textbook moves or like to think out-of-the-box? After several games, no matter who wins or loses, you'll know. Human Beaten by AI on Go, Not a Big Deal So the million-dollar question is: Does human beaten by AI on Go game change any of the above traits of the game? The answer is obviously no. People can still use Go to cultivate their brain and will. Making friends and finding respect for opponents. It is still a fun game with tons of depth. Winning is not all that important. There is a saying in Go community that goes \"A game with a heavy reward can never generate beautiful and brilliant matches(äº‰æ£‹æ— åå±€)\". This means if people care too much about winning, their creativity will get surpassed and they will all play safe, resulting in very boring games. Yes, humans are now not as good as winning the Go game as AI , but what's the big deal? There are things humans do better and there are things computers do better. Actually, there are plenty of things computers do better than humans. Calculating numbers, process information, not making mistakes. I seldom see people feel bad and say \" OMG , I'm not gonna do math anymore because my computer is better than me! \" People just say, \" Ok, the computer is better than us on computing numbers. Great. Let's use it to do the dirty work and let's focus on inventing new and more powerful algorithms \". Right? In fact, this is the exact reason that leads to the inventing of AI and eventually leads to the creation of AlphaGo. Go game is no different. If we stop the mentality of â€˜ AI vs Human ' and embrace the idea of â€˜ AI works for Human ', then great new possibilities will emerge. The Future of Go with AI will be Bright Ke Jie, Photo from Sohu.com The Lee Se-dol story might be a bit sad, but there is another story related to AlphaGo that is totally in a different tone. Chinese young Go master who was ranked #1 in China professional competition, Ke Jie , also had a three matches game with AlphaGo, and he lost miserably. All three matches were lost and he stood no chance at all. What his reaction? He was obviously in awe and paid respect to his formidable machine opponent, but at the same time, he is intrigued, very intrigued . He said playing with AlphaGo felt like opening a door to another totally different world. The way AlphaGo played the game is not like anything he encountered before, and he was already a seasoned player and won tons of awards in China and abroad. He then researched thoroughly the three matches he lost, trying to learn from it, and grow out of it. And you know what happened afterward? He had a mind-blowing 12-win streak on his professional competitions, beating every and single human opponent stand on his way. Different mentality leads to different results. The similar losing games yet different players and different outcomes make us think. Maybe losing to AI is not such a bad thing. We human is always best at learning from past mistakes and getting better. Adapt and grow, learn and create, that's something human can definitely do better than the computer, and only the sky is the limit. The Sky is the Limit Photo by Dominik SchrÃ¶der on Unsplash Once we switched our mentality, there are plenty of things Go player can do. For one, Maybe Mr. Lee Se-dol can join an AI team and try to help develop a new algorithm that can beat AlphaGo. He already planned to play the â€˜HanDol' AI , and maybe in the future, he can start an â€˜ AI Go Game League' and get his revenge by beating AlphaGo with a new AI player he helped develop named â€˜Se-dol Go'. Or maybe Mr. Ke Jie can leverage what he learned from AlphaGo and help develop an AI -based Go training system to improve human player's game. Use AI as a test tool to explore and verify. Maybe the AI community and Go community should work together to develop different styled AI Go players and have them play in a league, we might be able to see a lot of beautiful games and advance Go game theory. When AI and Humans work together, only the sky is the limit.","tags":"Machine Learning","url":"no-human-can-beat-alphago-so-what-3401b40fa0f0"},{"title":"5 Things I Learned from Google's New ML -Powered Recorder App","text":"There are tons of audio recording apps in the app store, but you know things will be a bit different if Google developed a brand new one. Google recently released a new â€˜ Recorder ' app that is powered by its state-of-the-art Machine Learning algorithm that can transcribe what it hears with impressive precision in real-time. This is not the first time Google tried to bless its product with some AI â€˜superpower'. Some of their prior attempts failed (I'm talking to you Google Clips !) and some had quite formidable success, for example, Google's Pixel phone camera app. With the camera hardware spec a little below industry mainstream, Google's Pixel flagship phone managed to pull off as one of the best smartphone cameras on the market thanks to its Machine Learning algorithms for image post-processing. The â€˜Recorder' app is yet another attempt by Google to spice up competition using AI , this time on audio. After digging deeper into what the app can do differently and how AI played a core role in it, I found some very interesting insights on how Google handles app, AI and user experience that could shed some light on future app development in the AI -era. What is Google Recorder? You can refer to the following short YouTube video on what Recorder does. In short, you can use it to do real-time transcription, search recorded audio by keywords, automatically generate tags or segment the audio into different categories like music, speech, etc. I've been using it for more than a week and found it to be useful, slick and pleasant to use. Recording audio is not a complicated task, but the AI part makes it even easier. I can see this little app makes a big difference for students and people attending meetings regularly. #1 Adoption of Edge-First Model Design Image from WishDesk We all heard of the term â€˜Mobile-First Design'. When companies develop their applications, they will design and optimize their app based on mobile experience first, then to other platforms like desktop or web. I think the same idea can also be applied to AI -powered application design, hence â€˜Edge-First Design'. Usually, Machine Learning based applications run on the cloud, this is due to the heavy computation requirements for most state-of-the-art ML models. For enterprise applications, this approach is fine since the hardware is hardly a real issue. But if a company wants to build impactful AI -based apps for the consumers, then a cloud-based system often won't cut it. Running AI -based apps from the cloud is not only slow but also has serious privacy concerns. Also to the normal consumer, they are used to the snappiness modern mobile apps offers. They can care less whether your app is based on some SOTA models or not, if the experience cannot match the high standard they get used to, boosted by many years of modern smartphone hardware/software development. So putting the AI on the â€˜Edge', e.g. user's phone, tablet, smart home devices will be a better way to success. Image from Lann Google Recorder app did a great job on this. It uses a new model called â€˜ ** RNN transducer( RNN -T) **' that is compact enough to reside on the phone while powerful enough to do real-time transcription. Instead of the traditional â€˜pipeline' approach, the RNN -T model uses a single neural network, end-to-end approach which is growingly more popular to solve complicated problems. Until recently, we've seen a lot of research progress being made on increasing the prediction performance by using bigger and bigger models, yet the opposite direction is equally important: Using as compact a model as possible to achieve similar performance so the model can be put on the edge. I expect more research to be done in this area when machine learning matures in the coming years. #2 Use Different Technology Stack for Performance Another interesting development is the introduction of Swift for TensorFlow . Created by the creator of Swift programming language, Chris Lattner . It uses open-source Swift language with TensorFlow and promises both fast development time like Python and high-level performance like C++. Fast.ai has a great introductory course on it. With ML moving more and more from research labs to commercial applications, the performance of ML models will play a much bigger role and Swift for TensorFlow has great potential on that. According to the founder of fast.ai , Jeremy Howard: What's New in Machine Learning - WWDC 2019 - Videos - Apple Developer Core ML 3 has been greatly expanded to enable even more amazing, on-device machine learning capabilities in your appâ€¦ developer.apple.com \"Swift can match the performance of hand-tuned assembly code from numerical library vendors. Swift for TensorFlow is the first serious effort I've seen to incorporate differentiable programming deep into the heart of a widely used language that is designed from the ground up for performance\" #3 Privacy Matters Photo by Matthew Henry on Unsplash One of the biggest concerns for AI applications is privacy. For AI to really show value, it has to know a lot about the user, often times their personal life details people don't feel comfortable sharing. Take audio recording as an example, you might want to record your family meeting discussing your next Christmas plan but don't want it to be transferred onto the cloud and get 10 Christmas travel agents calling you to sell their products. This gives â€˜offline' ML apps an advantage. Since the model is deployed locally on the edge and no data need to be transferred to the cloud, the user can feel assured that their privacy can be protected. The Recorder app runs all the models on-device and makes it a bit less reluctance for people to adopt it. #4 User Experience Design is Still the Key The Recorder app has a very slick and elegant UI . It's a simple app with minimal clutters. You can easily start/pause your recording, toggle between â€˜Audio' or â€˜Transcript' mode to check your recorded content and getting suggestions on tags from the content recorded. All works without friction. During recording, the app will automatically categorize sections of audio as â€˜Speech', â€˜Music', â€˜Whistling' â€¦ etc. and color code them accordingly. When playback your recorded audio, you can see each word get highlighted when being spoken in the transcript mode and you can search through the transcripts use the keyword you want. Very intuitive. What I'm trying to say is: User experience design will make or break a great AI model. Only when working seamlessly with other parts of the app can an AI feature delivers its value to the end-user. A model that can address the user's paint-point with high performance is only a start, not the end. AI should serve silently behind the scenes rather take the center stage. #5 Responsiveness Come with a Price In the mobile world, companies strive to offer more responsiveness. Consumers nowadays are very impatient and the last thing they want is to wait. Snappy experience means the user can focus on the content they want or the tasks at hand. But responsiveness on mobile devices is not easy to come by. Computing power, screen size, system resources are all very limited compare to desktop or cloud. To achieve the best responsiveness, more thoughts and research need to be put into the design and development of the app. This includes better use of CPU / GPU , memory optimization, choose fast programming languages for the implementation and reduce dependence on back-end servers. The Machine Learning industry has made great progress on research for the past few years, yet to have more impact on people's day-to-day life, more investment and work has to be done on the engineering side. And a switch from research to engineering is a sign of matureness for new technology. The Right Way of Developing AI Applications? Image from Overwatch People have this fantasy of scary AI taking over humanity for many years. Movies, novels, TV Shows all painted a very dramatic future of AI for mankind. To counter this public (biased?) impression on AI , special cautions need to be taken. It's beneficial to adopt an â€˜ AI exist as a tool to help human' mentality instead of an â€˜ AI vs Mankind' one. AI can do a lot of things, but rather than develop AI apps that can â€˜replace' humans, it's better to have AI that exists to help humans perform their tasks easier and faster. Like the Recorder app to help taking notes, image recognition systems to help the doctor diagnose better, augment reality app to help people better navigate the neighborhood, etc. A quiet, friendly, yet powerful AI diligently working behind the scenes to help people do whatever they do better is so much more comfortable and approachable for people, compare to a robotic killing machine in a SciFi movie.","tags":"Machine Learning","url":"5-things-i-learned-from-googles-new-ml-powered-recorder-app-6c9616a05b78"},{"title":"What You Need to Know About Netflix's â€˜Jupyter Killer': Polynote ðŸ“–","text":"Today, Netflix open-sourced Polynote , the internal notebook they developed, to the public. It's not rare these days that big tech companies open sources their internal tools or services, then got popular and adopted by the industry. Amazon AWS , Facebook's React.js, etc. are two of them. It makes sense. These big tech companies have the best engineers in the industry and more often than not they are facing the biggest challenges that will drive the development of great tools. Netflix's Polynote could be another one of those great tools and the data science/machine learning industry does need better tools in terms of how to write code, experiment algorithms and visualize data. Here are several things you need to know about this new tool. I'll try to keep this succinct and to the point so you can quickly read through it and be knowledgeable about the pros and cons of this new choice of our development/research environment. Polynote is more like a simple version of IDE rather than nicer version of a REPL auto-completion, error indication, better text editor, LaTex support Polynote put some emphasis on making the notebook work more like an IDE or code editors like VS Code. It supports better auto-completion, linting, rich text editor, and LaTex. This might be a bit of an overstatement, but that's the direction it is going. You can say better syntax highlighting and better auto-completion are trivial, but these little quality-of-life improvements could go a long way and make you focus more on the real tasks. BTW , most of the editing capabilities are powered by the Monaco editor which powers the experience of Visual Studio Code, showing potential to be even better. Multi-language Support Currently, it only supports Python, Scala, and SQL . You might argue that Jupyter Notebook also supports Python, R, and Julia. But how they support multi-languages is different. For Jupyter Notebook, you can only choose one language for one notebook. Whereas Polynote can support all these languages working seamlessly in one notebook. It achieves this by sharing variables between cells so different language cells can work under same context. Needless to say, this has the potential to be very powerful. With more languages it supports, a skilled data scientist can use the best language for the right tasks. It increased the skill-cap yet also raise the performance bar. Data Visualization and Data Awareness In Polynote, data visualization is built-in. It means developers won't need to write any code to visualize their data, they can just use a GUI interface and see the data the way they want. Also, developers won't need to type in any code in order to see the value of the variable, you can just use the GUI . When code is running, there is also a progress window at the right side of the screen so you always have an idea of which part of the code is currently running. These will all add up to better data intuition. Configuration and dependency management built-in Another quality-of-life improvement. Gone of the days you have to run things like: ! pip install packages You can simply specify what dependencies you need for your code to run smoothly and BOOM , Polynote will set it up for you. This will result in less clutter in code. How good is that! Reproducible Code Simply put, Polynote is not using the good old REPL model for code execution. It uses its own code interpreter instead. The biggest difference is: for Jupyter Notebook that uses REPL , you can safely execute cells not in the order they are written. You can execute cell 3, then cell 2, then cell 1. It's all up to you. This brings flexibility but decreases the sharability of the notebook. Polynote handles cell execution differently: By keeping track of the variables defined in each cell, Polynote constructs the input state for a given cell based on the cells that have run above it. Making the position of a cell important in its execution semantics enforces the principle of least surprise, allowing users to read the notebook from top to bottom. It seems to be more like you are writing a script instead of a notebook. You take more notice of making sure things are in order when writing it. But you get the benefit of consistent code results and better sharability. See the animation below: Conclusion We'll see how well the industry will adopt Polynote but definitely it shows potential and making some sound decisions. One question is whether the big cloud platforms like GCP , AWS or Azure will adopt it. This is quite important because, without the support of these cloud platforms, people rely on them to do research/experiment won't have access to Polynote and thus won't use it. Found this article useful? Follow me ( Michael Li ) on Medium or you can find me on Twitter @lymenlee or my blog site wayofnumbers.com . You could also check out my most popular articles below! \"This is CS50 \": A Pleasant Way to Kick Off Your Data Science Education Why CS50 is especially good to solidify your software engineering foundation towardsdatascience.com Two Sides of the Same Coin: Jeremy Howard's fast.ai vs Andrew Ng's deeplearning.ai How Not to â€˜Overfit' Your AI Learning by Taking Both fast.ai and deeplearning.ai courses towardsdatascience.com I finished Andrew Ng's Machine Learning Course and I Felt Great! The good, the bad, and the beautiful medium.com","tags":"Machine Learning","url":"what-you-need-to-know-about-netflixs-jupyter-killer-polynote"},{"title":"ðŸ’ŽHidden Gem: A Great PyTorch YouTube Tutorial Series by deeplizard","text":"Why PyTorchðŸ”¥ ? According to Wikipedia : PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing. It is primarily developed by Facebook's artificial intelligence research group. Facebook recently released the much anticipated 1.3 version at PyTorch DevCon 2019, adding support for Google TPU , PyTorch Mobile and more. Also, **The Gradient ** release a report on the current state of machine learning frameworks , stating that more and more researchers favor PyTorch to TensorFlow as their main framework. Another good reason if you are leaning/using the fast.ai library, it is based on PyTorch because it: \" use all of the flexibility and capability of regular python code to build and train neural networks \", and \" we were able to tackle a much wider range of problems \" To me, it feels more natural working with PyTorch, being Pythonic and all. A better analogy is that developing machine learning models using TensorFlow is like wearing heavy armor: It's powerful but very clunky. PyTorch gives you all the freedom and a smooth flow of actions. Photo from GHYFY Introducing deeplizard ðŸŠ Photo from deeplizard vlog â€” YouTube But the flexibility of PyTorch comes with a price. Getting into PyTorch isn't easy. More freedom means you have more factors that need considering and more nuances to balance. That's why a great tutorial will help you greatly smooth out the learning curve. There are many resources out there. Jeremy Howard 's wonderful tutorial on the PyTorch website is a good starting point. Yet if you want to delve down even deeper, I recommend you check out deeplizard's PyTorch Tutorial Series on YouTube. It's to-the-point (respect viewer's time by being concise), relevant (based on PyTorch 1.1) and most importantly, fun to watch. It uses a lot of neat animations/graphic editing techniques to make the video engaging and pleasant to watch. The production quality is very impressive. The â€˜showmanship' Makes deeplizard's Tutorial Engaging ðŸŽ­ Chris is really great at explaining a complicated concept in a very concise and clear way with the help of great animations and versatile form of short video clips. Their videos will keep you occupied from start to finish. Couple of things they really stand out: Great use of animations, illustrations, and overall great aesthetic deep lizard uses animation to explain how convolution works Some YouTube videos offer exceptional content, but the aesthetic is not there, especially for the screencast videos. Viewers usually have to stare at one or two windows most of the time, which is visually boring and easy to get tired. Not for deeplizard though. The team is very good at creating subtle yet aesthetically pleasing animations. Even for backdrop images, which are usually static, they created some zoom in/zoom out effect to make it less boring. The motion is subtle enough so there is no concern of motion sickness. Plenty of eye-candy ðŸ¬ I'd say. Embed relevant short clips of TED talks, keynotes, and other educator's videos Image from deeplizard @ YouTube Embedding short video clips of relevant yet different styled content is another way to make the learning engaging. Our brain gets tired quickly if only one part gets stimulated. Looking at the same scene or listening to the same person talking, people won't keep their focus long enough. At least can't do it without some mental efforts. Embedding a variety of styled video clips solved the problem. Different parts of your brain get excited and you can keep the learning flow effortlessly. Male, female and a special Sci-Fi style â€˜ AI ' character called â€˜deeplizard' voiceover to explain different type of problems, spice the content up R2D2 and C- CPO from theverge.com Other than the two lovely YouTubers of the channel Chris and Mandy , there is a virtual â€˜ AI creature' they created as a third voice-over. It sounds like C- 3PO in Star War movies, but female. It guides the viewer through the debugging process or asks some thought-provoking cryptic questions, etc. If you are into the Sci-Fi vibe, you'll totally love it. Again, less boring, more engaging. Good Extended Content on Membership Website Besides the videos itself, they also have a membership website where you can find extra learning materials: Blogs, Quiz, Code snippets, and other extra resources. It's behind a paywall but I'd say it's a good supplement of the video. Conclusion The main takeaway? I felt that they've made PyTorch seems quite straightforward and easy to understand. I felt like I can totally do my ML project on PyTorch going forward. Though I've only finished their PyTorch tutorials, I'd guess their other contents are also good too. Feel free to explore a bit more and let me know your experience below. If you are learning fast.ai course, since it's built on top of PyTorch, sooner or later you'll have to beef up your PyTorch knowledge and deeplizard's tutorial is a good place to start. Link here: Found this article useful? Follow me ( Michael Li ) on Medium or you can find me on Twitter @lymenlee or my blog site wayofnumbers.com . You could also check out my most popular articles below! \"This is CS50 \": A Pleasant Way to Kick Off Your Data Science Education Two Sides of the Same Coin: Jeremy Howard's fast.ai vs Andrew Ng's deeplearning.ai I finished Andrew Ng's Machine Learning Course and I Felt Great!","tags":"Machine Learning","url":"hidden-gem-a-great-pytorch-youtube-tutorial-series-by-deeplizard"},{"title":"\"This is CS50 \": A Pleasant Way to Kick Off Your Data Science Education","text":"CS50 professor David Malan teaches over 800 students on CS5 â€” from Youtube So You Want to Get Into Data Science Congratulations! Data Science is a career that's hottest, hardest, most challenging, most rewarding, and full of top-notch minds. Your journey is bound to be full of fun, challenges, enlightenments, and achievements (big or small). New papers are published daily or even hourly. New techniques and experiments are developed regularly. New ways of thinking become the new norm. And what seems magical before, are proven feasible. But You Don't Know Where to Start Photo by Ben White on Unsplash But getting into Data Science is not easy. Far from it. The learning curve is brutal. There is so much to learn: Linear Algebra, Calculus, Statistics, Python, SQL , Machine Learning, Algorithm, Optimization, Data Wrangling, Data Visualization, Software Engineering, DevOps, â€¦ The list goes on and on. Some people may have some background in math or statistics, which will definitely help. Yet you still need a solid foundation for software engineering to be efficient and be successful in your career. But this is not a problem, you say. After all, we live in an era of booming online education. There are plenty of courses paid and free we can choose. True, but this is precisely where the problem is . The biggest challenge for self-education these days is not lack of education resources, but hard to find the best or most relevant ones. Enter CS50 . If You are Only Allowed to Take One CS Course, Take CS50 . What is CS50 ? It is the introductory course on computer science taught at Harvard University by Professor David J. Malan . It is the largest class at Harvard with 800 students, 102 staff, and a professional production team. It offers both an on-campus and an online course. I've taken the online one, but it's already THE best computer science course I came across, period. Let me tell you why: The learning curve is so well designed, and it's like watching a great suspense movie The CS50 staff has the capability of knowing precisely what you do and do not know before each lecture (in that they have zero expert blindness ). So the speech will not mention anything you are not familiar with. It smoothly guides you through key concepts of computer science and makes it seem obvious. It raises questions from time to time and later addresses them with a more in-depth explanation of the concepts. You'll have plenty of â€˜a-ha' moments, and it almost felt like watching a suspense movie. Covers core and essential fundamentals of computer science, and leave plenty of room for you to dig deeper The course covers most of the critical computer science elements: C, Python, Data Structures, Algorithms, Software Engineering, Resource Management, Web Development, etc. It delves down deep enough so you can understand all the essential concepts while also know where to look if you want to dig deeper. Orchestrate variety of ways to teach you challenging/boring concept, never felt boring What is an array? Let's find out! â€” thecrimson.com CS50 has many ways to teach and keep you engaged. You'll play a game to understand different sorting algorithms, receive a rubber duck to experience the famous Rubber Duck Debugging , watch experiments of â€˜array of lights ðŸš¥' to learn data structure, even eat a delicious breakfast ðŸž while exploring the idea of pseudo-code. (One of my favorites is where David J. Malan uses a Yellowpage phonebook to explain binary search and tears down half of the book and throw it away. A definitive moment in CS50 indeed. ) Interactive, fun and engaging, the time just flew by, and you'll be amazed what you can do once the course is over The learning experience is so fun you'll feel the time fly by without noticing it. Some of the problem set it gives are quite challenging, yet not impossible. And you'll feel so proud of yourself once you cracked it. You'll probably fall in love with the joy of problem-solving. If you are stuck, there is an online community on almost every social network platform (Twitter, Reddit, Stack Exchange, Facebook, etc.) where you can get help. Out-of-class activities get you familiar with the â€˜developer culture,' which is essential for your future career. Puzzle days, office hours, CS 50 Fairs, the final project â€˜All-nighter' hackathon (free breakfast at IHOP if you stay up all night), lots of activities designed to get you familiar with the â€˜developer culture' and better prepare you for the software engineering world. State-of-the-art course software to get you started How great is a computer science course if they don't use the software tools they developed themselves? Over the years, CS50 's staff has developed a series of tools/software to help the students write code , submit homework , check their code quality/syntax , tidy up code styles , and even generate color-coded code documentation in PDF form ! These are all neat and useful â€˜ training-wheels ' as David J. Malan puts it and will help you get up to speed. But, please don't just take my words for it, see what YouTube CEO Susan D. Wojcicki said about her experience: And It Is Great for Data Science Too Being a great course, CS50 is also very relevant to Data Science. It helps you lay a solid foundation of software engineering for your future career: It teaches you C. More importantly, through C, you understand the fundamentals of computer like how memory works, what is a pointer, data structures, etc. If you can write C, then you can quickly learn to write in C++. C++ is the de facto low-level, high-performance language used for data science libraries like Numpy, Pandas, Sk-Learn, etc. It teaches Python, which is the primary high-level language for Machine Learning and Data Science. It teaches SQL , which is the most widely used language in Data Science. It also teaches web programming, useful when you try to deploy your model to production. So essentially nothing taught in the course is not somewhat useful to you, and the foundation it helps you build will go a long way. CS50 and Beyond! Once you finished the course, you'll be more knowledgable and confident to continue your Data Science journey, and I'll point you to a couple of possible directions from here: CS50 's Web Programming with Python and JavaScript Teaches you the most relevant and progressive web programming tools like CSS , Javascripts, React, Flask/Django, by the talented TF Brian Yu . Link here . **Jeremy Howard 's Fast.ai course to Start a â€˜Top-down' Approach for ML ** Fast.ai is fantastic and unique. It enables you to build state-of-the-art deep learning models within the first lesson with less than ten lines of code. Then it delves down deeper and deeper on the how and why. The only prerequisite is one-year of coding experience, which CS50 would have already prepared you with. **Andrew Ng 's Machine Learning Course at Coursera** Another great Machine Learning course , but a â€˜Bottom-up' style. It smoothly explains the math fundamentals first and gradually builds up the knowledge to piece together complicated machine learning models from scratch. I have an article that explains the difference between Andrew Ng and Jeremy Howard 's different approaches to machine learning education and recommend a potentially efficient way to learn. Corey Schafer's YouTube channel, Python and OOP Tutorials As good as it is, CS50 only covers the generic and basic concepts of Python. You'll need more in-depth knowledge to code efficiently for your data science projects. For this, I recommend Corey Schafer's YouTube channel . He is one of the best Python educators I came across to explain complicated ideas in a crystal clear way. Not one second of his videos is wasted. The content is concise, to the point, and highly condensed. He has playlists for basic Python , SQL , Matplotlib , Git , and Object-Oriented Programming . Conclusion Learning Data Science is never a breeze, and I hope this article will help a little in alleviating the pain and make your journey a bit more efficient and fun. If you know other courses and resources that are also great, please feel free to leave a response so others can also see. Thanks! Any feedback or constructive criticism is welcomed. You can either find me on Twitter @lymenlee or my blog site wayofnumbers.com .","tags":"Machine Learning","url":"this-is-cs50-a-pleasant-way-to-kick-off-your-data-science-education"},{"title":"Attack Toxic Comments Kaggle Competition using Fast.ai","text":"Kaggle is a good place to learn and practice your Machine Learning skills. It's also a great place to find the proper dataset for your learning projects. I need a good classification NLP dataset to practice my recently learned fast.ai lesson, and I came across the Toxic Comment Classification Challenge . The competition is held two years ago and has long concluded, but it doesn't hurt to submit my scores and see how well I did. This is one of the things Kaggle is great for since in the real world, it will usually be much harder to know how good or bad your model is, whereas, in Kaggle, you'll see clearly where your performance is in the Leaderboard. The Data Set This competition is held by The Conversation AI team, a research initiative founded by Jigsaw and Google (both a part of Alphabet). Its goal is to find out the best model that can classify multiple toxicity types in comments. The toxicity types are: toxic severe_toxic obscene threat insult indentity_hate Comments are given in a training file train.cvs and a testing file test.csv. And you'll need to predict a probability of each type of toxicity for each comment in test.csv. It is a multi-label NLP classification problem. Look at the Data Let's first take a look at the data. We need to import the necessary modules and do some logistics to set up the paths for our files. import numpy as np * # linear algebra* import pandas as pd * # data processing, CSV file I/O (e.g. pd.read_csv) * from fastai.text import * from fastai import * Notice here we imported everything from fastai.text and fastai modules. Are we against the software engineering best practice here? Actually, not quite. It's rather a deliberate move in a more iterative and interactive data science kind of way. With all the library available, I can easily test and try different functions/modules without having to go back and import them every time. It will make the explore/experiment flow much more smoothly. But I digressed, let's load the data and look at it: # Kaggle store dataset in the /kaggle/input/ folder, path = Path('/kaggle/input/jigsaw-toxic-comment-classification-challenge/') path.ls() # the /kaggle/input/ folder is read-only, copy away so I can also write to the folder. !mkdir data !cp -a {path}/*.* ./data/ !ls data # make sure everything is correctly copied over path = Path('/kaggle/working/data/') path.ls() # read in the data and have a peak df = pd.read_csv(path/'train.csv') df.head() The toxicity types are one-hot encoded The comments are in comment_text column and all toxicity types are â€˜one-hot' encoded, we'll have to do something about it to make it fit into our model later. Have a look at one comment Transfer Learning: Fine-Tune Our Language Model We'll use transfer learning for this task, to do that, we'll use a pre-trained model based on Wikipedia called wikitext-103 . It is a model that's already trained from the Wikipedia dataset(or â€˜corpus' in NLP terms) to predict the next words from a giving unfinished sentence. We'll leverage the â€˜language knowledge' the model already learned from the Wikipedia dataset and build on top of that. To achieve the best results, we'll need to â€˜fine-tune' the model to make it learn a bit from our â€˜comments' dataset since what people say in the comments are not necessarily the same with the more formal Wiki. Once the language model is fine-tuned, we can then use it to further do our classification task. Now let's load the training data into the fast.ai databunch so we can start training the language model first. bs = 64 # set batch size to 64, works for Kaggle Kernels data_lm = (TextList.from_df(df, path, cols='comment_text') .split_by_rand_pct(0.1) .label_for_lm() .databunch(bs=bs)) We use fast.ai's Data Block API for this task. It is a very flexible and powerful way to address the challenging task of building a pipeline: loading your data into the model. It isolates the entire process into different parts/steps, each step with multiple methods/functions to adapt to different types of data and the ways data is stored. This concept is a lot like the Linux philosophy, highly modulized and with each module only do one thing but really really well. You are free to explore the wonderful API here , for the above code though, it does the following things: Import data from Pandas DataFrame named df, tell the model to use comment_text as input (TextList.from_df(df, path, cols='comment_text')) Split the training dataset into train/validation set by random 10/90 percent. (.split_by_rand_pct(0.1)) Ignore the given labels( since we are only fine-tuning the language model, not training the classifier yet) and use the language model's â€˜predict next word' as labels. (.label_for_lm()) Build the data into a databunch, with batch size bs. (.databunch(bs=bs)) Now let's look at the databunch we just built: Notice we lost all the toxicity types Notice that the databunch doesn't have all the toxicity type labels since we are only fine-tuning the language model. OK , time for some typical fast.ai learning rate adjustments and training: We put our databunch into a language_model_learner, tell it the language model base we want to use (AWD_LSTM) and assign a default dropout rate of 0.3 . From the LR Finder graph, find the biggest downward slope and pick the middle point as our learning rate. (For a more detailed explanation of how this â€˜fit_one_cycle' magic is done, please refer to this article . It is a SOTA technique of fast.ai that combines learning rate and momentum annealing). Now we can â€˜unfreeze' the model and train the entire model couple of epochs: We can look at one example of how well the model did: The result is hardly optimal. Ideally, we need to train a bit more epochs but for this Kaggle Kernel, I was running out of GPU quota so I stopped at 4. The result definitely has room to improve and you can try it yourself. Anyway, what we want from the language model is the encoder part, so we save it. *# save the encoder for next step use* learn.save_encoder('fine_tuned_enc') Transfer Learning: Training the Classifier Let's read in the test dataset: test = pd.read_csv(path/\"test.csv\") test_datalist = TextList.from_df(test, cols='comment_text') Again, build our databunch: data_cls = (TextList.from_csv(path, 'train.csv', cols='comment_text') .split_by_rand_pct(valid_pct=0.1) .label_from_df(cols=['toxic', 'severe_toxic','obscene', 'threat', 'insult', 'identity_hate'], label_cls=MultiCategoryList, one_hot=True) .add_test(test_datalist) .databunch()) data_cls.save('data_clas.pkl') Please note the difference this time: We now use all our toxicity styles labels (.label_from_df(cols=[â€˜toxic', â€˜severe_toxic','obscene', â€˜threat', â€˜insult', â€˜identity_hate'],label_cls=MultiCategoryList, one_hot=True),) We added our test set here. (.add_test(test_datalist)) Now look at our classifier databunch : Note that now we have all the toxicity styles labels Finally, time to put everything together! We'll put the databunch into the text_classifier_learner model and load the encoder we learned from the language model. learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5) learn.load_encoder('fine_tuned_enc') Again, find the best learning rate and train one cycle: Train a bit more cycles and unfreeze: See the results: Off by one, but overall the prediction is OK . For the purpose of reference, I submitted the prediction to Kaggle and get a 0.96583 Public Score. The result is not optimal but like I said I didn't train all the way due to limited GPU . The purpose of this article is to show you the whole process of using fast.ai to tackle multi-labels text classification problem. The real challenge here is to load the data into the model using Data Block API . Conclusion I hope you learned a thing or two from this article. Fast.ai is really a lean, flexible and powerful library. For the things it can do (like image/text classification, tabular data, collaborative filtering, etc.), it does it very well. It is not as extensive as Keras, but it's very sharp and focused. Kind of like Vim and Emacs if you are familiar with the command line text editor war. ðŸ˜œ You can find the Kaggle Kernel here . Any feedback or constructive criticism is welcomed. You can either find me on Twitter @lymenlee or my blog site wayofnumbers.com .","tags":"Machine Learning","url":"attack-toxic-comments-kaggle-competition-using-fast-ai"},{"title":"9 Things I Learned from Blogging on Medium for the First Month","text":"Photo by Glenn Carstens-Peters on Unsplash I formally wrote my first story on Medium on Sept 5, 2019, and today is almost the end of my first month on Medium. During the month, I published 10 stories, gained 24K views, my articles got read 11K times, and gained 167 fans, 100 followers. Since I put all my stories into the Medium Partner Program , the member engagement for my stories gave me $134 in payment. I also became the Top Writer for both Artificial Intelligence and Education . It ain't much, but to me, it is very encouraging. It ain't much â€¦ Now that the numbers are out of the way, I want to say that overall I felt quite positive for the first month. This is not my first time blogging, sure, but it's the first time my stories have such reach, and for that, I appreciate Medium and its team for the opportunity. And I want to share with you a couple of things I learned along the way. I hope this could help others who also want to start writing on Medium to start quicker and smoother. Quality! Quality! Quality! Before I start writing on Medium, I've been reading Medium for quite some time. I always appreciated the high-quality content it offers. The content relevance, organization, layout, editorial standard, beautiful imagery, and the app UI , all spells quality and makes content consuming on Medium a pleasure. Now that I'm on the content-creating side of it, the high standard here also encourages me to keep the quality as good as possible to my readers. This includes, but not limited to: Proofreading my articles (I use Grammarly plus manual proofreading) Carefully pick photos that are beautiful, relevant and license-free ( Unsplash images are a great source and built into Medium's editor UI ) Contemplate a good title/subtitle that's catchy yet not cliche Creating my own GIF animation wherever I can to inject more â€˜energy' into my page. Cross-reference sources and embed videos wherever relevant to offer richer background knowledge. (Also to my own articles too, of course ðŸ˜‰) Make full use of Medium's rich editing and layout tools, like emoji, â€˜@', blockquote, etc. to make the story less boring and more vibrant to the eyes. Contemplating good tags that are diversified and also relevant to increase reach. The list could go longer, and no one story can cover every item in it, but that's something very beneficial to always keep in mind while writing. I felt it is as important as the texts I put down. I always strive to make the quality of the story the best I can manage. This is ultimately respecting my own time and my reader's time and I believe that's what Medium as a unique media promotes and rewards. One more note is don't overdo this though. After some polishment, sometimes you'll never feel that your article is ready to be published. Don't get caught by the analysis paralysis, hit the publish button, push your content to your reader. You can always improve them later. Writing is a journey, not a destination. Make Good Use of Medium's Editor I guess you can always write in your favorite software/app and import them into Medium, but I found it pleasant and efficient enough to just write on Medium's website editor UI . Having some years of experience in UI / UX , I can say the Medium editor is well designed in that it gets out of your way. It's what we called â€˜ invisible design '. It only appears when you need help and fades to the background when you are focusing on your task at hand. The interface is designed to be uncluttered yet powerful when needed. I found that getting familiar with what the editor has to offer really making my writing experience smooth and enjoyable. Take some time to read through Medium's guideline goes a long way. Numbers Won't Lie As a guy who has worked with numbers for years, stats are always what I have the most passion. Having done a lot of data visualization and dashboard design work myself, I found Medium's stats page clean and easy to read. The layout design is beautiful and has a good hierarchy with the most important numbers front and center, and everything else with a distance in the background. The only complain will be to fold more details in the background. This way, the more data-savvy people could dig deeper and the normal writers can enjoy the minimalism. Maybe that's another article at another time. I found myself visiting the stats page a bit too much, enjoyed watching the number tick up, and up (don't judge me pls). You don't have to do the same, but I encourage you to visit the stats page from time to time, it allows you to know how well each article do and when you are trying different writing styles, new topics or social media strategies, it provides a solid benchmark so you can adjust accordingly. For example, when I tried on promoting my articles heavily on Facebook, I did find my visit from Facebook increased a lot, but still not as much as when it gets curated by Medium. It's great insight! This kind of insight into what works and what not is obviously very valuable. Also, for Chrome users, I recommend installing an extension called â€˜ Medium Enhanced Stats ', offer better UI and more information on the stats page. Paywall, or Not Paywall, That Is the Question This is rather controversial. A lot of people don't like a paywall. As long as it's a paywall it is bad. I don't hold that strong of a feeling on paywall though. Getting paid as a writer is very well justified as long as you offer valuable content. This is no less or more decent than any other business. Having a paywall may reduce your reach, but also gives you more focus on people that really values quality. As for reach, I did some experiments and found out that Medium's 3 free paid stories actually will be enough most of the time. I put one free article and one paywalled one on Medium and promote it through Facebook. I didn't see much difference in Facebook's views ratio between the two. Also Medium only curates stories behind the paywall and curation is HUGE on increasing your reach. So I end up putting all my stories behind the paywall, and the results are not bad at all. The payment from my article doesn't seem much, but it at least paid my Medium membership so I can freely read all the great contents. You can test it out yourself and if you prefer your content the maximum reach then, by all means, set it as free content. Top Writer? Top Writer! After I wrote 3 or 4 articles, one of them got some traction. Not viral for sure, but my views start to grow quite fast. It reaches 2k in one day and two days later, I got an email from Medium saying I am now one of the Top Writers in the topic â€˜Artificial Intelligence'. How honored and humbled I was! I just start to write articles on Medium for a little more than a week and with less than five articles, I already become the Top Writer for the topic I cared most! Once I calmed down a little from the excitement, I started to contemplate what happened and why. There is quite some luck to it, sure, one of my stories got some attention or get promoted by some of the social media. But also it shows Medium's unique system values good quality, good content, not your track record or your brand name. So it is actually an edge for me and other people as green as me that sweating to produce great content: You will be recognized and rewarded for your quality work. The title is not permanent though, I think if I stop producing hit content it will go away, but it's perfectly fine. It's a good pressure to push me to write even better stories. Publications Matters Well, this is the first time I got to work with publications. After my first quality stories, one of the publications in Data Science approached me and ask whether I want to publish through them. After some research online, I found that publication is good for new writers like me, it can increase my reach and also provide some advice on my writing, etc. So I gladly agreed to publish some of my stories with them. After some stories, I felt that the publication did help me a bit in getting noticed. I did some research on other bigger publishers on Data Science and start to also submit my work with them. It's actually OK to publish with different publishers, what I did is for the more serious and heavyweight articles, I'll go with the big publishers. For the more entertaining and relaxed pieces, I'll submit to other publishers and see how the reaction is. I'm still in a â€˜trial and error' process. I'm still exploring working with different publishers and will share more experience once I get deeper. Responses, not Comments One thing I found quite unique for Medium is the response system. Responses are treated as â€˜first-world citizens' in Medium, which means it is treated the same way as a story. It will have its own stats, people can clap on it, etc. And because of that, I noticed that people really put more efforts into the responses they leave, resulting in very high-quality responses that often inspired me or pointed out things I missed or were wrong. I just love the response system. It really fosters quality communication and a clash of thoughts and ideas! Membership? Count Me In! The membership fee for Medium is a flat $5 . It opens up the entire Medium contents to you, you can freely read anything and everything it has to offer. To me, it is totally worth it. Not only it improved my ability to do research before putting down the first word of my article(did I say Medium has high quality and relevant content?), it also enables me to interact with other members and fit in deeper with the community. How to Make Money On Medium Well, I might not be qualified to talk about this, I just joined Medium a month ago after all. Yet I still want to share some of my thoughts on this. It does feel great to get rewarded for what you already love to do. The payment system, I believe, is built on â€˜member engagement'. The more members engage with your content, the more of their monthly membership fee will be distributed to you. I think it is quite fair, right? So this means you get rewarded by how deep and broad you â€˜touched ' people. Otherwise, people won't engage with you, they won't bother to clap, response, highlight, etc. This further encourages writers to come up with genuine content, people can only feel you when you really mean what you wrote. Conclusion Overall, I think Medium's member-based, quality-centric to online publishing really pulled some correct strings. And it is full of intelligent and diligent writes and curious, serious readers. It's a medium that connects us all with quality content, beautiful interfaces, and a well-designed system. Any feedback or constructive criticism is welcomed. You can either find me on Twitter @lymenlee or my blog site wayofnumbers.com .","tags":"Machine Learning","url":"9-things-i-learned-from-blogging-on-medium-for-the-first-month"},{"title":"On the Internet, Nobody Knows You Are a Dog, or AI","text":"Photo by Andy Kelly on Unsplash I came across the following tweet today and I wanted to talk about it. It is a new paper get accepted into EMLNP about generating deep fake comments according to a title and the article. There is already a lot of discussions about the ethical implication of this. Since it is a paper developed by Chinese researchers, as a Chinese myself, I think I can probably read more into it given that I'm more in the context of the Chinese online community and what are the possible uses of this new technology. Like Censoring, But More Aggressive Generating deep fake comments is somewhat the opposite of censoring, in a bad way. Instead of blocking/removing information you don't want , it generates/adds information that you do want . Censoring sometimes is not easy to spot, say your content is not recommended on YouTube or your tweet is hard to search on Twitter for some reason. These all happen in the background and usually done by algorithms. You don't know exactly what happened. A lot of the times, censoring has plausible deniability. Also, nobody can censor you if you don't put content up, so it's passive. But deep fake comments are different. It's more in-your-face, everybody can see it and they don't have to wait for you to post anything to act on it. It can flood your channel or timeline and render the real message/information less obvious. Compare to censoring, which is a passive way to shaping public opinions, deep fake comments is a very aggressive way to create some â€˜artificial trends' in an effort of engineering people's view on certain things. It could be some movie reviews, it can also be some report on social events to spin what happened. Nonetheless, the potential impact is big. Fine-Grained, yet Massive in Scale Photo by hue12 photography on Unsplash Deep fake comments might be in the early stage of development, but it has the potential of being fine-grained in quality and massive in quantity. The recent development in NLP often leverage transfer learning in training models with fewer data and more quickly. Researchers can utilize currently pre-trained model like the one trained on Wikipedia as a base, and fine-tune more specific models to gain state-of-the-art results much quicker with fewer data. The pre-trained model already knows how English as a language work overall, just needs to learn how certain type of English is spoken (e.g. Reddit, or IMDB movie comments). Utilizing transfer learning, deep fake comments have the potential of quickly developing multiple models for many niches and achieve fine-grained quality, generating very relevant and â€˜real' comments on different areas. Also, since it doesn't rely on human intervention (like the â€˜ 50-cents Party ' in Chinese Internet), theoretically you can have thousands of scripts, running slightly different styled models and generating comments trying to push the same agenda. Think of how well Google's targeted ads can do, and you'll have an idea of how much potential this â€˜targeted comments' has. I would even go so far as claiming it could be some kind of â€˜weapon' in some sense. In an Internet where no one knows you are a dog , people stopped trusting articles since it can be crafted to convince you buying some products or pushing some agenda, but people by and large still trust comments, thinking it's more human and more private thus more trustworthy. Now with the deep fake comments, even the comments cannot be trusted. What else on the Internet is still legit then? All Hope has Not Lost, Yet Having discussed all the scary indications of the deep fake comments can have. It's not without weakness. As we all know that comments alone won't have much influence if it cannot form a high-quality conversation. It's the exchange of idea and emotion that really touches people. One comments, no matter how â€˜real' or â€˜relevant' it is, won't have the optimum impact. When real people replied on the comment and expect a clever or powerful reply back, the algorithm will most likely fall short, at least for now. This is why a lot of the chatbot or â€˜Siri' like voice assistants have not gone mainstream yet. Being able to address this challenge is to say the AI has already passed the Turing Test , which is a very high bar and I don't believe we are there yet. Google's Duplex is currently the closest , but still not quite. So for now, I think the algorithm could create a lot of hassle, but cannot really touch people and have a very deep impact. Yet. What Can We Do I honestly don't know the answer to this. We can regulate the development and publication of this kind of technology, or we can foster self-discipline like what OpenAI was doing with their famous GPT -2 model (a respective move and should be encouraged, though far from solving the bigger issue though). Another way is to accept that the algorithm will be developed one way or another, and try to developed a counter- AI to detect the deep-fakes, like what Facebook and Google are doing right now. If we can detect the deep-fake, we can censor the deep-fake, right? Right? What do you think is the best way to deal with this? Please leave your comments (No Deep Fake Please!) below. Any feedback or constructive criticism are welcomed. You can either find me on Twitter @lymenlee or my blog site wayofnumbers.com .","tags":"Machine Learning","url":"On-the-Internet-Nobody-Knows-You-Are-a-Dog-or-AI"},{"title":"When â€˜Growth Hacks' Meets â€˜Growing Pain'","text":"What Happened In an era of influencer economy , famous Youtubers like Siraj Raval is considered very successful in spreading words of and enlighting newcomers to the somewhat daunting AI world. As of now, his YouTube channe l has 692K subscribers which is something. His content has a very broad reach. His â€˜Doing X in 5 minutes' tutorial videos are so popular, there is a meme for that: But recently, he ran into some problems. It's with his new course â€˜Making Money with Machine Learning' that he charges $200 for it. Charging $200 for a course is totally fine, the controversial part of it is that people were complaining that he used some code from other people's GitHub repo and also he accepted way more students than he promised and can properly handle without downgrading the experience. When some people seeking for refund, they also ran into some hiccups. â€˜Growth Hacks' vs â€˜Growing Pain' Some people accused him of fraud, I'm not so sure about that. This to me looks more like an honest mistake due to lack of experience in scaling up and entering into a field he is not familiar with. See, most of his more popular videos are entry-level tutorials with a bit of â€˜entertainment' (rap, parody, etc.) elements to it. He is very natural at that and that makes AI or Machine Learning not that boring or scary. And I believe that's why people like his content the most. However, when it comes to more serious education, especially when you want to charge $200 for it, people expect certain standards and he might not be fully aware of what those standards are. For example, you need to own your content, if you want to use other's contents like code snippet or diagrams, give credit, and very proper credit at that. I remember when fast.ai's Jeremy Howard was teaching the â€˜ Introduction to Machine Learning for Coders ' course. He used an â€˜overfitting vs underfitting' diagrams, and he credited it as from Quora. Photo Credit: Andrew Ng's Machine Learning course on Coursera. But turns out, the above image originally came from Andrew Ng 's Stanford Machine Learning course . So Jeremy Howard actually specifically corrected this error on his next lecture and went out of his way and praised Andrew Ng teaching style. I think this is the respective way of handling this. I don't think Siraj Raval is intentionally not giving out credit, he might not be so used to the academia convention of giving references, etc. People won't complain about it if you are doing free videos on YouTube and used their code, but if you try to charge for the content on a formal educational program, that's a totally different animal. On the accuse of taking too many students than he promised, I think it is mostly a scaling challenge. When the success hit you too fast and you are not prepared, you most definitely will stumble. It is understandable. However, how you handle it afterward is what will make all the difference. You can either get more help or properly refund people for the level of service you fail to live up to, just don't run away from it or trying to solve a mistake with more mistakes. This will at least save the reputation and get a second chance to make things right. Final Thoughts The situation is still developing and we'll see how he handles this. I'd like to say we give him the benefit of doubt. This guy did a lot for the AI community, helped people get started with AI / ML and made a lot of people laugh after all. My suggestion? Directly face the issue, acknowledge that he made a mistake and compensate people properly, then make a video on YouTube on how he handles scaling and did damage control! Turning crisis into opportunity. Take a page from The Tech Lead's playbook. Gotta monetize whenever you can, right?","tags":"Machine Learning","url":"when-growth-hack-meets-growing-pain"},{"title":"How I Migrated My Blog from GitHub Pages to Netlify","text":"Migrating Pelican site from GitHub Pages to Netlify The motivation Today I came across Rachel Thomas 's story of â€˜ **Why you (yes, you) should blog **'. She brought up a great point that all data scientists should have their own blog. She further explained that blogging helps you clear your thoughts, spread knowledge and get noticed. All great points and I wholeheartedly agree. So I wanted to share my recent blogging experience and hope it can provide some insights into what it takes and why it is rewarding to do this. The Settlement I've had my own blog for some time now. Starting my first blog post on WordPress.com, I stumbled along the way across multiple platforms, trying to find a good home for my thoughts and feelings. About a year ago, I settled on using Pelican (a Python-based static site generator) to generate my content, then host it on GitHub Pages . It all works pretty well. Python is an easy to write yet very powerful programming language. Also as a data scientist, you are very likely to live with Python every day. So among all the static site generators , I picked Pelican, which is quite mature and regularly maintained. It also supports tons of themes and plugins . (I've even developed a Pelican plugin that calculates the article read time like Medium and get pulled into the main branch. ). It supports Jupyter Notebooks which is also a plus for data scientists. GitHub Pages is a very popular, free hosting service generously offered by GitHub . It's based on Ruby's Jekyll framework but you don't have to use it. This solution is totally free and somewhat easy to maintain. Once you set everything up, you only need to focus on putting content and running a simple script to push it to GitHub and it will automatically make it live. I used it to blog for a while. All seems fine. (Note: Anyone wants to know more about how to do this, you can check this detailed blog post .) The Struggle Then came the struggle. Somehow I cannot figure out how to make the SEO work. I exposed the â€˜master' branch on GitHub and also my blog site, and Google think it's duplicate content and gave pretty bad rankings. It seems to be quite hard to get any traffic. Also as a free â€˜side' service provided by GitHub, there really isn't a lot of features for hosting on GitHub Pages. As outlined in this page by Netlify, it's OK when you start blogging, but when you try to get more serious of your work, GitHub Pages just won't cut it. Image Credit: Netlify.com The Strife So I decided to migrate to Netlify, which is also free, but offer way more features and if I want to scale up in the future, there are plenty of paid plans out there. Getting Pelican Ready Since I already have my Pelican site ready on GitHub, most of the work is done. (If you haven't set up Pelican site yet, you can follow this tutorial . ) I still need to make some changes to the site so Netlify can smoothly connect to my GitHub account and pull the site to deploy. Dependencies: First of all, Netlify will need to set up the necessary dependencies so it can build my site. This requires me to provide a requirements.txt file under the site GitHub repo. To do that, I created a Python virtual environment for it: $ sudo apt update $ sudo apt install virtualenv # install virtualenv $ cd ~/git/wayofnumbers.github.io/ $ virtualenv venv -p python3.6 # create a virtualenv for Python 3.6 $ source venv/bin/activate # activate the virtual env I also added venv/ in your .gitignore file so GitHub won't sync it. Once the virtual env is ready, I installed only the necessary packages as follows: $ pip install -U --force-reinstall pip $ pip install pelican Markdown typogrify ipython beautifulsoup4 nbconvert Now that the dependencies are all installed on my local virtual environment, I used the following command to generate the requirements.txt : $ pip freeze > requirements.txt CNAME : I created a CNAME file that contains my custom domain name( â€˜wayofnumbers.com') under the root folder of the repo. I also put the following lines in my pelicanconf.py file to ensure the CNAME file is copied to the root of the output directory: STATIC_PATHS = ['../CNAME'] EXTRA_PATH_METADATA = {'../CNAME': {'path': 'CNAME'}} Plugins and Themes: Then it's time to deal with plugins and themes. I copied the plugins and theme (folders) I use into the repo and set the pelicanconf.py file to point to those since on Netlify build time it needs to have access to them within the repo. Runtime.txt: Netlify needs a runtime.txt to decide which Python version to use for building the site. So I created a runtime.txt file under the root of the repo and put 3.7(Netlify supports either 3.7 or 3.5) in it. Alright, now that the Pelican is ready, I can move on to set the Netlify up! Connect to Netlify This part is actually quite easy. I registered to Netlifyâ€˜s free tier, and followed this step-to-step guide to connect my GitHub repo. The only thing different is on â€˜ Step 4: Configure Your Settings' . Since I was using Pelican, the â€˜Build command' I used is: pelican content -s publishconf.py After some failed builds due to dependencies issues, I got everything to work. Netlify automatically pulled my GitHub repo, installed the dependencies and built the site. I applied a custom domain with Google Domains and followed this link to set it up: https://www.netlify.com/docs/custom-domains/#googledomains . With $12 a year, it's totally worth it. I also turned on SSL , following this guide. So now my site is up and running on its new home: My blog with â€˜Elegant' theme The Thoughts The whole migration process took me around one day. I learned quite some new stuff from it. It's challenging but totally do-able. I encourage anyone that's interested in treating your blogging seriously to try this out. It's quite neat. Some people say data scientists should focus on their research and learning, I tend to wander off from time to time. Picking up some web programming tips here, getting some DevOps experience there. I found this kind of â€˜digress' actually is a bit relaxing and stimulate the other part of my brain. It's a form of rest and relax. I felt like playing a hacking game and solving problems along the way. Having knowledge of deployment will help you in putting your model to production easier and quicker. Having a blog is like having another venue to communicate with your colleagues and like-minded people out there. Can't go wrong with that, right? Any feedback or constructive criticism are welcomed. You can either find me on Twitter @ lymenlee or my blog site wayofnumbers.com .","tags":"Machine Learning","url":"how-I-migrated-my-blog-from-github-pages-to-netlify"},{"title":"How Long Until Boston Dynamics Robot Can Be a KungFu Master?","text":"Image Credit: Boston Dynamics Anyone interested in AI and robotics should look at the video below. In this video, Atlas from Boston Dynamics was performing a whole set of gymnastics routine including jumping, rolling and jump forward, stand up-side-down with two arms, and finally a 180 vertical spin. Again, amazing yet scary at the same time. The moves are so human-like is somewhat passed the uncanny valley and starts to appear very natural. With the fluent flow of moves showcased in this very short video, people can't help but ask: how are we till we see some KungFu master level robot moves? Like what we see in Alita: Battle Angel ? I can think of one thing this could be useful for. As far as I know, a lot of ancient Kung Fu set were lost in history just because there are no good apprentices to learn and preserve it. Huge lost for humanity IMO . If we can develop a robot that can â€˜copy' the set moves, at least we can preserve at least the form of it, right?","tags":"Machine Learning","url":"how-long-until-boston-dynamics-robot-can-be-a-kungfu-master"},{"title":"Two Sides of the Same Coin: Jeremy Howard's fast.ai vs Andrew Ng's deeplearning.ai","text":"Which One to Take? WHY NOT BOTH ! Data science and artificial intelligence might be the hottest topic in tech right now, and rightfully so. There are tremendous breakthroughs both on application level and research fields. This is a blessing, and a curse, at least for students and enthusiasts that want to break into this area. There are too many algorithms to learn, too many coding/engineering skills to hone, and way too many new papers to keep up with even if you felt you've mastered the art. The journey is long, the learning curve is steep, the strife is real, yet the potential is so great people still flock into it. The good thing is we also have great educators and instructors working on mitigating the pain and make the process a little less harsh and a bit more fun. We'll explore two of the greatest among them and share a potentially effective approach to help you swim through the sea of Data Science a bit happier. AI Learning â€˜Burn-out' Photo by Toa Heftiba on Unsplash If you list what one needs to learn to become an â€˜ OK ' data scientist or machine learning engineer, it could be scarily long: Math: Linear Algebra, Calculus, Statistics, Algorithms, â€¦ Coding: Python, R, SQL /NoSQL, Hadoop, Spark, Tensorflow/PyTorch, Keras, Numpy, Pandas, OpenCV, Data Visualizationâ€¦ Algorithms: Linear Regression, Logistic Regression, Support Vector Machine, PCA , Anomaly Detection, Collaborative Filtering, Neural Network, CNN , RNN , K-Means, NLP , Deep Learning, Reinforcement Learning, AutoML, â€¦ Engineering: Command Line, Cloud platform( AWS , GCP , Asure), DevOps, Deployment, NGINX /Apache, Dockerâ€¦ The list can easily make the head spin for a person just entering the filed. Yet, it is still just scratching the surface. Some people make an ambitious plan ( Siraj Raval 's plan is great btw) and dive right into it. Some lost momentum and felt totally under the water and the exit is nowhere to be seen. What went wrong? You â€˜Overfit' Yourself From Andrew Ng's Machine Learning course Overfitting is a very familiar idea for anyone that knows a bit of Machine Learning. It basically means your algorithm learned â€˜too much' of the data and buried itself into the little details of the data-set and missing the big picture. Come to think of it, sometimes when we learn something, we dive so deep we forgot why we were learning it and how it will fit into the big picture. It's something I'd like to call â€˜overfitting' your own learning. This happens especially often for people coming from academia background. A math Ph.D. tends to make sure all the theorems are fully understood before proceeding to the next one. This is great for learning math. Have a profound understanding of theories will give you great intuition and confidence. It will enable you to see patterns and issues people without the training cannot see easily, yet Data Science demands more. Theory aside, there is also a practical part to it. A properly applied algorithm coupled with efficient codes, carefully tuned hyper-parameters, and well-designed pipeline will usually achieve decent results, but not algorithm alone. Delve down too deep into theory, and you risk missing the practical side of the learning. It's equally important to accumulate experiences on how to implement what you learned and handle real-life complexities. How to address this? Entering deeplearning.ai and fast.ai courses. Deeplearning.ai and Fast.ai A lot of courses have been developed to help navigate people through the learning process. Among them, Deeplearning.ai and fast.ai are two unique ones that have their own approaches and can give us some insights into a potentially effective way of learning Data Science. deeplearning.ai deeplearning.ai is a paid course developed by Andrew Ng . Like his other courses , it is known for its well-designed learning curve, calm and smooth teaching style, and challenging while fun assignments. It is well accepted as the Deep Learning course one cannot go wrong with. It starts from the fundamental theories and works its way up on how to put all the pieces together to solve real-life problems. It's also called a â€˜Bottom-up' approach. fast.ai fast.ai is introduced by Jeremy Howard and Rachel Thomas as a free course to teach people with basic coding experience state-of-the-art deep learning techniques. Without much explanation of the underlying theories, with very few lines of code, student of fast.ai is capable of achieving astoundingly great results on its own domain quickly into the lessons. (I built a Chinese Calligraphy Style Classifier that reaches 96% accuracy rate and deployed it on the cloud after finishing lesson 1 of fast.ai course.) It teaches you how to tackle the real-world problem first, then digs deeper and deeper into how and why things work. It's also called a â€˜Top-down' approach. Which One is the Best Approach? Both! So â€˜Bottom-up' and â€˜Top-down', which one is better? Which one should we take? The answer is Both ! Photo by Maarten Deckers on Unsplash See, these two courses complement each other. Say you start from Andrew Ng 's deeplearning.ai course, you buried yourself into endless formulas and theories, you gained a lot of intuition, but after weeks of learning, you still have nothing to show to your friends and not quite sure when you can apply your newly gained knowledge. Your study on the machine learning fundamentals is getting diminishing returns. Your brain slows down and you start to feel boring. Now is the perfect time to start taking a lesson or two of the fast.ai course. With the help of the powerful fast.ai library and few lines of code, you'll be able to build impressive models that solve real-life problems and even beat some state-of-the-art papers and Kaggle competitions. This will give your brain a totally different kind of stimulation and your heart more confidence and passion to delve deeper into why everything works. Once you built a couple of projects and â€˜wow'ed your friends, you will be more motivated to learn more about the fundamentals, then you can go back to deeplearning.ai course and keep your study there. These two courses push each other forward, you can just rinse and repeat till you finished both. This forms a perfect learning circle. Photo by Dan Freeman on Unsplash The best thing about taking both courses this way is once you finished both, you'll be fully prepared. You have tons of projects built along the way from fast.ai course to showcase to potential employers and you also have the deep knowledge of how everything works or even published one paper or two to show your findings. You are now a well-rounded Data Scientist. How cool is that?","tags":"Machine Learning","url":"two-sides-of-the-same-coin"},{"title":"How to Deploy Your Machine Learning Web App to Digital Ocean","text":"You've collected your data, cleaned it up diligently, squeezed it into your carefully fine-tuned model and sweated many GPU hours and trained the model. The prediction is State-Of-The-Art! Bravo! But what now? Share it with the world of course! It has such great potential and no one has done this before, you want everyone to try it out! How? You ask. In this tutorial, I'll introduce you to an affordable and flexible way of deploying your trained Machine Learning model. I'll walk you through every step in the way and hopefully, after reading this article, you'll have no issue deploying your â€˜next big thing(model)' to the world. How to Train(and export) Your Dragon(Model) Image from https://www.facebook.com/HowToTrainYourDragon/ First of all, you need to train your model and export it. In this article, we'll use Fast.ai's library to showcase how it's done. You may want to refer to my two-part articles about how to collect data and train a Chinese Calligraphy Classifier model or you can also use your own model. For the purpose of this article, I'll assume that you already trained the model and achieved your desired accuracy rate. Fast.ai uses a learn object to train the model, to export your model, use methodlearn.export() to export and save your trained model to a export.pkl file( my model export file from the link above is around 100MB ). Save this file, we'll use that later. â€˜GitHub-Driven' Web Development With the model ready, the next step is web app development. I assume you are a full-stack web developer, so let's jump right into coding. No, I'm just kidding here. We'll use a boilerplate web app template on GitHub to quickly get your web app ready. You only need to do some minor tweaks and you'll be ready to go. If you don't know what GitHub is, it is a place to hold the source code of a lot of open-source applications. I already put a ready-made web app's code there so you can easily download and reuse. Go to this GitHub repository , click the big green button â€˜ Clone or download ' on the right side, like below: On the pop-down window, copy the link, then go to your terminal and type: git clone [https://github.com/wayofnumbers/fastai-vision-uvicorn-gunicorn-starlette-docker.git](https://github.com/wayofnumbers/fastai-vision-uvicorn-gunicorn-starlette-docker.git) cd fastai-vision-uvicorn-gunicorn-starlette-docker These commands will clone all the required code onto your local machine, under a folder named fastai-vision-uvicorn-gunicorn-starlette-docker and enter that folder. This is the main folder we'll be working on, there are a couple of things in it that worth explaining: app : The structure of this appfolder is as below: template |--app.html main.py export.pkl This is where your Starlette web app source code resides. It has a very simple Python file main.py. The **Starlette **is a lightweight ASGI framework/toolkit, which is ideal for building high-performance asyncio services. It also has the saved model fileexport.pkl. The template folder holds an HTML template file app.html which will serve as your web app UI . Remember the exported export.pkl file you saved? Pull that out and replace the one in this app folder. So the app will use your model. You are also welcomed to update the app.html file for better-looking UI , but it's not necessary as far as deployment is concerned. Now the source code of your web app is ready, we need to wrap it into a Docker container and do some testing. We use the Dockerfile as the config file. We'll explore more in the next section. Let's Dockerize it! We will use Docker to create a container where our web app runs. If you don't know what Docker is, just know that it is kind of a mini virtual machine, with all the necessary libraries and dependencies installed so the app can run smoothly. It is smaller and more flexible than real Virtual Machine and can be created and deployed very easily. First, you need to install Docker. Here is a very thorough guide for your reference. After installation, if you are running Ubuntu, then it's beneficial to run the following commands: sudo groupadd docker sudo usermod -aG docker $USER This will eliminate the need to use sudoevery time you enter a docker command. Reboot, now docker should be properly installed. In the same directory where app folder and Dockerfile resides, we need to create a docker image that contains all source code within this folder so we can test things out. Enter the following command(don't forget the â€˜.' at the end): docker build -t test_app . This will start a docker image building process according to the Dockerfile. It will take a while, so let's take a brief look at what's inside the Dockerfile: #1 FROM tiangolo/uvicorn-gunicorn-starlette:python3.7 #2 RUN pip install fastai aiohttp #3 RUN pip install jinja2 #4 RUN pip install starlette #5 COPY ./app /app #6 WORKDIR /app #7 EXPOSE 80 It is quite self-explanatory: Line 1: Specify from which starter image we'll build our docker image. We use tiangolo/uvicorn-gunicorn-starlette:python3.7 . You can find its GitHub link here and Docker Hub link here . Line 2,3,4: Install fast.ai library, jinja template framework, Starlette framework, and other utilities. Line 5: Copy your app folder into docker image so our app can run within the docker container. Line 6, 7: Assign work directory to the app folder and expose port 80 to outside so we can visit the web app through port 80( HTTP ). Once the docker image is created, run docker images to check. You'll find something like: REPOSITORY TAG IMAGE ID CREATED SIZE test_app latest xxxxxxxxx 1 minutes ago 4.05GB Now we can fire up a docker container from the created image and test your app locally: docker run -p 80:80 \\ -v ./absolute/path/to/export.pkl:/app/export.pkl \\ -e TITLE=\"Chinese Calligraphy Classifier\" \\ -e SUBTITLE=\"Can disambiguate Chinese calligraphy styles like KaiShu, LiShu, XiaoZhuan\" test_app On the above docker command, we specified the port to be 80. We transferred two environment variables into the container, TITLE and SUBTITLE , they will be used to display our web app UI titles. At the end we specified our docker image name: test_app. Please note that for export.pkl file, you need to use the absolute path, otherwise Docker will not be able to find it. If you don't see any error, your docker container should now be up and running. Head over to your browser and type 127.0.0.1 and hit enter, voilÃ  ! You should see the web app. Give it a â€˜Kaishu', â€˜Lishu' or â€˜Xiaozhuan' calligraphy image and hit â€˜ Classify ', you should see something like this: Very rough web app UI You can see the app classified this as â€˜KaiShu', which is correct. Now that your app is up and running on the local machine, we are 80% done. What's left is to deploy it on the cloud. Let's head to the cloud next! Next Step, Cloud! For the cloud hosting service, we'll use DigitalOcean . Comparing to the more incumbent players like Amazon AWS , GCP , or Azure, it's more friendly to developers and cheaper. You can follow this well written and concise tutorial to create an account and a â€˜Droplet' of your own. (â€˜Droplet' is a virtual machine running by Digital Ocean where you can install your app in, much like an AWS instance.) If you want, you can use this link to create your account and get $50 credit for free, which will be enough to get you started. Use the following configuration as a reference: It is recommended that you create your Droplets with at least 4G memory since installing PyTorch will require a lot of memory. You can resize it down to 2G later. You can choose the default â€˜Data Center' and set up your authentication method. Use SSH key or password, whichever way you feel more comfortable. I personally prefer SSH key, fewer keypresses and more secure. Once the Droplet is created, SSH into it and we are ready for the final deployment! Deploy! Deploy! Deployï¼ Now you should be able to SSH into your server as root. It's recommended to create a normal user with sudo privilege, you can follow this tutorial . Once a normal user is created, log out of your root user and SSH back into the server with your normal user account. The final deployment is very similar to what we've already done on our local machine, only this time we do it on the remote droplet server. First, let's git clone our repo so we have the source code: git clone [https://github.com/wayofnumbers/fastai-vision-uvicorn-gunicorn-starlette-docker.git](https://github.com/wayofnumbers/fastai-vision-uvicorn-gunicorn-starlette-docker.git) cd fastai-vision-uvicorn-gunicorn-starlette-docker Don't forget to copy your export.pkl file to replace what's in the app folder. (follow this link if you don't know how) If docker is not installed, install docker. Then build the docker image using below command. Again, if the image building failed due to low memory, resize your memory up, you can resize it down later without much cost increase. docker build -t test_app . Once the image is built, fire up the docker container: docker run -p 80:80 \\ -v ./absolute/path/to/export.pkl:/app/export.pkl \\ -e TITLE=\"Chinese Calligraphy Classifier\" \\ -e SUBTITLE=\"Can disambiguate Chinese calligraphy styles like KaiShu, LiShu, XiaoZhuan\" test_app Once the docker container is up and running, head over to your browser and enter your Droplet's IP address, hit Enter. Congratulations! You've successfully deployed your Deep Learning model to the Internet! Conclusion Not that hard, huh? Deployment using standard DigitalOcean Droplet offers a lot of flexibilities. You can do whatever you want to your Droplets since you have root access. You can run multiple apps on it, and pay very little($5 - $10 tier should be enough). If your app gets some traction and needs more resources, you can easily scale up. I hope this tutorial somewhat help you deploy your AI app. If you have any question or want to share your deployment experience, please write a response below. Happy Deploying!","tags":"Machine Learning","url":"how-to-deploy-ML-web-app-to-DO"},{"title":"OpenAI: Catch Me If You Can","text":"Who is OpenAI? When it comes to reinforcement learning, OpenAI is a big name. The OpenAI Gym toolkit provides a solid foundation for a lot of ML researchers to explore and study reinforcement learning techniques. They also are known to have developed â€˜ GPT -2 ' language model. The â€˜deep fake' news the model generated is so scarily good that OpenAI refused to release the trained model, just the code and paper . From OpenAI.com Hide and Seek, Only This Time the Computer is Playing It Today they release something new and equally groundbreaking: The Multi-agent Hide and Seek . You can have a look at the short video below from their website: Simply put, they designed a reinforcement agent and let it play a simple â€˜Hide and Seek' game that we all played when we were still a kid. After millions of games played with itself and the prior version of itself. Both the seeking and hiding agent developed several very effective strategies to counter each other and win. Basic abilities agent has to play and win the game How to Train Your Dragon, urrâ€¦ Agent The agents develop their tactics in an adversarial way. Both agents move randomly Seeking agent learns to chase hiding agent. Hiding agent learns to run away from seeking agent (not working) Hiding agent learns to use blocks in the environment to block entrance to a small room and hide inside (It works!) Seeking agent learns to use ramp blocks in the environment to jump over the wall to get inside the blocked room Hiding agent learns to move ramp blocks inside the room, then block the room â€¦â€¦ the game keeps playing and more gaming mechanism is discovered and exploited, both agents getting smarter and smarter. The seeking agent and hiding agent counter each other and at the same time grow with each other. This is a concept (ç›¸ç”Ÿç›¸å…‹ mutually reinforce and neutralize each other) very familiar to Chinese people, and can be illustrated in a simple way: Taichi å¤ªæž Philosophy aside, we did see this kind of concept appear on recent AI field quite often. Another example is the rise of GAN (General Adversarial Network) where a â€˜generator' and â€˜discriminator' are trained at the same time to achieve state-of-the-art results. The Agents Looks Cute! But Why I Still Feels a Bit Chilly on My Spine? Agents in the game are quite cute with cartoony big heads and smiley eyes. But underneath the cuteness, what does the great results suggest? Well, just imagine, if they are not playing this cute little hide and seek game where agents giggles when get caught, rather, they are playing Doom or Quake, where blood and gores fly around when the agent gets caught. Will the bloody scene lead you to start worrying about the possible application of this model and the potential it has if weaponized? If this still seems too far away from reality, let me bring this uncomfortable imagination one step further, allow me to use three words: Boston Dynamic, Drones, Skynet. The tasks and tactics agent learned from millions of games might still seem easy. Hide, use blocks, use ramps, etc. But don't forget that complicated and sophisticated strategy is formed with all these small pieces. One big advancement of AI recently is transfer learning , build new AI models on top of already trained/learned models. (Using transfer learning based on already trained IMAGENET model, people can quickly train a fine-grained cat/dog classifier with only 100 images and 1 GPU in minutes. I explained the approach of fast.ai at here ). These basic game tactic model can be utilized in the future to build more realistic and dangerous military strategy models that can totally be applied in war. This is not beyond our reach now. If we put all our current AI and robotic achievements together, great/scary things can be achieved. When an OpenAI model agent running within a Boston Dynamics robot or killer drones, and video surveillance networks everywhere to watch your every step, if you are the hider playing this game, what is the chance of you winning?","tags":"Machine Learning","url":"openai-catch-me-if-you-can"},{"title":"How I Trained Computer to Learn Calligraphy Styles: Part 2","text":"Photo by Kon Karampelas on Unsplash I wanted to start a series of posts for the projects I finished/polished for my Practical Deep Learning for Coders fast.ai course. Since I'm pretty green on ML / DL field, I hope the challenges I faced and overcome could be of value for other people experiencing the same journey. Model 1 ãƒ» 1a Making It Even Better In my last post , I explained the approach I take for this image recognition problem using fast.ai library. As you can see, once we get the data down to a fast.ai ImageDataBunch, the code is rather simple and we achieve a 90% accuracy rate, which is quite impressive considering the quality of our data(randomly downloaded from Google/Baidu search without much data cleaning). Now, can we do better? DDI Editor's Pick: 5 Machine Learning Books That Turn You from Novice to Expert | Data Drivenâ€¦ The booming growth in the Machine Learning industry has brought renewed interest in people about Artificialâ€¦ www.datadriveninvestor.com Turns out, we can! How? Well, there are two things in our prior pipeline that could improve: Image Pre-processing Tweak Model Training Fine Tune. Let's dive deeper. Image Pre-Processing Tweak Remember when we import our data into fast.ai ImageDataBunch, we used the following code: Notice that on our image pre-processing, i.e. get_transforms function, we didn't give it any parameter and just used the default. The default will try to apply a variety of image augmentation techniques to make the image data-set generalize better, like flipping, warping, rotating, cropping, etc. This is good, fast.ai library helped us do the â€˜best practice' for the majority of the cases. But in our case here, some default might not work that well. The biggest one is â€˜flipping'. Because we are trying to classify calligraphy artworks and in real life, it will never randomly flip left/right or up/down. So making the images flips randomly will not reflect the real-life cases and thus won't help with our training accuracy. To fix this, we tweaked our code as below: Notice we pass do_flip=False into the get_transforms function, thus telling the module to not randomly flipping our images during importing. Model Training Fine Tune Now that the image pre-processing is done. We can re-structure out model training to avoid overfitting and achieve better accuracy. This approach is introduced in the fast.ai Practical Deep Learning for Coders course lesson 3 . Instead of training the model directly from a 256x256 image size, we'll gradually scaling up the image size. More concretely, we will first train a CNN to classify the images of 128x128 size, once we achieved best accuracy, we'll then use transfer learning and keep training the model on the same data-set, except with 256x256 image size. We'll call the 128x128 image size training â€˜stage 1' and 256x256 image size training â€˜stage 2' After our stage 1 training(where my last post left off), we have a trained CNN model called learn , it's â€˜unfreezed' and achieves an accuracy of around 85%. Accuracy 86% after training a 128x128 image size CNN . Now we need to freeze the network again, create a new ImageDataBunch with 256x256 image size and restart the same training process. After finding the best learning rate, we train the CNN with another 2 epochs, already breaking into 91% accuracy. We'll then do the same â€˜unfreeze' and keep training. After unfreeze, we trained the model with another 4 epochs, the accuracy broke into 96.5% . Observed that valudation_losshas already surpassed training_loss, suggesting a sign of overfitting. We'll stop our training here. This simple technique is also called â€˜ Progressive resizing ' by Jeremy Howard from fast.ai and helped his team beat Google in a competition of speed training IMAGENET in *DAWNBench by training the IMAGGNET in a whopping 18 minutes and \\$40 Amazon AWS cost.* To Wrap It Up Photo by Franki Chamaki on Unsplash With two simple tweaks, we managed to increase the accuracy around 6.5%, breaking into the state-of-the-art range of results. Major takeaways: When doing image pre-processing, make sure the processed images still properly represent what real-life data will look like. The reason gradually increase training image size works is: by giving the trained model a data-set that's 4 times bigger, actually means giving the model a brand new data to train, avoiding overfitting. Starting from smaller sized images for training will also have the benefit of faster training and quicker experimenting. This usually leads to better results. That's it for Chinese Calligraphy Classifier. I hope you learned a thing or two after reading these two articles. We're trying to get some specific calligrapher's â€˜true' and â€˜fake' artworks and see if we can build a â€˜true or false' classifier. This will be a very interesting and much valuable next step. Will report back and write more articles if we made real progress. But until then, we'll move on to put this well-trained model into production and build a web-app around it. Stay tuned. If you haven't read my first post on this topic, here's the link: How I Trained Computer to Learn Calligraphy Styles: Part1 Build a Deep Learning Model with fast.ai Library medium.com","tags":"Machine Learning","url":"chinese-calligraphy-classifier-2"},{"title":"How I Trained Computer to Learn Calligraphy Styles: Part 1","text":"Photo by Raychan on Unsplash I wanted to start a series of posts for the projects I finished/polished for my Practical Deep Learning for Coders fast.ai course. Since I'm pretty green on ML / DL field, I hope the challenges I faced and overcome could be of value for other people experiencing the same journey. Model 1 ãƒ» 1a Why Build a Chinese Calligraphy Classifier Like any calligraphy, Chinese calligraphy is a form of art. Some great pieces written by some ancient masters have both great art value and economic values (selling at multi-million dollars on auctions). * Jieshi Tie by Song Dynasty politician and scholar Zeng Gong, \\$30,000,000* There are multiple main styles/schools of calligraphy, mainly belongs to different dynasties. Each has its own way of shaping the character and arranging them. The differences are subtle and abstract. It makes sense to see if a trained deep learning model can do a good job of telling which style it is. DDI Editor's Pick: 5 Machine Learning Books That Turn You from Novice to Expert | Data Drivenâ€¦ The booming growth in the Machine Learning industry has brought renewed interest in people about Artificialâ€¦ www.datadriveninvestor.com I picked three styles: Lishu(éš¶ä¹¦) Kaishu(æ¥·ä¹¦) Xiaozhuan(å°ç¯†) as a proof-of-concept. Once successful trained, the model could serve as a transfer learning base-model for the more fine-grained classifier( e.g. calligraphers classifier). This has some real-life value. From time to time, some ancient artifacts are discovered and some of them are calligraphy artworks. Sometimes it's hard to tell whose work it is. Is it valuable (like undiscovered artwork by a famous calligrapher)? This calligrapher classifier can serve as a way to quickly identify artworks by great calligraphers. ( Finding diamond in the rough ðŸ˜‰ ) Collecting Data To build a calligraphy classifier, we will need some calligraphy examples of each style. I did some search online and cannot find any good already-made data-set for different calligraphy styles. So I'll have to build it myself. Building a images data-set isn't hard thanks to Google's Images search functionality and some JavaScript snippets. Here's how: Go to Google Images and search for \"éš¶ä¹¦ å­—å¸– ç½‘æ ¼\" (lishu, characters book, grid), this will give you the most relevant results. Scroll down to show more results, you'll hit the bottom with â€˜ Show more results ' button. Click if you want more, but keep in mind that 700 images is the maximum here. Google search results for Lishu style Now is where the magic happens. Press Ctrl+Shift+J in Windows/Linux and Cmd+Opt+J in Mac to bring up the JavaScript â€˜Console' window of the browser. The following JavaScript snippet will get the URLs of each of the images. 4) If successfully run, a text file will be downloaded with all the URLs for the images in your search results. You can then set up a folder and use fast.ai's â€˜download_images' function to download these images. Rinse and repeat for other styles. You might want to put them into different folders like kaishu, xiaozhuan and put them all under a folder called train so later on, fast.ai can easily import them into the model. Alternatively, you can also go to Baidu.com for images search, using this snippet to automatically download the images you searched for. (Code too long to be put into this post, so I link it here). Let's Have a Look at the Data If you organize the downloaded images into train/lishu, train/kaishu, train/xiaozhuan, then you can run the following code to import them into and transformed accordingly, ready to fit a model.fast.ai's powerfulImageDataBunch object, where all data is organized, splitted and transformed accordingly, ready to fit a model. Note that we split the train/validation set with an 80/20 ratio, image resized to 224 which is a good default for any image recognition task. Now that data is imported properly, let's look at our images: As we can see from the few examples above, the data-set is rather â€˜dirty'. The images are not properly cropped, with some side notes with different calligraphy style and some images only have one or two characters. But it's OK . Let's quickly train the model and see how it performs so we can gain some insights into our data. Quick and Dirty Training Let's first create a model. We'll be using transfer learning and use ResNet50 as our model. Pre-trained weights will be downloaded. With 3 epoches of fit_one_cycle, we managed to reach a 90% accuracy rate on our validation set. Not bad! Unfreeze and Fine-Tune Our Training Since the fit_one_cycle function will freeze the initial layers and only training the last couple of layers to speed up the training speed(this approach works because usually for transfer learning, initial layers will capture basic features of the images that are not likely to change a lot), we can hopefully further improve our accuracy by unfreezing all the layers and train again. We used the above lr_find function to find a good learning rate range. The key is to find the steepest slope (as indicated in the orange circle above) in the learning curve and slice it for further training. For example, in the above figure, the bottom of the curve is at 1e-03, then we can pick one point at 1/10 of that, which is 1e-04, and the other one at 1e-06 or 1e-05 (This is inspired from an experimental concept of â€˜Super-convergence', described in details in fast.ai course . Sometime you need to do a bit of experiment to find the best learning rate combination but then again, fast.ai is always preaching iterative and interactive approach.) The idea is still to train the first couple of layers slower and last couple layers faster. Let's train another two epoch: Slightly better and the validation_loss starts to surpass train_loss, a sign of overfitting. Let's stop here and wrap things up. Results Interpretation We reached 90% accuracy. Not state-of-the-art but already pretty impressive considering we only have a roughly 700 images per class data-set. More data will definitely lead to better results. Let's look at our results and see if we can find some insights. Using the ClassificationIntepretation object from fast.ai, we can easily calculate the top_losses and see what they are: Look at the confusion matrix, the model does really well in recognize â€˜xiaozhuan', probably due to its unique stroke arrangements. A couple of insights: We still have totally wrong images like the grid one (2nd one on 1st row) If there are too few (1st row, 1st column) or too many (2nd row, 2nd column) characters, the model will struggle. Some image shows â€˜in-between' kind of styles which the model also had a hard time classify. Which is totally normal, since even human will have a hard time telling which style it belongs to. Final Thoughts This experimental project actually works exceedingly well with fast.ai library. Jeremy Howard said on the course and I quote here (not exactly word by word, but I hope I captured the gist of it. ðŸ™): fast.ai is a very opinionated library. Wherever we know a best default, we'll choose it for you. Whatever best practice we know works well, we'll do it for you. This is at least proven in this project. With only very few lines of code and very minimum efforts for data collection, we managed a 90% accurate model. I believe with more and better quality data. The state-of-the-art results could be achieved and our calligrapher classifier vision is not beyond reach. fast.ai's tagline: Making neural nets uncool again. Finally, allow me to paraphrase above tagline with a Chinese poet: \"Where once the swallows knew the mansions of the great, They now to humbler homes would fly to nest and mate.\" You could find out how I fine-tuned the model and achieved better accuracy at the link below: How I Trained Computer to Learn Calligraphy Styles: Part 2 Build a Deep Learning Models with fast.ai Library medium.com","tags":"Machine Learning","url":"chinese-calligraphy-classifier-1"},{"title":"I finished Andrew Ng's Machine Learning Course and I Felt Great!","text":"Just finished Andrew Ng 's Machine Learning course on Coursera , and it's GREAT ! Here some thoughts and observations: What's great about it Well designed learning curve EVE Online game's (in)famous crazy learning curve This is especially important for people that never heard of Machine Learning. Not assuming the student have any prior knowledge and gradually guide them through complex concept makes the learning experience challenging yet still fun. Avoid complex math, yet find a way to still enable student to do ML (meme) The Andrew Ng â€˜Silent Protector' Meme Maybe the biggest fear for people want to get into Machine Learning and AI is â€˜I'm not a math person'. Being able to not getting into too much math yet still explain clearly the concept is invaluable, especially for totally green guys. *Octave / Matlab is more â€˜math' like, less digression on programming language itself* Some people might not agree with me on this. Yes Octave/Matlab doesn't have all the fancy libraries like scikit-learn and Pandas, yet it's very expressive when it comes to represent math equations. Transfer equations from class to Matlab code is easier than Python IMHO . Cover most popular models, good foundation Linear/Logistic Regression SVM Neural Network Collaborative Filtering Anomaly Detection K-Means PCA With all these algorithms/models under your belt, you are ready to solve a lot of problems with Machine Learning. Provide practical ML projects knowledge, not only algorithm and programming Besides theory, the course also offers very practical Machine Learning project knowledge, hot to build a pipeline, how to structure the problem solving, etc. Well designed quizzes and assignments, as part of learning too I was always amazed by how well the quizzes and assignments are designed. They are challenging, yet with some efforts achievable, and at the same time offer some new perspective on the lesson. I always learned a few new things doing those and totally enjoyed them. What's lacking? A bit dated on libraries and architectures You won't find the high-level Keras , TensorFlow or PyTorth here, but this course is about foundation of Machine Learning and it delivered on its promise. 2. Could use more examples/applications of ML for motivation There are a lot of exciting development and applications on ML / AI field. If students could be exposed to more of those, it will give them more reasons to keep learning. Final Thoughts â€˜Don't worry about it if you don't understand' â„¢ï¸ Overall great course if you are totally new to Machine Learning. All of the well thought out contents coupled with Andrew Ng 's gentle and calm explanation makes the learning experience a breeze and a pleasant journey. The road ahead for Machine Learning might not be so smooth after all but having a â€˜soothing' start could carry you a long way. ðŸ‘","tags":"Machine Learning","url":"andrewng-ml-course-review"},{"title":"Types of Optimization Algorithms used in Neural Networks and Ways to Optimize Gradient Descent","text":"Original Story Anish Singh Walia : If your input data is sparse then methods such as SGD , NAG and momentum are inferior and perform poorly. For sparse data sets one should use one of the adaptive learning-rate methods. An additional benefit is that we won't need to adjust the learning rate but likely achieve the best results with the default value. If one wants fast convergence and train a deep Neural Network Model or a highly complex Neural Network then Adam or any other Adaptive learning rate techniques should be used because they outperforms every other optimization algorithms. One thing about Machine Learning the overal depth of the topics and algorithms makes it so easy to totally â€˜sink' yourself into it. And there is always something to dig. This article provides a view from a higher ground and compare different optimization algorithms and their application areas, thus pulling you out of the deep hole of deep learning. A more visual example of these algorithms, see these two beautifully crafted animations: SGD optimization on loss surface contours SGD optimization on saddle point","tags":"Machine Learning","url":"Typtes-of-optimization-algorithms"},{"title":"Tweaking Pelican Elegant Theme","text":"Pelican has a lot of themes, developed by the community and shared on its official GitHub repo here . Pelican Themes also offer some previews of them so you can have a good idea of what to expect. Some themes are really easy to setup and configure, others need some efforts. The Elegant them is the latter. For most of the themes, to make it work, you just need to add define the â€˜ THEME ' variable, like so: 'THEME' = 'theme/themename' For Elegant, it's way more than that, and it's a good thing. Elegant packed a lot of great features and thorough considerations to the reader. And that's why I choose it as the theme for my site. Good things come with a price they say. So let's find out. Search Search is useful when you have a lot of articles. All serious blog need to have it. To use it, add â€˜tipue_search' and â€˜sitemap' to your plugins and it will automatically be enabled. About Me and My Project Elegant's home page layout put the blogger himself front and center with â€˜About Me' and the â€˜My Project' at the top, followed with â€˜Recent Posts'. To use them, you need to set the â€˜LANDING_PAGE_ABOUT' and â€˜ PROJECTS ' variables in the pelicanconf.py . jQuery Issue I've enabled all the nice features, like search, collasible comments, collasible comments. But they all won't work on Chrome because it's considered â€˜unsafe scripts'. After some digging, it turns out the site is using HTTPS , while the original theme's template uses HTTP to load the jQuery that did all these nice features. Once I replaced the HTTP with its HTTPS counterpart, everything works like a charm. Table of Contents Took me some time to get table of contents to work. Firstly â€˜extract_toc' plugin needs to be added into the â€˜ PLUGINS ' variable. Then â€˜markdown' Python module needs to be installed and configured for it to work as the Elegant website instructions. But after all this, it still didn't work. Turns out, you need to add [TOC] in the Markdown file, after all the meta data, to actually add the table of contents into your post. After I did that, everything works. Conclusion Install and tweaking a Pelican theme isn't that hard. Look into the static folder for CSS , tweak them if you want, or add custom CSS of your own and load them in the template. Then go into the template folder to check the html files. With basic HTML / CSS /Javascripts knowledge, you already can achieve a lot on tweaking any theme of your liking.","tags":"Tools","url":"Tweak-Pelican-Elegant-Theme"},{"title":"The AI Shortage","text":"Original Story Nikolai Yakovenko from NVIDIA : But when I look for a designer, a Java developer, a real estate agent, etc â€” some are way better than others and deserve to get paid more than an AI researcher â€” but you're fundamentally talking about pulling from a large well-balanced pool. It's mostly an information game, and a matter of getting a little better than you need, but not much more than you can afford or should be paying. In AI , it's different. There just aren't enough people to go around. And there aren't enough people for every good project that can be attempted. Either academic, or something that if it works, can save the company $1M. The booming of a new disruptive technology always did this to the industry as well as the talent pool. It drives money into investing on the next big thing, and the money lures more talents into the field. There will be a shortage in the very beginning, and there will always be a surplus at the end of the curve. I'm afraid AI won't be any different. It's just that the curve will take 10 maybe more years to unfold so it's not too late to get in the game if you think you have the stuff, since at the end of day, people with talent and grit will win, in every new technology â€˜gold rush'.","tags":"Machine Learning","url":"The-AI-Shortage"},{"title":"Machine Learning Notes : Text Data Analysis","text":"/*! * * IPython notebook * */ /* <span class=\"caps\">CSS</span> font colors for translated <span class=\"caps\">ANSI</span> escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #<span class=\"caps\">3E424D</span>; } .ansi-black-bg { background-color: #<span class=\"caps\">3E424D</span>; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #<span class=\"caps\">E75C58</span>; } .ansi-red-bg { background-color: #<span class=\"caps\">E75C58</span>; } .ansi-red-intense-fg { color: #<span class=\"caps\">B22B31</span>; } .ansi-red-intense-bg { background-color: #<span class=\"caps\">B22B31</span>; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #<span class=\"caps\">DDB62B</span>; } .ansi-yellow-bg { background-color: #<span class=\"caps\">DDB62B</span>; } .ansi-yellow-intense-fg { color: #<span class=\"caps\">B27D12</span>; } .ansi-yellow-intense-bg { background-color: #<span class=\"caps\">B27D12</span>; } .ansi-blue-fg { color: #<span class=\"caps\">208FFB</span>; } .ansi-blue-bg { background-color: #<span class=\"caps\">208FFB</span>; } .ansi-blue-intense-fg { color: #<span class=\"caps\">0065CA</span>; } .ansi-blue-intense-bg { background-color: #<span class=\"caps\">0065CA</span>; } .ansi-magenta-fg { color: #<span class=\"caps\">D160C4</span>; } .ansi-magenta-bg { background-color: #<span class=\"caps\">D160C4</span>; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #<span class=\"caps\">60C6C8</span>; } .ansi-cyan-bg { background-color: #<span class=\"caps\">60C6C8</span>; } .ansi-cyan-intense-fg { color: #<span class=\"caps\">258F8F</span>; } .ansi-cyan-intense-bg { background-color: #<span class=\"caps\">258F8F</span>; } .ansi-white-fg { color: #<span class=\"caps\">C5C1B4</span>; } .ansi-white-bg { background-color: #<span class=\"caps\">C5C1B4</span>; } .ansi-white-intense-fg { color: #<span class=\"caps\">A1A6B2</span>; } .ansi-white-intense-bg { background-color: #<span class=\"caps\">A1A6B2</span>; } .ansi-default-inverse-fg { color: #<span class=\"caps\">FFFFFF</span>; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #<span class=\"caps\">E3F2FD</span>; border-left-width: 1px; padding-left: 5px; border-right-color: #<span class=\"caps\">E3F2FD</span>; border-right-width: 1px; background: #<span class=\"caps\">E3F2FD</span>; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #<span class=\"caps\">42A5F5</span>; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #<span class=\"caps\">66BB6A</span>; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #<span class=\"caps\">66BB6A</span>; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #<span class=\"caps\">303F9F</span>; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In <span class=\"caps\">CM2</span>, this used to be 0.4em, but in <span class=\"caps\">CM3</span> it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In <span class=\"caps\">CM3</span> this went to 4px from 0 in <span class=\"caps\">CM2</span>. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #<span class=\"caps\">BA2121</span>; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #<span class=\"caps\">AA22FF</span>; font-weight: bold; } .highlight-meta { color: #<span class=\"caps\">AA22FF</span>; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #<span class=\"caps\">AA22FF</span>; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #<span class=\"caps\">BA2121</span>; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #<span class=\"caps\">AA22FF</span>; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but <span class=\"caps\">FF</span> barfs all over that */ height: 24em; /* <span class=\"caps\">FF</span> needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/<span class=\"caps\">FF</span> */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #<span class=\"caps\">FF0000</span> } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #<span class=\"caps\">BC7A00</span> } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #<span class=\"caps\">FF0000</span> } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #<span class=\"caps\">0044DD</span> } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #<span class=\"caps\">BA2121</span> } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #<span class=\"caps\">0000FF</span>; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #<span class=\"caps\">AA22FF</span> } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #<span class=\"caps\">D2413A</span>; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #<span class=\"caps\">0000FF</span> } /* Name.Function */ .highlight .nl { color: #<span class=\"caps\">A0A000</span> } /* Name.Label */ .highlight .nn { color: #<span class=\"caps\">0000FF</span>; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #<span class=\"caps\">AA22FF</span>; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Affix */ .highlight .sb { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Backtick */ .highlight .sc { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Char */ .highlight .dl { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Delimiter */ .highlight .sd { color: #<span class=\"caps\">BA2121</span>; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Double */ .highlight .se { color: #<span class=\"caps\">BB6622</span>; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Heredoc */ .highlight .si { color: #<span class=\"caps\">BB6688</span>; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #<span class=\"caps\">BB6688</span> } /* Literal.String.Regex */ .highlight .s1 { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #<span class=\"caps\">0000FF</span> } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #<span class=\"caps\">3E424D</span>; } .ansi-black-bg { background-color: #<span class=\"caps\">3E424D</span>; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #<span class=\"caps\">E75C58</span>; } .ansi-red-bg { background-color: #<span class=\"caps\">E75C58</span>; } .ansi-red-intense-fg { color: #<span class=\"caps\">B22B31</span>; } .ansi-red-intense-bg { background-color: #<span class=\"caps\">B22B31</span>; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #<span class=\"caps\">DDB62B</span>; } .ansi-yellow-bg { background-color: #<span class=\"caps\">DDB62B</span>; } .ansi-yellow-intense-fg { color: #<span class=\"caps\">B27D12</span>; } .ansi-yellow-intense-bg { background-color: #<span class=\"caps\">B27D12</span>; } .ansi-blue-fg { color: #<span class=\"caps\">208FFB</span>; } .ansi-blue-bg { background-color: #<span class=\"caps\">208FFB</span>; } .ansi-blue-intense-fg { color: #<span class=\"caps\">0065CA</span>; } .ansi-blue-intense-bg { background-color: #<span class=\"caps\">0065CA</span>; } .ansi-magenta-fg { color: #<span class=\"caps\">D160C4</span>; } .ansi-magenta-bg { background-color: #<span class=\"caps\">D160C4</span>; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #<span class=\"caps\">60C6C8</span>; } .ansi-cyan-bg { background-color: #<span class=\"caps\">60C6C8</span>; } .ansi-cyan-intense-fg { color: #<span class=\"caps\">258F8F</span>; } .ansi-cyan-intense-bg { background-color: #<span class=\"caps\">258F8F</span>; } .ansi-white-fg { color: #<span class=\"caps\">C5C1B4</span>; } .ansi-white-bg { background-color: #<span class=\"caps\">C5C1B4</span>; } .ansi-white-intense-fg { color: #<span class=\"caps\">A1A6B2</span>; } .ansi-white-intense-bg { background-color: #<span class=\"caps\">A1A6B2</span>; } .ansi-bold { font-weight: bold; } Note: This is the notebook of one of the project I did, it's quite long but I'm sure you'll find some good example of how text data analysis can be done with ease leveraging the power of Pandas, Sklearn, NLTK etc. 1. Overview 1.1 Dataset Selection When it comes to text data analysis practice, solid and relevant content makes it easier to figure out hidden paterns and insights. Also by picking an area where domain knowledge is strong, it makes the data analysis process less boring and more meaningful. That's why TechCrunch posts compilation is a good dataset to start. TechCrunch is known to be always up-to-date, covering new technology and rising startups 24/7, and the content is also familiar. Unlike pure text file datasets, this dataset is organized into cvs format. Besides the posts content texts, other interesting and valuable features are also included: post date, authors, category, tags, title and image source. With the abundance of features, the potential insights are quite impressive. 1.2 Potential Analysis of Dataset By analyzing the length of the posts, we can gain an idea of typical technical blog length, combined with the post date data, we can then figure out whether the technical blogging world is going towards a more lengthy way or prefer shorter, bite-sized writeups. This will provide good guidance for new bloggers or big news corporations on how long they should control their post lengths. Further, since the posts have category feature, it's possible for us to do comparison on the average post length across different topics. Giving us more insights into the post length trend per topics. We can also calculate the frequencies of words used in the posts, look at the most popular words in certain categories, this will help the writers to check if some new â€˜buzz words' are worth noticing and add to his dictionary. Combined with the post dates, valuable information about the rise or fall of certain words can be extracted from the data set, providing some interesting insights. For example, by comparing the frequencies of â€˜iOS' and â€˜Android' in â€˜apps' category posts, we can know which faction is gaining more traction in the mobile app war. We can use the tf-idf method to figure out the most unique words for each category, and develop a tags recommendation system based on our learning. Then with â€˜tags' and â€˜title' features, we can then develop an algorithm to predict possible tags, and train our algorithm with the tags and title data. Last but not least, the â€˜image source' data can tell us which category uses more images than others. By parsing and analyzing the image url data, we can figure out what's the most popular image upload/share service, and with â€˜post date' data, the trend of these services. 1.3 Business Applications This project is able to help bloggers, technical writers, website editors to track and find out the most popular words in different areas like â€˜apps', â€˜startups'. They can use the finding to enrich their vocabulary and gain better success in the future writing. The data visualization, especiall the word cloud can help the marketing managers and analyst find out the new â€˜buzz word' of the month, thus help spotting potential new opportunity. By looking at the â€˜startups' category, it can help the VC to spotting new interesting starups if its name rises in word frequency. With a little tweak of the data selection, for example if we classify the articles using â€˜author' instead of â€˜category', we can gain insights into one certain writer's vocabulary, and give suggestions on whether he has beening using one phrase a bit too much and also sugget new â€˜hot word of the month' to him, thus creating some value or SAAS he/she might willing to pay for monthly. Dataset: TechCrunch Posts Compilation URL : https://www.kaggle.com/thibalbo/techcrunch-posts-compilation BACK TO TOP 2. Data Import First we need to import all the Python modules we will need for this assignment: In [1]: import sklearn import seaborn as ans import plotly import matplotlib.pyplot as plt import pandas as pd import numpy as np % matplotlib inline Pandas can handle most of the dataset formats, JSON , csv, HTML , text, Excel, SQL etc. Here is a complete list . In [2]: %%time # using Pandas' 'read_csvâ€˜ methos to read the source dataset csv into a DataFrame object # for further processing, there are other ways to read big csv file for Python that's faster # like pandas.io.parsers.read_csv, but since our dataset is not too big, we'll just use # pandas.read_csv in this assignment df = pd . read_csv ( './techcrunch_posts.csv' ) print ( df . shape ) # We are dealing with a dataset that has 39115 entries and 11 columns. (39115, 11) CPU times: user 1.02 s, sys: 107 ms, total: 1.12 s Wall time: 1.12 s We added the Jupyter Notebook magic command â€˜%%time' to calculate time consumption of the read in process. As we can see 2s isn't too bad. In [5]: #Printing categories available. categories = { x for x in df [ 'category' ] if x == x } print ( 'There are %d categories in the dataset.' % ( len ( categories ))) There are 55 categories in the dataset. Since we want to predict the correct category for an article, we want to group our data into categories and do analysis on each category to gain insights. In [6]: # only put content texts with 'Apps' category into a list of texts raw_apps = [] for index , row in df . iterrows (): if row [ 'category' ] == 'Apps' : raw_apps . append ( row [ 'content' ]) #find out how many articles in app category and display one article to see how it looks like. print ( 'There are %d articles in catetory: Apps \\n ' % ( len ( raw_apps ))) There are 9395 articles in catetory: Apps We have 9395 posts that's in the category of â€˜apps'. We can see from above results that the raw_apps is a string of list containing all the content texts. In [7]: # put all raw content texts into a list of texts raw_content = [] for index , row in df . iterrows (): raw_content . append ( row [ 'content' ]) print ( len ( raw_content )) 39115 In [8]: # only put content texts with 'Startups' category into a list of texts raw_startups = [] for index , row in df . iterrows (): if row [ 'category' ] == 'Startups' : raw_startups . append ( row [ 'content' ]) print ( len ( raw_startups )) 2969 In [9]: # Print the number of entries for the selected categories d = [ len ( raw_startups ), len ( raw_apps )] index = [ 'Startups:' , 'Apps:' ] cat_len = pd . Series ( d , index ) cat_len . head () Out[9]: Startups: 2969 Apps: 9395 dtype: int64 Now that we've read in the data, put into Pandas DataFrame so it's easier to manipulate. Then we look at the articles in groups, read some single article etc. After some data exploration, we have a rough idea of what the dataset is and how it is organized. Let's find out what we can do with it next. BACK TO TOP 3. Data Preprocessing Now that we imported and data and gained some initial understanding of the dataset, we will be moving on to do some preprocessing 3.1 Data Subset Cleanup First of all, we will reduce the dataset size a little. In [10]: # shorten the list for better processing speed dataset = raw_apps [: 3000 ] print ( 'The length of the data set now is: %d \\n ' % ( len ( dataset ))) The length of the data set now is: 3000 In [11]: # put the list of all strings into pandas DataFrame for furthur processing. dfContent = pd . DataFrame ( dataset , columns = [ 'Content' ]) print ( dfContent . shape ) (3000, 1) Now the contents of each post is saved in a Pandas DataFrame, we will introduct NLTK to do word stemming and filter out stop words. In [12]: # import nltk stemmer import nltk from nltk.stem.porter import PorterStemmer # NLTK comes with a lot of corpora, toy grammars, trained models, etc. # A complete list is posted at: http://nltk.org/nltk_data/ # Below we just download what we need here. Punkt Tokenizer Models and stopwords for stemming nltk . download ( 'punkt' ) nltk . download ( 'stopwords' ) [nltk_data] Downloading package punkt to /home/lisper/nltk_data... [nltk_data] Package punkt is already up-to-date! [nltk_data] Downloading package stopwords to /home/lisper/nltk_data... [nltk_data] Package stopwords is already up-to-date! Out[12]: True In [13]: # import stopwords from nltk.corpus import stopwords #There is also a corpus of stopwords, that is, high-frequency words like the, to and also that # we sometimes want to filter out of a document before further processing. stop_words = stopwords . words ( 'english' ) # Stemmers remove morphological affixes from words, leaving only the word stem. porter = PorterStemmer () newContent = [] # filter out stop words for content in dfContent [ 'Content' ] . astype ( str ): # tokenize the content texts first tokens = nltk . word_tokenize ( content ) # remove punctuations wordsPunctuation = [ word for word in tokens if word . isalpha ()] # remove stop words and re=assemble words into a new content without # punctuation and stop words stop_words = set ( stopwords . words ( 'english' )) words = [ w for w in wordsPunctuation if not w . lower () in stop_words ] # stemmer_words = [porter.stem(word) for word in words] # commented the stemmer out because we want to see real words instead of root words. content = ' ' . join ( words ) newContent . append ( content ) # put the new words into Pandas DataFrame dfNewContent = pd . DataFrame ( newContent , columns = [ 'Content' ]) In [14]: print ( dfNewContent . shape ) (3000, 1) BACK TO TOP 3.2 Bag-of-Word Representation With tokenized and filtered content, we can then make it into a bag of words for further analysis. In [15]: # bag of words creation using Sklearn from sklearn.feature_extraction.text import CountVectorizer count_vect = CountVectorizer () #To count words in a document bag_words = count_vect . fit_transform ( dfNewContent [ 'Content' ] . astype ( str )) In [16]: print ( bag_words . shape ) # this is a sparse matrix (3000, 29161) In [17]: # put bag-of-words into DataFrame, since 'bag_words' is a sparse matrix, we need to run '.toarray()' function # to transfer it into array so we can put it into DataFrame df_bow = pd . DataFrame ( data = bag_words . toarray (), columns = count_vect . get_feature_names ()) In [19]: # print out 10 most common words in our data df_bow . sum () . sort_values ()[ - 10 :] Out[19]: one 4239 apps 4309 people 4721 facebook 4880 new 5958 also 5984 company 6242 users 7358 like 7440 app 11793 dtype: int64 In [20]: # print out 10 least common words in our data df_bow . sum () . sort_values ()[: 10 ] # small sample size means most words occur one time Out[20]: lice 1 node 1 nofsinger 1 defanged 1 noho 1 def 1 noisiness 1 deets 1 deepu 1 nominate 1 dtype: int64 As we can see, the most used words have â€˜new', â€˜also', â€˜like' which are not very valuable for us since these are more common words and appear in most of the articles. We still need to dig deeper to find out more unique words. That's where Tf-Idf comes in. BACK TO TOP 3.3 Tf-Idf Representation In information retrieval, tfâ€“idf or TFIDF , short for term frequencyâ€“inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. Put in human-readable words, term frequency means some word is used a lot in one documents, thus more important in weight. Inverse Document Frenquency means some word only appears in one article, thus more unique. Combine these two factors and we'll get TF - IDF , the important AND unique words. More details here . In [21]: # tf-idf creation # Good thing is we don't have to dig too deep into how it's calculated, Sklearn already did it for us from sklearn.feature_extraction.text import TfidfVectorizer tfidf_vect = TfidfVectorizer () tfidf_mat = tfidf_vect . fit_transform ( dfNewContent [ 'Content' ] . astype ( str )) In [22]: # convert to pandas to get better idea about the data df_tfidf = pd . DataFrame ( data = tfidf_mat . toarray (), columns = tfidf_vect . get_feature_names ()) In [23]: # print out 10 words with max tfidf, normalized by document occurrence df_tfidf . max () . sort_values ()[ - 10 :] Out[23]: vemory 0.857791 sosh 0.859951 quit 0.863868 dots 0.866528 drupe 0.876808 yo 0.880990 drizly 0.883821 zula 0.900980 wattpad 0.908695 nan 1.000000 dtype: float64 The results doesn't make too much sense, words like â€˜nan', â€˜yo' doesn't give us much value. We need to further fine tune our method. In [24]: # now introcucing stop words in the Tf-Idf vectorizer and max/min df # to smooth out some extremes # stop_words='english', tfidf_vect_stop = TfidfVectorizer ( stop_words = 'english' , max_df = 0.99 , min_df = 30 ) content_tfidf = tfidf_vect_stop . fit_transform ( dfNewContent [ 'Content' ] . astype ( str )) print ( content_tfidf . shape ) vec = content_tfidf . max ( axis = 0 ) df_content_tfidf = pd . DataFrame ( data = vec . toarray (), columns = tfidf_vect_stop . get_feature_names ()) df_content_tfidf . max () . sort_values ()[ - 10 :] (3000, 3285) Out[24]: wallet 0.841446 giphy 0.841934 parking 0.842608 selfie 0.842988 swarm 0.846628 water 0.851259 ebay 0.852287 emoji 0.870236 wechat 0.870539 windows 0.907426 dtype: float64 Now the results are much better, we can see â€˜emoji' as a hot word which does reflect the trend sine iOS 11 release. We also see â€˜wechat' which is a fast growing Chinese â€˜Whatsapp' alternative. The word â€˜wallet' may suggest that e-payment like Paypal or crytocurrency like BitCoin still have a lot of media coverage. BACK TO TOP 4. Data Visualization To do data visualization, first we want to write some functions that will take in the category name as a parameter, then process the data needed for visualization for that category. So we don't have to repeat the same code for each category. It is DRY , thus more Pythonic. 4.1 PreProcessing Functions In [25]: #Function to analyze any given category. from os import path from wordcloud import WordCloud #Install world cloud using pip. import matplotlib.pyplot as plt import matplotlib.pyplot as plt ; plt . rcdefaults () def analyzeCategory ( category ): raw_data = [] for index , row in df . iterrows (): if row [ 'category' ] == category : raw_data . append ( row [ 'content' ]) raw_df = pd . DataFrame ( raw_data , columns = [ 'Content' ]) analysis = {} processedDocuments = [] for content in raw_df [ 'Content' ] . astype ( str ): tokens = nltk . word_tokenize ( content ) wordsPunctuation = [ word for word in tokens if word . isalpha ()] stop_words = set ( stopwords . words ( 'english' )) #words = [w for w in tokenizedDf['tokenized_sents'][2] if not w in stop_words] words = [ w for w in wordsPunctuation if not w . lower () in stop_words ] #stemmed = [porter.stem(word) for word in words] ## We tried to implement stemmed words but we are getting weird words as outputs. #print(words) content = ' ' . join ( words ) row = [ content , len ( words )] processedDocuments . append ( row ) processedDocuments_df = pd . DataFrame ( processedDocuments , columns = [ 'Content' , 'ContentLength' ]) analysis [ 'documents' ] = processedDocuments analysis [ 'documents_df' ] = processedDocuments_df analysis [ 'stringOfContent' ] = '' . join ( analysis [ 'documents_df' ][ 'Content' ] . astype ( str )) #BagOfWords count_vect_def = CountVectorizer () analysis [ 'bag_words' ] = count_vect_def . fit_transform ( processedDocuments_df [ 'Content' ] . astype ( str )) analysis [ 'df_bow' ] = pd . DataFrame ( data = analysis [ 'bag_words' ] . toarray (), columns = count_vect_def . get_feature_names ()) #TFIDF tfidf_vect_def = TfidfVectorizer () analysis [ 'tfidf' ] = tfidf_vect_def . fit_transform ( processedDocuments_df [ 'Content' ] . astype ( str )) analysis [ 'df_tfidf' ] = pd . DataFrame ( data = analysis [ 'tfidf' ] . toarray (), columns = tfidf_vect_def . get_feature_names ()) #Frequency of words. sum_words = analysis [ 'bag_words' ] . sum ( axis = 0 ) words_freq = [( word , sum_words [ 0 , idx ]) for word , idx in tfidf_vect_def . vocabulary_ . items ()] sorted ( words_freq , key = lambda x : x [ 1 ], reverse = True ) wordFreq_df = pd . DataFrame ( sorted ( words_freq , key = lambda x : x [ 1 ], reverse = True ), columns = [ 'Word' , 'Frequency' ]) analysis [ 'wordFreq_df' ] = wordFreq_df [: 20 ] return analysis def showFreqGraph ( wordFreq_df ): #Frequency Graph objects = wordFreq_df [ 'Word' ] y_pos = np . arange ( len ( objects )) performance = wordFreq_df [ 'Frequency' ] plt . barh ( y_pos , performance , align = 'center' , alpha = 0.5 ) plt . yticks ( y_pos , objects ) plt . xlabel ( 'Frequency' ) plt . title ( 'Word Frequency' ) return plt . show () def showWordCloud ( stringOfContent ): wordcloud = WordCloud () . generate ( stringOfContent ) image = wordcloud . to_image () plt . imshow ( wordcloud , interpolation = 'bilinear' ) plt . axis ( \"off\" ) return plt . show () BACK TO TOP 4.2 Word Frequency of All Categories To get an overall idea of the word frequency across all categories, we listed the histogram and world cloud of all categories. In [26]: #Analyze all categories. meanCategoryWordCount = [] In [ ]: for category in categories : print ( \"------------------------------------------\" + category . upper () + \"------------------------------------------\" ) analysis = analyzeCategory ( category ) showFreqGraph ( analysis [ 'wordFreq_df' ]) showWordCloud ( analysis [ 'stringOfContent' ]) row = [ category , analysis [ 'documents_df' ][ 'ContentLength' ] . mean ()] meanCategoryWordCount . append ( row ) Note: We will not show the results here since it's way too long for a blog. BACK TO TOP 4.4 Article Length of Categories To find out the average article length of each categories, we visualized the histogram of content length across all categories. In [28]: #Histogram to show average content length. df_meanCategoryWordCount = pd . DataFrame ( meanCategoryWordCount , columns = [ 'Category' , 'ContentLength' ]) #Histogram for Content Length. objects = df_meanCategoryWordCount [ 'Category' ] y_pos = np . arange ( len ( objects )) performance = df_meanCategoryWordCount [ 'ContentLength' ] fig = plt . figure ( figsize = ( 10 , 10 )) ax = fig . add_subplot ( 111 ) plt . barh ( y_pos , performance , align = 'center' , alpha = 0.5 ) plt . yticks ( y_pos , objects ) plt . xlabel ( 'ContentLength' ) plt . title ( 'Average Content Length' ) plt . show () Not surprisingly, â€˜column' articles are the longest. â€˜Podcast' is the shortest since it might only contain a short intro and a link to the actual podcast! BACK TO TOP 4.5 Author Contributions It's also valuable to find out which author is the biggest contributor. We created a histogram of all authors and their number of articles. In [29]: # Aggregating articles by author and plotting contributions by each authors. df_Category = df . groupby ( by = 'authors' ) df_Category = sorted ( df_Category , # iterates pairs of (key, corresponding subDataFrame) key = lambda x : len ( x [ 1 ]), # sort by number of rows (len of subDataFrame) reverse = True ) authors = [] for val , grp in df_Category [: 10 ]: print ( 'There are' , len ( grp ), 'articles by' , val + '.' ) authors . append ([ val , len ( grp )]) df_authors = pd . DataFrame ( authors , columns = [ 'Author' , 'articles' ]) height = df_authors [ 'articles' ] bars = df_authors [ 'Author' ] y_pos = np . arange ( len ( bars )) # Create bars plt . figure ( figsize = ( 15 , 5 )) plt . bar ( y_pos , height ) # Create names on the x-axis plt . xticks ( y_pos , bars ) # Show graphic plt . show () There are 3772 articles by Sarah Perez. There are 3232 articles by Anthony Ha. There are 3026 articles by Ingrid Lunden. There are 2895 articles by Darrell Etherington. There are 2555 articles by Natasha Lomas. There are 2278 articles by Jordan Crook. There are 2245 articles by Josh Constine. There are 1885 articles by Steve O'Hear. There are 1676 articles by Rip Empson. There are 1232 articles by Romain Dillet. Drilling down to our top contributors: â€˜Sarah Perez', â€˜Anthony Ha' and â€˜Ingrid Lunden'. Let's find out what category each of them wrote the most. In [30]: #Lists all articles by category authored Sarah Perez dfAuthorCategories = df [ df [ 'authors' ] == 'Sarah Perez' ] . groupby ( by = 'category' ) dfAuthorCategories = sorted ( dfAuthorCategories , # iterates pairs of (key, corresponding subDataFrame) key = lambda x : len ( x [ 1 ]), # sort by number of rows (len of subDataFrame) reverse = True ) print ( 'Sarah Perez has authored:' ) for val , grp in dfAuthorCategories : print ( ' ' , len ( grp ), 'article/s in' , val + '.' ) Sarah Perez has authored: 2048 article/s in Apps. 385 article/s in Fundings & Exits. 290 article/s in Social. 255 article/s in Startups. 218 article/s in eCommerce. 179 article/s in Mobile. 105 article/s in Gadgets. 96 article/s in Enterprise. 61 article/s in Advertising Tech. 19 article/s in Europe. 17 article/s in Opinion. 15 article/s in Education. 11 article/s in Gaming. 9 article/s in Media. 8 article/s in Finance. 7 article/s in Developer. 4 article/s in Disrupt NY 2016. 4 article/s in GreenTech. 4 article/s in Health. 3 article/s in Collaborative Consumption. 3 article/s in Hack. 3 article/s in Security. 2 article/s in Artificial Intelligence. 2 article/s in Entertainment. 2 article/s in Events. 2 article/s in Government. 1 article/s in Disrupt SF 2016. BACK TO TOP 4.6 Topics Trend Over Time Being able to know the trend of topics over time sometime is very valuable information. It helps the editors of the website or media to better manage how much coverage each category should have. To do that, we created a series of category percentage Donut Plot to show the trend over the years of our dataset. In [31]: #Converting date to dateTimeFormat df [ 'new_date' ] = pd . to_datetime ( df [ 'date' ]) In [41]: #Plot all categories by year using Donut Plot. df_dateOfArticles = df . groupby ( df . new_date . dt . year ) for val , grp in df_dateOfArticles : print ( 'Year ' , val , ':' ) yearlyArticles = df [ df . new_date . dt . year == val ] yearlyArticles = yearlyArticles . groupby ( by = 'category' ) yearlyArticles = sorted ( yearlyArticles , # iterates pairs of (key, corresponding subDataFrame) key = lambda x : len ( x [ 1 ]), # sort by number of rows (len of subDataFrame) reverse = True ) yearlyCategories = [] for val , grp in yearlyArticles [: 10 ]: #print('There are',len(grp),'articles about',val +'.') yearlyCategories . append ([ val , len ( grp )]) df_yearlyCategories = pd . DataFrame ( yearlyCategories , columns = [ 'Category' , 'Count' ]) # Create a circle for the center of the plot my_circle = plt . Circle ( ( 0 , 0 ), 0.7 , color = 'white' ) # Give color names plt . pie ( df_yearlyCategories [ 'Count' ], labels = df_yearlyCategories [ 'Category' ]) p = plt . gcf () p . gca () . add_artist ( my_circle ) plt . show () Year 2010 : Year 2011 : Year 2012 : Year 2013 : Year 2014 : Year 2015 : Year 2016 : From the graphs we can see that â€˜social' is most popular around 2012 and shrinked down every year, while â€˜apps' is a rising star from 2012 and keeping the momentum till 2016. BACK TO TOP 5. Reference [1] Sebastian Raschka, \"Python Machine Learning\" BACK TO TOP In [ ]: if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Machine Learning","url":"MLN-Text-data-analysis"},{"title":"Setup Data Science Blog with Pelican + GitHub Pages","text":"First of all, this is by no means a thorough tutorial. I've followed Dataquest's blog post: Building a data science portfolio: Making a data science blog to get this one setup. Here are some insights and hiccups that may be helpful to others who want to do the same thing. Static sites and static sites generator If you have never experienced the web development world, static site might be a new word to you. Actually it's quite simple, it's just plan web-site with HTML files, CSS sheets and Javascript files. These file never changes unless you make them, thus the word â€˜static'. The â€˜dynamic' site, on the other hand, use database and complex post-end technology to â€˜dynamically' generate these HTML / CSS /Javascripts files. It's much harder to develop and maintain. But I don't want that complexity you say. I just want to write something and post them and make them look neat. Then, my friend, look no further than a static site. Good news to us, there are a lot of static sites generators out there that can help us do the heavy-lifting of developing a website. The static sites generators come with many flavors, Jekyell(based on Ruby) , Pelican(based on Python are too popular one. Since I'm more familiar with Python. I decided to use Pelican to build my data science blog. The beautiful thing here is, since Pelican is written in Python, it's quite easy to make it work with Jupyter Notebook, which is a huge bonus for data science. This means you can write your blog posts using Jupyter Notebook, leverage all the powerful snippets, data visualization and code executing it has and roll all those into your post, with ease. Install Pelican Usually install Pelican will be easy, but if we also want to support Jupyter Notebook it will be harder. Many python modules will need to be installed using pip . Here is a list I used: Markdown == 2 .6.6 # Markdown support pelican == 3 .6.3 # Pelican itself jupyter> = 1 .0 # Jupyter Notebook ipython> = 4 .0 # iPython nbconvert> = 4 .0 # beautifulsoup4 # not sure why we need pharsing here, maybe manipulating codes ghp-import == 0 .4.1 #handle git branches matplotlib == 1 .5.1 #data visualization Once all are installed, run: pelican-quickstart Answer couple of questions and the backbone of your site is up. To make the Jupyter Notebook part work, we will need this Pelican plugin (yes, Pelican support plugins!): Pelican-ipynb . Once installed, activate the plugin in your pelicanconf.py . This is your dot file, and you'll be dealig with it a lot later on. Add these into the bottom: MARKUP = ( 'md' , 'ipynb' ) PLUGIN_PATH = './plugins' PLUGINS = [ 'ipynb.markup' ] Write Post Well this is the easier part. Just put your Jupyter Notebook file into the 'content' folder. Also, for each post, we'll need a meta file to include some meta data of the post. The meta file should have the extension: .ipynb-meta . Here is an example: Title : First Post Slug : first - post Date : 2016 - 06 - 08 20 : 00 Category : posts Tags : python firsts author : Vik Paruchuri Summary : My first post , read it to find out . It's quite easy to figure out what they are so I won't bother explain here. When done, save. Generating HTML Exit out of content folder, and run pelican content to generate the HTML . Enter output again and run: python -m pelican.server Then visit: localhost:8000 to see your new site. Putting it on GitHub Pages Create a GitHub Page is simple and there are many tutorials out there. Once created, edit your SITEURL in publishconf.py file, make it into https://username.github.io , substitute username with your site name. Run pelican content -s publishconf.py to generate the real stuff. Run ghp-import output -b master to import everything into the output folder to the master branch. Run git push origin master to push changes to GitHub repo. Themes There are a lot of themes to choose from. What you need to do is to configure your pelicanconf.py file and assign the theme name. Some themes may need to install extra Python modules or have access to other services to work. But overall the process is straight forward. Google Analytics Pelican have Google Analytics support out of the box. Register the site on GA , then get the UA-XXXXxxxxx id, put it into the pelicanconf.py file and you're golden. Disqus Disqus support come out of the box too. Register the site on Disqus, get your shortname correct, and put into pelicanconf.py and you should be good too. Some turorial suggest put into publishconf.py , well mine only works on pelicanconf.py so use your own judgement. SEO Basic SEO can be achieved using sitemap plugin. Search for it and put into pelicanconf.py , it will work automatically. Conclusion Overall the process is not hard at all. Once everything is set. Just focus on putting in solid content using Jupyter Notebook. Enjoy coding, visualizing and writing!","tags":"Tools","url":"Setup-Pelican-1"},{"title":"Machine Learning Notes : Numpy and Pandas","text":"/*! * * IPython notebook * */ /* <span class=\"caps\">CSS</span> font colors for translated <span class=\"caps\">ANSI</span> escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #<span class=\"caps\">3E424D</span>; } .ansi-black-bg { background-color: #<span class=\"caps\">3E424D</span>; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #<span class=\"caps\">E75C58</span>; } .ansi-red-bg { background-color: #<span class=\"caps\">E75C58</span>; } .ansi-red-intense-fg { color: #<span class=\"caps\">B22B31</span>; } .ansi-red-intense-bg { background-color: #<span class=\"caps\">B22B31</span>; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #<span class=\"caps\">DDB62B</span>; } .ansi-yellow-bg { background-color: #<span class=\"caps\">DDB62B</span>; } .ansi-yellow-intense-fg { color: #<span class=\"caps\">B27D12</span>; } .ansi-yellow-intense-bg { background-color: #<span class=\"caps\">B27D12</span>; } .ansi-blue-fg { color: #<span class=\"caps\">208FFB</span>; } .ansi-blue-bg { background-color: #<span class=\"caps\">208FFB</span>; } .ansi-blue-intense-fg { color: #<span class=\"caps\">0065CA</span>; } .ansi-blue-intense-bg { background-color: #<span class=\"caps\">0065CA</span>; } .ansi-magenta-fg { color: #<span class=\"caps\">D160C4</span>; } .ansi-magenta-bg { background-color: #<span class=\"caps\">D160C4</span>; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #<span class=\"caps\">60C6C8</span>; } .ansi-cyan-bg { background-color: #<span class=\"caps\">60C6C8</span>; } .ansi-cyan-intense-fg { color: #<span class=\"caps\">258F8F</span>; } .ansi-cyan-intense-bg { background-color: #<span class=\"caps\">258F8F</span>; } .ansi-white-fg { color: #<span class=\"caps\">C5C1B4</span>; } .ansi-white-bg { background-color: #<span class=\"caps\">C5C1B4</span>; } .ansi-white-intense-fg { color: #<span class=\"caps\">A1A6B2</span>; } .ansi-white-intense-bg { background-color: #<span class=\"caps\">A1A6B2</span>; } .ansi-default-inverse-fg { color: #<span class=\"caps\">FFFFFF</span>; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #<span class=\"caps\">E3F2FD</span>; border-left-width: 1px; padding-left: 5px; border-right-color: #<span class=\"caps\">E3F2FD</span>; border-right-width: 1px; background: #<span class=\"caps\">E3F2FD</span>; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #<span class=\"caps\">42A5F5</span>; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #<span class=\"caps\">66BB6A</span>; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #<span class=\"caps\">66BB6A</span>; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #<span class=\"caps\">303F9F</span>; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In <span class=\"caps\">CM2</span>, this used to be 0.4em, but in <span class=\"caps\">CM3</span> it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In <span class=\"caps\">CM3</span> this went to 4px from 0 in <span class=\"caps\">CM2</span>. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #<span class=\"caps\">BA2121</span>; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #<span class=\"caps\">AA22FF</span>; font-weight: bold; } .highlight-meta { color: #<span class=\"caps\">AA22FF</span>; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #<span class=\"caps\">AA22FF</span>; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #<span class=\"caps\">BA2121</span>; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #<span class=\"caps\">AA22FF</span>; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but <span class=\"caps\">FF</span> barfs all over that */ height: 24em; /* <span class=\"caps\">FF</span> needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/<span class=\"caps\">FF</span> */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #<span class=\"caps\">FF0000</span> } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #<span class=\"caps\">BC7A00</span> } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #<span class=\"caps\">FF0000</span> } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #<span class=\"caps\">0044DD</span> } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #<span class=\"caps\">BA2121</span> } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #<span class=\"caps\">0000FF</span>; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #<span class=\"caps\">AA22FF</span> } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #<span class=\"caps\">D2413A</span>; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #<span class=\"caps\">0000FF</span> } /* Name.Function */ .highlight .nl { color: #<span class=\"caps\">A0A000</span> } /* Name.Label */ .highlight .nn { color: #<span class=\"caps\">0000FF</span>; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #<span class=\"caps\">AA22FF</span>; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Affix */ .highlight .sb { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Backtick */ .highlight .sc { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Char */ .highlight .dl { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Delimiter */ .highlight .sd { color: #<span class=\"caps\">BA2121</span>; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Double */ .highlight .se { color: #<span class=\"caps\">BB6622</span>; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Heredoc */ .highlight .si { color: #<span class=\"caps\">BB6688</span>; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #<span class=\"caps\">BB6688</span> } /* Literal.String.Regex */ .highlight .s1 { color: #<span class=\"caps\">BA2121</span> } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #<span class=\"caps\">0000FF</span> } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #<span class=\"caps\">3E424D</span>; } .ansi-black-bg { background-color: #<span class=\"caps\">3E424D</span>; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #<span class=\"caps\">E75C58</span>; } .ansi-red-bg { background-color: #<span class=\"caps\">E75C58</span>; } .ansi-red-intense-fg { color: #<span class=\"caps\">B22B31</span>; } .ansi-red-intense-bg { background-color: #<span class=\"caps\">B22B31</span>; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #<span class=\"caps\">DDB62B</span>; } .ansi-yellow-bg { background-color: #<span class=\"caps\">DDB62B</span>; } .ansi-yellow-intense-fg { color: #<span class=\"caps\">B27D12</span>; } .ansi-yellow-intense-bg { background-color: #<span class=\"caps\">B27D12</span>; } .ansi-blue-fg { color: #<span class=\"caps\">208FFB</span>; } .ansi-blue-bg { background-color: #<span class=\"caps\">208FFB</span>; } .ansi-blue-intense-fg { color: #<span class=\"caps\">0065CA</span>; } .ansi-blue-intense-bg { background-color: #<span class=\"caps\">0065CA</span>; } .ansi-magenta-fg { color: #<span class=\"caps\">D160C4</span>; } .ansi-magenta-bg { background-color: #<span class=\"caps\">D160C4</span>; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #<span class=\"caps\">60C6C8</span>; } .ansi-cyan-bg { background-color: #<span class=\"caps\">60C6C8</span>; } .ansi-cyan-intense-fg { color: #<span class=\"caps\">258F8F</span>; } .ansi-cyan-intense-bg { background-color: #<span class=\"caps\">258F8F</span>; } .ansi-white-fg { color: #<span class=\"caps\">C5C1B4</span>; } .ansi-white-bg { background-color: #<span class=\"caps\">C5C1B4</span>; } .ansi-white-intense-fg { color: #<span class=\"caps\">A1A6B2</span>; } .ansi-white-intense-bg { background-color: #<span class=\"caps\">A1A6B2</span>; } .ansi-bold { font-weight: bold; } Overview This will be a series of notes to record the thinking and learning of my Machine Learning journey. Hopefully it can serve as a place to record the learning process/progress as well as providing some reference for others just entering this field. Numpy Basics Numpy is a powerful module of Python. It covers a lot of basics of Linear algebra, and are great when it comes to doing sceintific and mathematical calculations. That's why it is the â€˜go-to' solution for Machine Learning. There are other â€˜highler-level' and more dedicated modules out there like Pandas, seaborn that also utilize or even built on Numpy. Thus proves the powerfulness of Numpy in another way. Though works mostly on the fundation level, Numpy should be considered an equivelant to other more â€˜advanced' modules and whichever fits the most to solve the problem at hand should be used. Without further ado, let's jump right into some code In [1]: import numpy as np # use 'np' to represent Numpy is kind of a coding convention print ( 'Numpy version: ' , np . __version__ ) Numpy version: 1.13.3 Now it's imported, let's use it to do some basic stuffs. In [2]: x = np . random . rand ( 5 , 3 ) x Out[2]: array([[ 0.06584995, 0.58936577, 0.02054667], [ 0.90132301, 0.62575129, 0.76350867], [ 0.70707616, 0.19462487, 0.35358817], [ 0.44329537, 0.57977487, 0.78594087], [ 0.76109628, 0.86614311, 0.51521077]]) Manipulate with array is what Numpy do best. Here we generated an 5 row 3 columns array of randome numbers (from 0 to 1) In [3]: print ( x . shape ) print ( x . dtype ) (5, 3) float64 We can look at the shape of an array and what data type it is. Obviously it's a float since it's generated from np.random.rand. In [4]: y = np . random . rand ( 3 , 4 ) z = np . dot ( x , y ) z Out[4]: array([[ 0.60055916, 0.43108417, 0.35430406, 0.32056793], [ 2.10608162, 0.91944706, 0.73772388, 1.22819697], [ 1.1554381 , 0.48784172, 0.3088563 , 0.63719203], [ 1.66918268, 0.69113499, 0.68490871, 1.04397122], [ 1.95288349, 0.98819028, 0.76639304, 1.09896047]]) Doing some good old dot product. In [6]: z = x @ y z Out[6]: array([[ 0.60055916, 0.43108417, 0.35430406, 0.32056793], [ 2.10608162, 0.91944706, 0.73772388, 1.22819697], [ 1.1554381 , 0.48784172, 0.3088563 , 0.63719203], [ 1.66918268, 0.69113499, 0.68490871, 1.04397122], [ 1.95288349, 0.98819028, 0.76639304, 1.09896047]]) Or more intuitively use â€˜@' operand. How to index Numpy array First create a sample array using np.array function. In [7]: x1 = np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ], [ 7 , 8 , 9 ]]) x1 Out[7]: array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) Array[row, col] represent array element in â€˜row' and â€˜col'. Note that In [8]: x1 [ 1 , 1 ] #row 1, col 1, since Python list starts from 0, so it's 2nd row and col; Out[8]: 5 In [9]: x1 [:, 2 ] #':' means all elements, so this means all elements on 3rd column, let's see Out[9]: array([3, 6, 9]) In [10]: x1 [:, 1 ] > 3 # an array condition equation will generate an array of boolean values; Out[10]: array([False, True, True], dtype=bool) In [11]: x1 [ x1 [:, 1 ] > 3 ] # This means index the rows that the 2nd column is greater than 3; Out[11]: array([[4, 5, 6], [7, 8, 9]]) Shape Manipulations In [12]: x1 . reshape ( 9 ) #reshape x1 into one row Out[12]: array([1, 2, 3, 4, 5, 6, 7, 8, 9]) In [13]: x1 . reshape ( 3 , 3 ) #reshape back to 3x3 Out[13]: array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) In [14]: x1 . reshape ( 9 , 1 ) #reshape into 9x1 Out[14]: array([[1], [2], [3], [4], [5], [6], [7], [8], [9]]) Dot and Mutiplication In [15]: x2 = np . arange ( 9 ) . reshape ( 3 , 3 ) x2 Out[15]: array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) In [16]: multi = x1 * x2 dot = np . dot ( x1 , x2 ) print ( 'x1 * x2 =' , multi ) print ( 'x1 dot x2 =' , dot ) x1 * x2 = [[ 0 2 6] [12 20 30] [42 56 72]] x1 dot x2 = [[ 24 30 36] [ 51 66 81] [ 78 102 126]] Pandas Basics In [17]: # set some basic data col_names = [ 'temperature' , 'time' , 'day' ] data = np . array ([[ 64 , 2100 , 1 ], [ 50 , 2200 , 1 ], [ 48 , 2300 , 1 ], [ 34 , 0 , 2 ], [ 30 , 100 , 5 ]]) data Out[17]: array([[ 64, 2100, 1], [ 50, 2200, 1], [ 48, 2300, 1], [ 34, 0, 2], [ 30, 100, 5]]) In [18]: # explore the data using numpy, it's clumsy data2 = data [ data [:, 1 ] > 1500 ] data2 Out[18]: array([[ 64, 2100, 1], [ 50, 2200, 1], [ 48, 2300, 1]]) In [19]: # now let's try use Pandas import pandas as pd df = pd . DataFrame ( data , columns = col_names ) df Out[19]: .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } temperature time day 0 64 2100 1 1 50 2200 1 2 48 2300 1 3 34 0 2 4 30 100 5 Pandas DataFrame will put all the data into a much nicer form with neat labels In [20]: df [ df . time > 1500 ] #Now do it again with data exploration, this time using Pandas DataFrame Out[20]: .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } temperature time day 0 64 2100 1 1 50 2200 1 2 48 2300 1 Much nicer! In [22]: # now let's get some basic info of the DataFrame df . info () df . describe () <class 'pandas.core.frame.DataFrame'> RangeIndex: 5 entries, 0 to 4 Data columns (total 3 columns): temperature 5 non-null int64 time 5 non-null int64 day 5 non-null int64 dtypes: int64(3) memory usage: 200.0 bytes Out[22]: .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } temperature time day count 5.000000 5.00000 5.000000 mean 45.200000 1340.00000 2.000000 std 13.608821 1180.25421 1.732051 min 30.000000 0.00000 1.000000 25% 34.000000 100.00000 1.000000 50% 48.000000 2100.00000 1.000000 75% 50.000000 2200.00000 2.000000 max 64.000000 2300.00000 5.000000 In [23]: # you can change the element in DataFrame like so: df . day [ df . day == 1 ] = 'Mon' df Out[23]: .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } temperature time day 0 64 2100 Mon 1 50 2200 Mon 2 48 2300 Mon 3 34 0 2 4 30 100 5 In [24]: # or do it the Pandas way df . day . replace ( to_replace = range ( 7 ), value = [ 'Su' , 'Mon' , 'Tues' , 'Wed' , 'Th' , 'Fri' , 'Sat' ], inplace = True ) df Out[24]: .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } temperature time day 0 64 2100 Mon 1 50 2200 Mon 2 48 2300 Mon 3 34 0 Tues 4 30 100 Fri In [25]: # one hot encoding example pd . get_dummies ( df . day ) Out[25]: .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } Fri Mon Tues 0 0 1 0 1 0 1 0 2 0 1 0 3 0 0 1 4 1 0 0 In [ ]: if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Machine Learning","url":"MLN-Numpyandpandas"}]}