<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Michael Li" />

        <meta name="description" content="Described how to build a multi-label toxic comments classifier from scratch usingÂ fast.ai
" />
        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Machine Learning, AI, NLP, fast.ai, Deep Learning, Machine Learning, " />

<meta property="og:title" content="Attack Toxic Comments Kaggle Competition usingÂ Fast.ai  - How to build a multi-label NLP classifier from scratch "/>
<meta property="og:url" content="https://wayofnumbers.com/attack-toxic-comments-kaggle-competition-using-fast-ai" />
<meta property="og:description" content="Described how to build a multi-label toxic comments classifier from scratch usingÂ fast.ai" />
<meta property="og:site_name" content="Way of Numbers" />
<meta property="og:article:author" content="Michael Li" />
<meta property="og:article:published_time" content="2019-10-08T20:00:00-05:00" />
<meta name="twitter:title" content="Attack Toxic Comments Kaggle Competition usingÂ Fast.ai  - How to build a multi-label NLP classifier from scratch ">
<meta name="twitter:description" content="Described how to build a multi-label toxic comments classifier from scratch usingÂ fast.ai">
<meta property="og:image" content="/theme/images/apple-touch-icon-152x152.png" />
<meta name="twitter:image" content="/theme/images/apple-touch-icon-152x152.png" >

        <title>Attack Toxic Comments Kaggle Competition usingÂ Fast.ai  - How to build a multi-label NLP classifier from scratch  Â· Way of Numbers
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="https://wayofnumbers.com/theme/css/elegant.prod.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://wayofnumbers.com/theme/css/custom.css" media="screen">

        <link rel="shortcut icon" href="https://wayofnumbers.com/theme/images/favicon.ico" type="image/x-icon" />
        <link rel="icon" href="https://wayofnumbers.com/theme/images/apple-touch-icon-152x152.png" type="image/png" />
        <link rel="apple-touch-icon" href="https://wayofnumbers.com/theme/images/apple-touch-icon.png"  type="image/png" />
        <link rel="apple-touch-icon" sizes="57x57" href="https://wayofnumbers.com/theme/images/apple-touch-icon-57x57.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="72x72" href="https://wayofnumbers.com/theme/images/apple-touch-icon-72x72.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="76x76" href="https://wayofnumbers.com/theme/images/apple-touch-icon-76x76.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="114x114" href="https://wayofnumbers.com/theme/images/apple-touch-icon-114x114.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="120x120" href="https://wayofnumbers.com/theme/images/apple-touch-icon-120x120.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="144x144" href="https://wayofnumbers.com/theme/images/apple-touch-icon-144x144.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="152x152" href="https://wayofnumbers.com/theme/images/apple-touch-icon-152x152.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="152x152" href="https://wayofnumbers.com/theme/images/apple-touch-icon-180x180.png" type="image/png" />
        <link href="https://wayofnumbers.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Way of Numbers - Full Atom Feed" />
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-148798026-1', 'auto');
    ga('send', 'pageview');
</script>


    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://wayofnumbers.com/"><span class=site-name>Way of Numbers</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://wayofnumbers.com
                                    >Home</a>
                                </li>
                                <li ><a href="https://wayofnumbers.com/about-me">About&nbsp;Me</a></li>
                                <li ><a href="https://wayofnumbers.com/categories">Categories</a></li>
                                <li ><a href="https://wayofnumbers.com/tags">Tags</a></li>
                                <li ><a href="https://wayofnumbers.com/archives">Archives</a></li>
                                <li><form class="navbar-search" action="https://wayofnumbers.com/search" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://wayofnumbers.com/attack-toxic-comments-kaggle-competition-using-fast-ai">
                Attack Toxic Comments Kaggle Competition using&nbsp;Fast.ai
                <small class="subtitle">
                    How to build a multi-label NLP classifier from scratch
                </small>
            </a>
        </h1>
    </header>
</div>


<div class="row-fluid">
    <div class="span2 table-of-content">
        <nav>
        <h4>Contents</h4>
        <div class="toc">
<ul>
<li><a href="#the-data-set">The DataÂ Set</a></li>
<li><a href="#look-at-the-data">Look at theÂ Data</a></li>
<li><a href="#transfer-learning-fine-tune-our-language-model">Transfer Learning: Fine-Tune Our LanguageÂ Model</a></li>
<li><a href="#transfer-learning-training-the-classifier">Transfer Learning: Training theÂ Classifier</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
</div>
        </nav>
    </div>
    <div class="span8 article-content">
            
            
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/0*SxwidHTBf5ZSysg9.jpg"/></p>
<p><a href="http://www.kaggle.com">Kaggle</a> is a good place to learn and practice your Machine Learning skills. Itâ€™s also a great place to find the proper dataset for your learning projects. I need a good classification <span class="caps">NLP</span> dataset to practice my recently learned fast.ai lesson, and I came across the <a href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge">Toxic Comment Classification Challenge</a>. The competition is held two years ago and has long concluded, but it doesnâ€™t hurt to submit my scores and see how well I did. This is one of the things Kaggle is great for since in the real world, it will usually be much harder to know how good or bad your model is, whereas, in Kaggle, youâ€™ll see clearly where your performance is in theÂ Leaderboard.</p>
<h2 id="the-data-set">The Data Set<a class="headerlink" href="#the-data-set" title="Permanent link"> </a></h2>
<p>This competition is held by The <a href="https://conversationai.github.io/">Conversation <span class="caps">AI</span></a> team, a research initiative founded by <a href="https://jigsaw.google.com/">Jigsaw</a> and Google (both a part of Alphabet). Its goal is to find out the best model that can classify multiple toxicity types in comments. The toxicity typesÂ are:</p>
<blockquote>
<p>toxic
severe_toxic
obscene
threat
insultÂ indentity_hate</p>
</blockquote>
<p>Comments are given in a training file train.cvs and a testing file test.csv. And youâ€™ll need to predict a probability of each type of toxicity for each comment in test.csv. It is a multi-label <span class="caps">NLP</span> classificationÂ problem.</p>
<h2 id="look-at-the-data">Look at the Data<a class="headerlink" href="#look-at-the-data" title="Permanent link"> </a></h2>
<p>Letâ€™s first take a look at the data. We need to import the necessary modules and do some logistics to set up the paths for ourÂ files.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span> <span class="o">*</span><span class="c1"># linear algebra*</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span> <span class="o">*</span><span class="c1"># data processing, CSV file I/O (e.g. pd.read_csv)</span>
<span class="o">*</span><span class="kn">from</span> <span class="nn">fastai.text</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">fastai</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
<p>Notice here we imported everything from fastai.text and fastai modules. Are we against the software engineering best practice here? Actually, not quite. Itâ€™s rather a deliberate move in a more iterative and interactive data science kind of way. With all the library available, I can easily test and try different functions/modules without having to go back and import them every time. It will make the explore/experiment flow much more smoothly. But I digressed, letâ€™s load the data and look atÂ it:</p>
<div class="highlight"><pre><span></span># Kaggle store dataset in the /kaggle/input/ folder,
path = Path('/kaggle/input/jigsaw-toxic-comment-classification-challenge/')
path.ls()

# the /kaggle/input/ folder is read-only, copy away so I can also write to the folder. 
!mkdir data
!cp -a {path}/*.* ./data/
!ls data

# make sure everything is correctly copied over
path = Path('/kaggle/working/data/')
path.ls()

# read in the data and have a peak
df = pd.read_csv(path/'train.csv')
df.head()
</pre></div>
<p><img alt="The toxicity types are one-hot encoded" src="https://cdn-images-1.medium.com/max/2000/1*XhZcKKIvj9-r0RmksgoYXQ.png"/><em>The toxicity types are one-hotÂ encoded</em></p>
<p>The comments are in comment_text column and all toxicity types are â€˜one-hotâ€™ encoded, weâ€™ll have to do something about it to make it fit into our modelÂ later.</p>
<p><img alt="Have a look at one comment" src="https://cdn-images-1.medium.com/max/2000/1*9hNkR1Z0Y279_xNxfZ-bMw.png"/><em>Have a look at oneÂ comment</em></p>
<h2 id="transfer-learning-fine-tune-our-language-model">Transfer Learning: Fine-Tune Our Language Model<a class="headerlink" href="#transfer-learning-fine-tune-our-language-model" title="Permanent link"> </a></h2>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/0*ZItmfFjXqRgyJIbw.jpg"/></p>
<p>Weâ€™ll use transfer learning for this task, to do that, weâ€™ll use a pre-trained model based on Wikipedia called <a href="https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset">wikitext-103</a>. It is a model thatâ€™s already trained from the Wikipedia dataset(or â€˜corpusâ€™ in <span class="caps">NLP</span> terms) to predict the next words from a giving unfinished sentence. Weâ€™ll leverage the â€˜language knowledgeâ€™ the model already learned from the Wikipedia dataset and build on top of that. To achieve the best results, weâ€™ll need to â€˜fine-tuneâ€™ the model to make it learn a bit from our â€˜commentsâ€™ dataset since what people say in the comments are not necessarily the same with the more formal Wiki. Once the language model is fine-tuned, we can then use it to further do our classificationÂ task.</p>
<p>Now letâ€™s load the training data into the fast.ai databunch so we can start training the language modelÂ first.</p>
<div class="highlight"><pre><span></span>bs = 64   # set batch size to 64, works for Kaggle Kernels
data_lm = (TextList.from_df(df, path, cols='comment_text')
                .split_by_rand_pct(0.1)
                .label_for_lm()
                .databunch(bs=bs))
</pre></div>
<p>We use fast.aiâ€™s Data Block <span class="caps">API</span> for this task. It is a very flexible and powerful way to address the challenging task of building a pipeline: loading your data into the model. It isolates the entire process into different parts/steps, each step with multiple methods/functions to adapt to different types of data and the ways data is stored. This concept is a lot like the Linux philosophy, highly modulized and with each module only do one thing but really really well. You are free to explore the wonderful <span class="caps">API</span> <a href="https://docs.fast.ai/data_block.html">here</a>, for the above code though, it does the followingÂ things:</p>
<ol>
<li>
<p>Import data from Pandas DataFrame named df, tell the model to use comment_text as input (TextList.from_df(df, path,Â cols=â€™comment_textâ€™))</p>
</li>
<li>
<p>Split the training dataset into train/validation set by random 10/90 percent.Â (.split_by_rand_pct(0.1))</p>
</li>
<li>
<p>Ignore the given labels( since we are only fine-tuning the language model, not training the classifier yet) and use the language modelâ€™s â€˜predict next wordâ€™ as labels.Â (.label_for_lm())</p>
</li>
<li>
<p>Build the data into a databunch, with batch size bs.Â (.databunch(bs=bs))</p>
</li>
</ol>
<p>Now letâ€™s look at the databunch we justÂ built:</p>
<p><img alt="Notice we lost all the toxicity types" src="https://cdn-images-1.medium.com/max/2000/1*tZb2mpF3ybJizigXjZD7Vw.png"/><em>Notice we lost all the toxicityÂ types</em></p>
<p>Notice that the databunch doesnâ€™t have all the toxicity type labels since we are only fine-tuning the languageÂ model.</p>
<p><span class="caps">OK</span>, time for some typical fast.ai learning rate adjustments andÂ training:</p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*vKptpwNJ5yj-ufCweNY5cQ.png"/></p>
<p>We put our databunch into a language_model_learner, tell it the language model base we want to use (AWD_LSTM) and assign a default dropout rate of <strong>0.3</strong>. From the <span class="caps">LR</span> Finder graph, find the biggest downward slope and pick the middle point as our learning rate. (For a more detailed explanation of how this â€˜fit_one_cycleâ€™ magic is done, please refer to this <a href="https://docs.fast.ai/callbacks.one_cycle.html#What-is-1cycle?">article</a>. It is a <span class="caps">SOTA</span> technique of fast.ai that combines learning rate and momentum annealing). Now we can â€˜unfreezeâ€™ the model and train the entire model couple ofÂ epochs:</p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*pQRrm9fcMkRua9k9LbBbzA.png"/></p>
<p>We can look at one example of how well the modelÂ did:</p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*UCNNMwGBhh7oxbRIMxg7Pg.png"/></p>
<p>The result is hardly optimal. Ideally, we need to train a bit more epochs but for this Kaggle Kernel, I was running out of <span class="caps">GPU</span> quota so I stopped at 4. The result definitely has room to improve and you can try it yourself. Anyway, what we want from the language model is the encoder part, so we saveÂ it.</p>
<div class="highlight"><pre><span></span>*# save the encoder for next step use*
learn.save_encoder('fine_tuned_enc')
</pre></div>
<h2 id="transfer-learning-training-the-classifier">Transfer Learning: Training the Classifier<a class="headerlink" href="#transfer-learning-training-the-classifier" title="Permanent link"> </a></h2>
<p>Letâ€™s read in the testÂ dataset:</p>
<div class="highlight"><pre><span></span>test = pd.read_csv(path/"test.csv")
test_datalist = TextList.from_df(test, cols='comment_text')
</pre></div>
<p>Again, build ourÂ databunch:</p>
<div class="highlight"><pre><span></span>data_cls = (TextList.from_csv(path, 'train.csv', cols='comment_text')
                .split_by_rand_pct(valid_pct=0.1)
                .label_from_df(cols=['toxic', 'severe_toxic','obscene', 'threat', 'insult', 'identity_hate'], label_cls=MultiCategoryList, one_hot=True)
                .add_test(test_datalist)
                .databunch())
data_cls.save('data_clas.pkl')
</pre></div>
<p>Please note the difference thisÂ time:</p>
<ol>
<li>
<p>We now use all our toxicity styles labels (.label_from_df(cols=[â€˜toxicâ€™, â€˜severe_toxicâ€™,â€™obsceneâ€™, â€˜threatâ€™, â€˜insultâ€™, â€˜identity_hateâ€™],label_cls=MultiCategoryList,Â one_hot=True),)</p>
</li>
<li>
<p>We added our test set here.Â (.add_test(test_datalist))</p>
</li>
</ol>
<p>Now look at our classifier databunchÂ :</p>
<p><img alt="Note that now we have all the toxicity styles labels" src="https://cdn-images-1.medium.com/max/2000/1*47Wryn1f-yDMfiu3l-bXMA.png"/><em>Note that now we have all the toxicity stylesÂ labels</em></p>
<p><strong>Finally, time to put everything together!</strong> Weâ€™ll put the databunch into the text_classifier_learner model and load the encoder we learned from the languageÂ model.</p>
<div class="highlight"><pre><span></span>learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)
learn.load_encoder('fine_tuned_enc')
</pre></div>
<p>Again, find the best learning rate and train oneÂ cycle:</p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*xXpZwueb6Yec9TvVvJN7SA.png"/></p>
<p>Train a bit more cycles andÂ unfreeze:</p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*GcvvzZNPv9Qe1M1bwvcjEA.png"/></p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*2Ny7Ka7Ewv6b_0TH8R8RsA.png"/></p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*BWi5dpbgRmwyvr7VQdh59A.png"/></p>
<p>See theÂ results:</p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*vePv-fiRXOukp3ZgteqwnA.png"/></p>
<p>Off by one, but overall the prediction is <span class="caps">OK</span>. For the purpose of reference, I submitted the prediction to Kaggle and get a 0.96583 Public Score. The result is not optimal but like I said I didnâ€™t train all the way due to limited <span class="caps">GPU</span>. The purpose of this article is to show you the whole process of using fast.ai to tackle multi-labels text classification problem. The real challenge here is to load the data into the model using Data Block <span class="caps">API</span>.</p>
<h2 id="conclusion">Conclusion<a class="headerlink" href="#conclusion" title="Permanent link"> </a></h2>
<p>I hope you learned a thing or two from this article. Fast.ai is really a lean, flexible and powerful library. For the things it can do (like image/text classification, tabular data, collaborative filtering, etc.), it does it very well. It is not as extensive as Keras, but itâ€™s very sharp and focused. Kind of like Vim and Emacs if you are familiar with the command line text editor war.Â ğŸ˜œ</p>
<blockquote>
<p>You can find the Kaggle Kernel <a href="https://www.kaggle.com/lymenlee/toxic-comments-classification-fast-ai">here</a>.</p>
</blockquote>
<p>Any feedback or constructive criticism is welcomed. You can either find me on Twitter <a href="https://twitter.com/lymenlee">@lymenlee</a> or my blog site <a href="https://wayofnumbers.com/">wayofnumbers.com</a>.</p>


             
 
            
                <hr />
    <div class="author_blurb">
        <a href="https://medium.com/@lymenlee" target="_blank" rel="nofollow noopener noreferrer">
            <img src=/images/avatars/michael.png alt="Michael Li Avatar" title="Michael Li">
            <span class="author_name">Michael Li</span>
        </a>
        is the creator and lead developer of this site.
    </div>

            






            <hr/>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="previous-article">Â« <a href="https://wayofnumbers.com/9-things-i-learned-from-blogging-on-medium-for-the-first-month" title="Previous: 9 Things I Learned from Blogging on Medium for the FirstÂ Month - Why Medium is a good platform to exchange ideas">9 Things I Learned from Blogging on Medium for the FirstÂ Month <small class="subtitle">Why Medium is a good platform to exchange ideas</small></a></li>
                <li class="next-article"><a href="https://wayofnumbers.com/this-is-cs50-a-pleasant-way-to-kick-off-your-data-science-education" title="Next: â€œThis is CS50â€: A Pleasant Way to Kick Off Your Data ScienceÂ Education - Why CS50 is especially useful to solidify your software engineering foundation">â€œThis is CS50â€: A Pleasant Way to Kick Off Your Data ScienceÂ Education <small class="subtitle">Why CS50 is especially useful to solidify your software engineering foundation</small></a> Â»</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2019-10-08T20:00:00-05:00">Oct 8, 2019</time>
            <h4>Category</h4>
            <a class="category-link" href="https://wayofnumbers.com/categories#machine-learning-ref">Machine Learning</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://wayofnumbers.com/tags#ai-ref">AI
                    <span>11</span>
</a></li>
                <li><a href="https://wayofnumbers.com/tags#deep-learning-ref">Deep Learning
                    <span>6</span>
</a></li>
                <li><a href="https://wayofnumbers.com/tags#fastai-ref">fast.ai
                    <span>5</span>
</a></li>
                <li><a href="https://wayofnumbers.com/tags#machine-learning-ref">Machine Learning
                    <span>20</span>
</a></li>
                <li><a href="https://wayofnumbers.com/tags#nlp-ref">NLP
                    <span>2</span>
</a></li>
            </ul>
<h4>Stay in Touch</h4>
<div id="sidebar-social-link">
    <a href="https://twitter.com/lymenlee" title="My Twitter" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="Twitter" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1da1f3"/><path fill="#fff" d="M437 152a72 72 0 0 1-40 12 72 72 0 0 0 32-40 72 72 0 0 1-45 17 72 72 0 0 0-122 65 200 200 0 0 1-145-74 72 72 0 0 0 22 94 72 72 0 0 1-32-7 72 72 0 0 0 56 69 72 72 0 0 1-32 1 72 72 0 0 0 67 50 200 200 0 0 1-105 29 200 200 0 0 0 309-179 200 200 0 0 0 35-37"/></svg>
    </a>
    <a href="https://github.com/wayofnumbers" title="GitHub" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
    <a href="www.linkedin.com/in/michael-li-dfw" title="LinkedIn" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="LinkedIn" role="img" viewBox="0 0 512 512" fill="#fff"><rect width="512" height="512" rx="15%" fill="#0077b5"/><circle cx="142" cy="138" r="37"/><path stroke="#fff" stroke-width="66" d="M244 194v198M142 194v198"/><path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg>
    </a>
</div>
            



<!-- Begin MailChimp Signup Form -->
<div id="mc-embed-signup">
<form action="https://github.us17.list-manage.com/subscribe/post?u=c212184cc0965bdf1658f69f0&amp;id=5677a7b75e" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
<h4>Get Monthly Updates</h4>
<input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="Enter your email..." required>
<div class="clear"><input type="submit" value="Send me Free Updates" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
</form>
</div>
<!--End mc_embed_signup-->




            



        </section>
</div>
</article>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>
    <div>
        Content licensed under <a rel="license nofollow noopener noreferrer"
    href="http://creativecommons.org/licenses/by/4.0/" target="_blank">
    Creative Commons Attribution 4.0 International License</a>.
    </div>

    <div>
        <span class="site-name">Way of Numbers</span> - Data science for the rest of us.
    </div>



    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
        Hosted on:
        <a href=https://www.netlify.com/ target="_blank" rel="nofollow noopener noreferrer">
            Netlify
        </a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>